### NestJS에서 Kafka와 Avro를 사용하는 방법

NestJS는 강력한 서버 측 프레임워크로, Kafka와 같은 메시징 시스템과의 통합을 통해 대규모 실시간 데이터를 효과적으로 처리할 수 있습니다. 이 글에서는 **Avro**라는 데이터 직렬화 포맷을 사용하여 NestJS에서 Kafka와 통합하는 방법을 설명하고, 이를 통해 데이터를 효율적으로 직렬화하고 전송하는 다양한 사례를 소개하겠습니다. **Avro**는 **스키마 기반 직렬화**를 지원하며, Kafka와 함께 사용될 때 그 장점이 극대화됩니다.

### 1. Avro 직렬화를 사용하는 이유

NestJS에서 Kafka를 활용할 때 **Avro**를 사용하는 이유는 무엇일까요? 몇 가지 주요 장점을 살펴보겠습니다.

#### 1.1 스키마 기반 데이터 직렬화

Avro는 스키마 기반 직렬화 포맷으로, 데이터를 직렬화할 때 **스키마 레지스트리(Schema Registry)**를 사용합니다. 이를 통해 각 메시지가 일관된 구조를 가지며, 메시지마다 스키마 정보를 포함할 필요 없이 중앙에서 관리할 수 있습니다. Avro와 Kafka를 결합하면 **스키마 레지스트리**에 저장된 스키마를 사용하여 데이터를 직렬화하고, 메시지에는 해당 스키마의 ID만 포함되므로 전송 데이터 크기가 줄어듭니다.

#### 1.2 데이터 일관성 보장

Avro의 스키마 기반 관리 방식은 데이터를 일관되게 유지할 수 있는 장점을 제공합니다. 각 서비스가 다른 버전의 데이터를 주고받더라도, Avro는 스키마 호환성을 보장하므로 안정적으로 데이터 처리가 가능합니다.

#### 1.3 효율적인 데이터 압축

Avro는 데이터를 바이너리 포맷으로 직렬화하므로, 텍스트 기반 포맷(JSON, XML 등)보다 **데이터 크기가 작아** 네트워크 전송 효율이 높고 저장 공간도 절약할 수 있습니다.

#### 1.4 빠른 직렬화/역직렬화 속도

바이너리 기반의 Avro는 텍스트 기반 포맷보다 직렬화 및 역직렬화 속도가 훨씬 빠릅니다. 이는 **실시간 데이터 처리**가 중요한 시스템에서 매우 유리한 특성입니다.

### 2. Kafka와 Avro를 사용하는 효과적인 사례

Kafka와 Avro를 결합하여 사용하는 대표적인 사례 몇 가지를 소개하겠습니다.

#### 2.1 데이터 호환성 유지

여러 서비스가 상호작용하는 대규모 엔터프라이즈 환경에서는 데이터 구조가 지속적으로 변경될 수 있습니다. 예를 들어, NestJS 기반의 고객 관리 시스템에서 **고객 데이터 구조**가 변경되었을 때, 새로운 필드가 추가되더라도 기존 데이터와의 충돌을 피할 수 있습니다. Avro의 스키마 호환성 덕분에 NestJS 서비스들이 새로운 필드를 쉽게 수용하거나 무시할 수 있습니다.

#### 2.2 대규모 실시간 데이터 처리

**IoT 기반 NestJS 시스템**에서 센서 데이터를 실시간으로 Kafka를 통해 수집하고 처리할 때, Avro는 직렬화된 데이터 크기를 최소화하여 네트워크 효율성을 높이고 실시간 데이터 처리를 가능하게 합니다. 예를 들어, 스마트 홈 시스템에서 온도나 습도 데이터를 지속적으로 수집하여 분석하는 경우, Avro와 Kafka의 결합이 적합합니다.

#### 2.3 로그 수집 및 분석

NestJS 애플리케이션에서는 여러 애플리케이션 로그를 실시간으로 Kafka를 통해 수집하고 분석해야 할 때가 많습니다. Avro를 사용하면 로그 데이터를 효율적으로 직렬화하여 Kafka를 통해 전송하고, 다양한 분석 도구와 연계할 수 있습니다.

### 3. NestJS에서 Avro와 Kafka 통합하기

NestJS에서 Kafka와 Avro를 통합하려면, 주로 **Confluent Schema Registry**를 활용하여 Avro 스키마를 중앙에서 관리하는 방법을 사용합니다. 이를 통해 데이터 직렬화와 역직렬화가 수월해지고, 각 클라이언트가 스키마에 맞춰 데이터를 처리할 수 있습니다.

#### 3.1 Avro 직렬화 및 예외 처리 강화

기존의 SchemaRegistryService 코드에 예외 처리를 추가하여, 스키마를 가져오거나 스키마 ID를 불러올 때 발생할 수 있는 오류를 처리하고 로깅을 통해 문제를 추적할 수 있도록 개선하였습니다.

또한, 스키마 레지스트리를 자주 조회하면 성능에 영향을 미칠 수 있으므로, 스키마를 캐시하여 불필요한 네트워크 호출을 줄였습니다.

```typescript
// schema-registry.service.ts
import { Injectable, Logger } from "@nestjs/common";
import { SchemaRegistry } from "@kafkajs/confluent-schema-registry";
import NodeCache from "node-cache";

@Injectable()
export class SchemaRegistryService {
  private registry: SchemaRegistry;
  private readonly logger = new Logger(SchemaRegistryService.name); // 로거 추가
  private schemaCache = new NodeCache(); // 캐시 추가

  constructor() {
    this.registry = new SchemaRegistry({ host: "http://localhost:8081" });
  }

  async getSchema(schemaId: number) {
    const cachedSchema = this.schemaCache.get(schemaId);
    if (cachedSchema) {
      return cachedSchema;
    }

    try {
      const schema = await this.registry.getSchema(schemaId);
      this.schemaCache.set(schemaId, schema); // 캐시에 저장
      return schema;
    } catch (error) {
      this.logger.error(
        `Failed to get schema with ID ${schemaId}: ${error.message}`
      );
      throw new Error("Schema fetching failed");
    }
  }

  async getLatestSchemaId(subject: string) {
    try {
      return await this.registry.getLatestSchemaId(subject);
    } catch (error) {
      this.logger.error(
        `Failed to get latest schema ID for subject ${subject}: ${error.message}`
      );
      throw new Error("Latest schema ID fetching failed");
    }
  }
}
```

### 4. Kafka 프로듀서와 컨슈머의 예외 처리 및 로깅 강화

Kafka 프로듀서와 컨슈머 서비스에서는 데이터를 직렬화하고 전송하거나 소비하는 과정에서 발생할 수 있는 오류를 처리하고, 오류 발생 시 적절한 로그를 남기도록 개선하였습니다.

#### 4.1 Kafka 프로듀서 구현

Kafka 프로듀서에서 데이터 직렬화 및 전송 중 오류가 발생할 수 있는 경우를 대비하여 예외 처리를 강화하고, 로깅을 추가하여 문제가 발생했을 때 원인을 쉽게 파악할 수 있도록 하였습니다. 또한, 스키마 ID를 메시지에 포함하도록 개선하였습니다.

```typescript
// kafka-producer.service.ts
import { Injectable, Logger } from "@nestjs/common";
import { ClientKafka } from "@nestjs/microservices";
import { SchemaRegistryService } from "./schema-registry.service";

@Injectable()
export class KafkaProducerService {
  private readonly logger = new Logger(KafkaProducerService.name);

  constructor(
    private readonly kafkaClient: ClientKafka,
    private readonly schemaRegistryService: SchemaRegistryService
  ) {}

  async sendCustomerData(topic: string, data: any) {
    try {
      const schemaId = await this.schemaRegistryService.getLatestSchemaId(
        "customer-value"
      );
      const avroSchema = await this.schemaRegistryService.getSchema(schemaId);

      // 데이터 직렬화 및 스키마 ID 추가
      const schemaIdBuffer = Buffer.alloc(4);
      schemaIdBuffer.writeUInt32BE(schemaId, 0);
      const serializedData = Buffer.concat([
        schemaIdBuffer,
        avroSchema.toBuffer(data)
      ]);

      this.logger.debug(
        `Sending data to topic ${topic}: ${JSON.stringify(data)}`
      );

      // 메시지 전송
      await this.kafkaClient.emit(topic, { value: serializedData });
      this.logger.log(`Successfully sent data to topic ${topic}`);
    } catch (error) {
      this.logger.error(
        `Failed to send data to topic ${topic}: ${error.message}`
      );
      throw new Error("Kafka message send failed");
    }
  }
}
```

#### 4.2 Kafka 컨슈머 구현

Kafka 컨슈머에서도 메시지를 처리하는 도중 발생할 수 있는 오류를 처리하고, 스키마 ID 추출 과정에서 문제가 발생할 수 있는 상황에 대비하여 예외 처리를 추가하였습니다. 또한, 스키마 ID를 메시지에서 추출하여 적절히 처리할 수 있도록 수정하였습니다.

```typescript
// kafka-consumer.service.ts
import { Injectable, OnModuleInit, Logger } from "@nestjs/common";
import { Consumer, Kafka } from "kafkajs";
import { SchemaRegistryService } from "./schema-registry.service";

@Injectable()
export class KafkaConsumerService implements OnModuleInit {
  private readonly logger = new Logger(KafkaConsumerService.name);
  private consumer: Consumer;

  constructor(private readonly schemaRegistryService: SchemaRegistryService) {
    const kafka = new Kafka({ brokers: ["localhost:9092"] });
    this.consumer = kafka.consumer({ groupId: "customer-group" });
  }

  async onModuleInit() {
    try {
      await this.consumer.connect();
      await this.consumer.subscribe({
        topic: "customer-data",
        fromBeginning: true
      });
      this.logger.log(
        "Kafka consumer connected and subscribed to topic: customer-data"
      );
    } catch (error) {
      this.logger.error(
        `Kafka connection or subscription error: ${error.message}`
      );
      throw new Error("Kafka connection failed");
    }

    await this.consumer.run({
      eachMessage: async ({ message }) => {
        try {
          const schemaId = message.value.readUInt32BE(0); // 메시지에서 스키마 ID 추출
          const avroSchema = await this.schemaRegistryService.getSchema(
            schemaId
          );
          const customerData = avroSchema.fromBuffer(message.value.slice(4));
          this.logger.log(
            `Received customer data: ${JSON.stringify(customerData)}`
          );
        } catch (error) {
          this.logger.error(`Failed to process message: ${error.message}`);
          // 예외 처리 후 계속 처리 가능
        }
      }
    });
  }
}
```

### 5. 센서에서 치명적인 오류가 발생했을 때: 엔터프라이즈급 설계 예시

엔터프라이즈 시스템에서는 센서에서 치명적인 오류나 임계 상황이 발생했을 때, 이를 빠르게 탐지하고 대응하는 것이 중요합니다. NestJS, Kafka, 그리고 Avro를 사용하여 이러한 경고(alert) 메시지를 전송하고 처리하는 방법을 살펴보겠습니다.

#### 5.1 Avro 스키마 정의 및 데이터 직렬화 전략

센서 오류나 치명적인 상태 발생 시 전송할 Alert 메시지의 Avro 스키마를 정의하고, 이를 효과적으로 캐싱하고 직렬화하는 방법을 살펴보겠습니다. 이 스키마는 센서 ID, 경고 유형, 심각도, 메시지 등을 포함합니다. 이를 통해 오류 메시지를 표준화하고 일관성 있게 관리할 수 있습니다.

```json
{
  "type": "record",
  "name": "SensorAlert",
  "fields": [
    { "name": "sensorId", "type": "string" },
    { "name": "alertType", "type": "string" },
    { "name": "timestamp", "type": "long" },
    {
      "name": "severity",
      "type": {
        "type": "enum",
        "name": "SeverityLevel",
        "symbols": ["INFO", "WARNING", "CRITICAL"]
      }
    },
    { "name": "message", "type": "string" }
  ]
}
```

위 스키마를 통해, 경고의 심각도를 명확히 구분하고 필요한 대응을 할 수 있습니다. 스키마는 **SchemaRegistryService**를 통해 관리되고, 각 메시지 전송 시 **스키마 ID**를 사용하여 직렬화합니다. 스키마는 한 번 조회 후 캐싱되어, 불필요한 네트워크 호출을 줄여 성능을 최적화합니다.

#### 5.2 Kafka 프로듀서 및 컨슈머 구현 예시

센서 오류 발생 시 경고 메시지를 전송하고 처리하는 Kafka 프로듀서와 컨슈머를 정의합니다. 이 과정에서 캐싱된 스키마를 활용하여 직렬화 및 역직렬화를 수행합니다.

```typescript
// sensor-alert-producer.service.ts
import { Injectable, Logger } from "@nestjs/common";
import { ClientKafka } from "@nestjs/microservices";
import { SchemaRegistryService } from "./schema-registry.service";

@Injectable()
export class SensorAlertProducerService {
  private readonly logger = new Logger(SensorAlertProducerService.name);

  constructor(
    private readonly kafkaClient: ClientKafka,
    private readonly schemaRegistryService: SchemaRegistryService
  ) {}

  // 센서 경고 메시지를 Kafka로 전송하는 메소드
  async sendSensorAlert(
    sensorId: string,
    alertType: string,
    severity: string,
    message: string
  ) {
    try {
      const schemaId = await this.schemaRegistryService.getLatestSchemaId(
        "sensor-alert-value"
      );
      const avroSchema = await this.schemaRegistryService.getSchema(schemaId);

      const sensorAlert = {
        sensorId,
        alertType,
        timestamp: Date.now(),
        severity,
        message
      };

      // 스키마 ID 추가 및 데이터 직렬화
      const schemaIdBuffer = Buffer.alloc(4);
      schemaIdBuffer.writeUInt32BE(schemaId, 0);
      const serializedData = Buffer.concat([
        schemaIdBuffer,
        avroSchema.toBuffer(sensorAlert)
      ]);

      this.logger.debug(
        `Sending sensor alert to Kafka: ${JSON.stringify(sensorAlert)}`
      );

      // 메시지 전송
      await this.kafkaClient.emit("sensor-alert", { value: serializedData });
      this.logger.log(
        `Successfully sent sensor alert for sensorId ${sensorId}`
      );
    } catch (error) {
      this.logger.error(`Failed to send sensor alert: ${error.message}`);
      throw new Error("Kafka message send failed");
    }
  }
}
```

### 6. 캐싱 전략을 활용한 성능 최적화

대규모 시스템에서는 빈번한 스키마 조회가 성능에 영향을 미칠 수 있습니다. 이를 방지하기 위해 **NodeCache**와 같은 메모리 기반 캐싱을 사용하여 스키마 정보를 로컬 메모리에 저장하고, 동일한 스키마를 사용할 경우 불필요한 네트워크 호출을 줄일 수 있습니다. 이를 통해 시스템 성능을 최적화할 수 있으며, 특히 고빈도의 메시지 송수신이 이루어지는 환경에서 더욱 효과적입니다.

#### 6.1 캐시 초기화 및 스키마 조회

캐시는 NestJS 서비스에 초기화될 때 자동으로 설정되며, `getSchema()` 메소드에서 캐시된 스키마가 있으면 이를 반환하고, 없을 경우에만 레지스트리에서 스키마를 가져옵니다. 이를 통해 스키마 조회 시간을 단축하고 네트워크 대역폭을 절약할 수 있습니다.

```typescript
// schema-registry.service.ts
import { Injectable, Logger } from "@nestjs/common";
import { SchemaRegistry } from "@kafkajs/confluent-schema-registry";
import NodeCache from "node-cache";

@Injectable()
export class SchemaRegistryService {
  private registry: SchemaRegistry;
  private readonly logger = new Logger(SchemaRegistryService.name);
  private schemaCache = new NodeCache(); // 스키마 캐싱

  constructor() {
    this.registry = new SchemaRegistry({ host: "http://localhost:8081" });
  }

  // 캐싱된 스키마 반환 또는 레지스트리에서 조회
  async getSchema(schemaId: number) {
    const cachedSchema = this.schemaCache.get(schemaId);
    if (cachedSchema) {
      return cachedSchema;
    }

    try {
      const schema = await this.registry.getSchema(schemaId);
      this.schemaCache.set(schemaId, schema); // 스키마 캐시 저장
      return schema;
    } catch (error) {
      this.logger.error(
        `Failed to get schema with ID ${schemaId}: ${error.message}`
      );
      throw new Error("Schema fetching failed");
    }
  }

  // 최신 스키마 ID 반환
  async getLatestSchemaId(subject: string) {
    try {
      return await this.registry.getLatestSchemaId(subject);
    } catch (error) {
      this.logger.error(
        `Failed to get latest schema ID for subject ${subject}: ${error.message}`
      );
      throw new Error("Latest schema ID fetching failed");
    }
  }
}
```

### 7. 엔터프라이즈급 시스템에서의 캐싱 및 스키마 최적화

캐싱 전략은 단순한 메시지 송수신을 넘어서 대규모 엔터프라이즈 시스템에서 중요한 역할을 합니다. 실시간 데이터 처리가 필요한 IoT 시스템이나 금융 시스템에서는 성능 저하가 치명적일 수 있기 때문에, Avro 스키마와 Kafka 메시징 시스템을 효율적으로 관리하는 것이 필수적입니다.

**1. 캐싱 유효 기간 설정**  
캐싱된 스키마가 항상 최신 상태를 유지하기 위해 유효 기간을 설정할 수 있습니다. NodeCache의 TTL(Time to Live)을 사용하여 스키마가 일정 시간이 지나면 자동으로 삭제되도록 설정할 수 있으며, 이는 자주 변경되는 스키마 환경에서 유용합니다.

```typescript
// 캐시 초기화 시 TTL을 1시간으로 설정
private schemaCache = new NodeCache({ stdTTL: 3600 }); // TTL: 1시간
```

**2. 지연 로딩(Lazy Loading) 기법**  
스키마를 미리 조회해 캐싱하는 방식이 아닌, 실제로 스키마가 필요할 때 조회하고 캐싱하는 **지연 로딩** 기법을 적용하면 필요할 때만 스키마 레지스트리에 접근할 수 있습니다. 이는 불필요한 데이터 조회를 방지하여 자원을 절약하는 효과를 가져옵니다.

**3. 분산 캐시 도입**  
시스템 규모가 커짐에 따라 단일 노드에서의 캐싱 전략이 한계에 다다를 수 있습니다. 이럴 경우, **Redis**와 같은 분산 캐시 솔루션을 도입하여 여러 노드 간에 스키마 캐시를 공유할 수 있으며, 이는 시스템의 일관성과 성능을 더욱 향상시킬 수 있습니다.

---

### 결론

NestJS와 Kafka, Avro를 결합하여 대규모 실시간 데이터 처리 시스템을 구축하는 방법을 살펴보았습니다. **Avro의 스키마 기반 직렬화** 덕분에 데이터의 일관성을 보장하면서도, 바이너리 포맷을 통한 빠른 직렬화/역직렬
