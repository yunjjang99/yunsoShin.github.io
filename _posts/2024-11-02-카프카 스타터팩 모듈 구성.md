# NestJS에서 토픽별 Kafka 설정을 위한 인터페이스 기반 구성 가이드

Kafka는 MSA 아키텍처에서 안정적이고 확장 가능한 메시징 솔루션으로 널리 사용됩니다. 여러 서비스가 동일한 Kafka 인프라를 사용할 때 특정 토픽에 대해 맞춤 설정(예: ACK 설정, 그룹 ID, 오프셋 관리 방식 등)이 필요할 수 있습니다. 이 글에서는 NestJS 기반 서버에서 Kafka의 토픽별 설정을 인터페이스 기반으로 구성하여 직관적이고 확장성 있는 코드를 작성하는 방법을 소개합니다.

---

#### 목표

1. **프로듀서**: 각 토픽에 대한 ACK 설정을 인터페이스로 관리하여 메시지 신뢰성을 높임.
2. **컨슈머**: 수동 커밋을 통해 데이터 신뢰성을 높이고, 토픽별 그룹 ID와 오프셋 관리 방식을 인터페이스로 관리.
3. **모듈화**: 토픽별 설정을 인터페이스로 분리하여 명확하고 재사용 가능한 Kafka 설정 제공.

---

## 토픽별 인터페이스 구성

각 토픽에 대해 필요한 설정을 `interface`로 정의하여 구성합니다. 이 인터페이스를 통해 `topic`, `ack`, `groupId`, `fromBeginning`, 그리고 `schemaId`와 같은 필수 속성을 관리할 수 있습니다.

### 1. Kafka Topic Interface 정의

Kafka 설정을 위한 각 토픽 인터페이스를 정의합니다. 모든 토픽이 동일한 구조를 가지도록 `KafkaTopicConfig`라는 기본 인터페이스를 두고, 각 토픽의 고유한 설정을 구현하는 방식입니다.

```typescript
// kafka-topics.interface.ts

// 기본 Kafka 토픽 설정 인터페이스
interface KafkaTopicConfig {
  topic: string;
  ack: "all" | 1 | 0;
  groupId: string;
  fromBeginning: boolean;
  schemaId: number;
}

// 각 토픽별 인터페이스 정의
export const KafkaTopicsConfig: Record<string, KafkaTopicConfig> = {
  MY_TOPIC: {
    topic: "my-topic",
    ack: "all", // 모든 복제본에 저장되어야 성공
    groupId: "group1", // 그룹 ID 설정
    fromBeginning: true, // 처음부터 데이터 수신
    schemaId: 1 // Schema registry에서 가져온 schema ID
  },
  ANOTHER_TOPIC: {
    topic: "another-topic",
    ack: 1, // 최소 1개의 복제본에 저장되면 성공
    groupId: "group2", // 그룹 ID 설정
    fromBeginning: false, // 최신 메시지만 수신
    schemaId: 2 // Schema registry에서 가져온 schema ID
  }
};
```

### 2. 프로듀서 및 컨슈머 코드에서 인터페이스 적용

이제 위에서 정의한 `KafkaTopicsConfig` 인터페이스를 사용하여 각 토픽에 대해 설정을 불러오도록 프로듀서와 컨슈머 코드를 작성합니다.

#### 프로듀서 코드

`sendMessage` 메서드에서 `KafkaTopicsConfig`의 설정을 기반으로 각 토픽에 맞는 ACK 설정과 토픽 이름을 불러와 메시지를 전송합니다.

```typescript
// kafka-producer.service.ts
import { Inject, Injectable } from "@nestjs/common";
import { Kafka, Producer, ProducerConfig } from "kafkajs";
import { SchemaRegistry } from "@kafkajs/confluent-schema-registry";
import { KafkaTopicsConfig } from "./kafka-topics.interface";

@Injectable()
export class KafkaProducerService {
  private readonly producers: Record<string, Producer> = {};

  constructor(
    @Inject("KAFKA_CLIENT") private readonly kafkaClient: Kafka,
    @Inject("SCHEMA_REGISTRY") private readonly schemaRegistry: SchemaRegistry
  ) {}

  // 토픽별 프로듀서 생성 함수
  private async getProducer(
    topicKey: keyof typeof KafkaTopicsConfig
  ): Promise<Producer> {
    const topicConfig = KafkaTopicsConfig[topicKey];
    if (!this.producers[topicConfig.topic]) {
      const producerConfig: ProducerConfig = { acks: topicConfig.ack };
      const producer = this.kafkaClient.producer(producerConfig);
      await producer.connect();
      this.producers[topicConfig.topic] = producer;
    }
    return this.producers[topicConfig.topic];
  }

  // 메시지 전송 함수
  async sendMessage(
    topicKey: keyof typeof KafkaTopicsConfig,
    key: string,
    message: any
  ) {
    const topicConfig = KafkaTopicsConfig[topicKey];
    const producer = await this.getProducer(topicKey);
    const encodedMessage = await this.schemaRegistry.encode(
      topicConfig.schemaId,
      message
    );
    await producer.send({
      topic: topicConfig.topic,
      messages: [{ key, value: encodedMessage }]
    });
  }
}
```

### 사용 예시

이제 `sendMessage` 메서드를 호출할 때, `KafkaTopicsConfig` 인터페이스에 정의된 설정을 토대로 토픽별로 다른 ACK 설정을 적용할 수 있습니다.

```typescript
await kafkaProducerService.sendMessage("MY_TOPIC", "key", { data: "example" });
await kafkaProducerService.sendMessage("ANOTHER_TOPIC", "key", {
  data: "example"
});
```

---

#### 컨슈머 코드

컨슈머 코드에서도 `KafkaTopicsConfig`의 설정을 기반으로 각 토픽에 대해 그룹 ID, 오프셋 관리 방식을 불러와 메시지를 처리합니다.

```typescript
// kafka-consumer.service.ts
import { Inject, Injectable, OnModuleInit } from "@nestjs/common";
import { Kafka, Consumer, EachMessagePayload } from "kafkajs";
import { SchemaRegistry } from "@kafkajs/confluent-schema-registry";
import { KafkaTopicsConfig } from "./kafka-topics.interface";

@Injectable()
export class KafkaConsumerService implements OnModuleInit {
  private consumers: Record<string, Consumer> = {};

  constructor(
    @Inject("KAFKA_CLIENT") private readonly kafkaClient: Kafka,
    @Inject("SCHEMA_REGISTRY") private readonly schemaRegistry: SchemaRegistry
  ) {}

  // 토픽별 컨슈머 생성 함수
  private async getConsumer(
    topicKey: keyof typeof KafkaTopicsConfig
  ): Promise<Consumer> {
    const topicConfig = KafkaTopicsConfig[topicKey];
    if (!this.consumers[topicConfig.topic]) {
      const consumer = this.kafkaClient.consumer({
        groupId: topicConfig.groupId,
        autoCommit: true
      });
      await consumer.connect();
      await consumer.subscribe({
        topic: topicConfig.topic,
        fromBeginning: topicConfig.fromBeginning
      });
      this.consumers[topicConfig.topic] = consumer;
    }
    return this.consumers[topicConfig.topic];
  }

  // 메시지 수신 및 오프셋 관리
  async consumeMessages(topicKey: keyof typeof KafkaTopicsConfig) {
    const topicConfig = KafkaTopicsConfig[topicKey];
    const consumer = await this.getConsumer(topicKey);
    await consumer.run({
      eachMessage: async (payload: EachMessagePayload) => {
        const { message } = payload;
        const decodedMessage = await this.schemaRegistry.decode(message.value);
        console.log(
          `Received message from ${topicConfig.topic}:`,
          decodedMessage
        );

        if (!topicConfig.fromBeginning) {
          await this.handleManualCommit(payload);
        }
      }
    });
  }

  // 수동 커밋 로직
  private async handleManualCommit(payload: EachMessagePayload) {
    const { topic, partition, message } = payload;
    try {
      console.log("Processing message:", message.value.toString());
      await this.consumers[topic].commitOffsets([
        { topic, partition, offset: (parseInt(message.offset) + 1).toString() }
      ]);
    } catch (error) {
      console.error("Failed to commit offset:", error);
    }
  }
}
```

### 사용 예시

`consumeMessages` 메서드를 호출할 때도 `KafkaTopicsConfig` 인터페이스에 정의된 설정을 토대로 각 토픽에 대한 그룹 ID와 오프셋 관리 방식을 적용할 수 있습니다.

```typescript
await kafkaConsumerService.consumeMessages("MY_TOPIC");
await kafkaConsumerService.consumeMessages("ANOTHER_TOPIC");
```

---

### 요약

이 구성을 통해 NestJS 환경에서 Kafka를 유연하게 사용할 수 있습니다. 각 토픽에 대해 인터페이스 기반으로 ACK 설정, 그룹 ID, 오프셋 관리 방식을 관리하여 데이터 신뢰성을 보장하고 효율성을 높일 수 있습니다. 특히 메시지 정합성이 중요한 경우 수동 커밋과 `fromBeginning` 옵션을 통해 서버 중단 이후에도 데이터를 손실 없이 처리할 수 있도록 설계할 수 있습니다.

이와 같은 인터페이스 기반 접근은 다양한 요구사항을 충족하면서도 간결하고 재사용 가능한 Kafka 설정을 제공합니다.
