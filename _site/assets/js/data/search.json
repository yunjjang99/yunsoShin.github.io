[
  
  {
    "title": "커넥션을 활용하여 토픽으로 데이터를 재생산하는 방법",
    "url": "/posts/%EC%BB%A4%EB%84%A5%EC%85%98%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%98%EC%97%AC-%ED%86%A0%ED%94%BD%EC%9C%BC%EB%A1%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%EC%9E%AC%EC%83%9D%EC%82%B0%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95/",
    "categories": "",
    "tags": "",
    "date": "2024-11-02 00:00:00 +0900",
    





    
    "snippet": "커넥션을 활용하여 토픽으로 데이터를 재생산하는 방법기존에 처리된 데이터를 Amazon S3에서 다시 로드하여 Kafka로 재처리하는 방법은 Kafka Connect를 활용하여 데이터를 새로운 Kafka 토픽으로 배치하는 방식입니다. 예를 들어, S3에 저장된 데이터는 JSON 형식으로 보관되었고, 이를 재처리하여 새로운 비즈니스 로직에 활용하고자 할 ...",
    "content": "커넥션을 활용하여 토픽으로 데이터를 재생산하는 방법기존에 처리된 데이터를 Amazon S3에서 다시 로드하여 Kafka로 재처리하는 방법은 Kafka Connect를 활용하여 데이터를 새로운 Kafka 토픽으로 배치하는 방식입니다. 예를 들어, S3에 저장된 데이터는 JSON 형식으로 보관되었고, 이를 재처리하여 새로운 비즈니스 로직에 활용하고자 할 때 Kafka Connect의 S3 Source Connector를 사용하여 Kafka 토픽에 데이터를 배치할 수 있습니다. 이때, 아래의 순서에 따라 설정합니다.1. 새로운 Kafka 토픽 생성새로운 토픽을 만들어 데이터를 수신할 준비를 합니다. kafka-topics.sh 스크립트를 사용하여 토픽을 생성할 수 있습니다:bin/kafka-topics.sh --create --topic reprocessed-data --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1위의 명령은 reprocessed-data라는 이름의 새 토픽을 생성합니다. --partitions와 --replication-factor는 필요에 따라 조정할 수 있습니다.2. Kafka Connect S3 Source Connector 설정Kafka Connect를 통해 S3에서 데이터를 로드하기 위해 Kafka Connect의 S3 Source Connector를 설정합니다. 이 커넥터는 S3 버킷에서 JSON 형식의 데이터를 가져와서 Kafka로 스트리밍합니다.connect-distributed.properties 파일에 연결된 커넥터 설정 파일을 작성하거나, REST API를 통해 S3 Source Connector를 설정할 수 있습니다. 여기에서는 REST API를 통해 설정하는 방법을 보여드립니다.설정 예제 (REST API 사용)curl -X POST -H \"Content-Type: application/json\" --data '{  \"name\": \"s3-source-connector\",  \"config\": {    \"connector.class\": \"io.confluent.connect.s3.S3SourceConnector\",    \"tasks.max\": \"1\",    \"s3.region\": \"ap-northeast-2\",  // 사용할 AWS S3 리전 설정    \"s3.bucket.name\": \"your-s3-bucket-name\",    \"s3.access.key.id\": \"your-access-key\",    \"s3.secret.access.key\": \"your-secret-key\",    \"format.class\": \"io.confluent.connect.s3.format.json.JsonFormat\",    \"topic\": \"reprocessed-data\",    \"partitioner.class\": \"io.confluent.connect.storage.partitioner.DefaultPartitioner\",    \"schema.compatibility\": \"NONE\",    \"s3.poll.interval.ms\": \"10000\"  }}' http://localhost:8083/connectors설명:  \"connector.class\": \"io.confluent.connect.s3.S3SourceConnector\": S3 소스 커넥터를 지정합니다.  \"tasks.max\": \"1\": 한 번에 실행할 수 있는 최대 태스크 수입니다.  \"s3.region\": \"ap-northeast-2\": 사용 중인 AWS 리전입니다. 여기서는 서울 리전을 예로 들었습니다.  \"s3.bucket.name\": \"your-s3-bucket-name\": 데이터를 가져올 S3 버킷의 이름입니다.  \"s3.access.key.id\"와 \"s3.secret.access.key\": AWS 인증에 필요한 키와 비밀 키입니다. (보안을 위해 IAM 역할을 사용하는 것을 권장)  \"format.class\": \"io.confluent.connect.s3.format.json.JsonFormat\": 데이터 형식을 JSON으로 지정합니다.  \"topic\": \"reprocessed-data\": 데이터를 전송할 Kafka 토픽입니다.  \"partitioner.class\": 파티셔닝 전략으로 기본 설정을 사용합니다.  \"schema.compatibility\": \"NONE\": 데이터 스키마 호환성을 설정합니다.  \"s3.poll.interval.ms\": \"10000\": S3 버킷을 폴링하는 간격(밀리초)입니다.이 설정은 Kafka Connect가 주기적으로 S3 버킷을 확인하고, 새롭게 추가된 JSON 데이터를 reprocessed-data 토픽으로 전송하게 합니다.3. 데이터 확인새로운 토픽에 데이터가 잘 수신되는지 확인하려면 다음과 같은 명령어를 사용할 수 있습니다:bin/kafka-console-consumer.sh --topic reprocessed-data --from-beginning --bootstrap-server localhost:9092이 명령어는 reprocessed-data 토픽에 전송된 데이터를 처음부터 소비하여 터미널에 출력합니다.4. 주요 고려사항  재처리 설정: 데이터가 정기적으로 S3에 업로드되거나 다른 버킷에 백업된 경우, 각 배치 처리마다 필요한 데이터를 불러올 수 있도록 폴링 간격을 조절해야 합니다.  데이터 필터링: 필요에 따라 데이터 필터링을 추가하여 원하는 데이터만 재처리할 수 있습니다.  에러 핸들링: 커넥터 설정에 오류 처리를 포함하여 손상된 파일이나 잘못된 형식의 데이터가 있을 경우 문제를 확인하고 건너뛸 수 있습니다.이와 같은 방법으로, 이전에 처리된 데이터를 Kafka 토픽으로 재로드하고, 새로운 비즈니스 로직에 맞추어 데이터를 다시 활용할 수 있습니다."
  },
  
  {
    "title": "카프카 컴패션옵션에 대한 정리",
    "url": "/posts/%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%BB%B4%ED%8C%A8%EC%85%98%EC%98%B5%EC%85%98%EC%97%90-%EB%8C%80%ED%95%9C-%EC%A0%95%EB%A6%AC/",
    "categories": "",
    "tags": "",
    "date": "2024-11-02 00:00:00 +0900",
    





    
    "snippet": "Kafka의 컴팩션(compaction): 데이터 중복 제거와 최신 상태 유지의 비결Kafka는 대용량의 실시간 데이터 스트림을 처리하는 데 최적화된 메시지 브로커 시스템으로, 다양한 데이터 보관 옵션을 제공하여 데이터 관리의 유연성을 높여줍니다. 그중에서도 컴팩션(compaction)은 특정 상황에서 중복된 데이터를 줄이고, 최신 상태를 유지하기 위...",
    "content": "Kafka의 컴팩션(compaction): 데이터 중복 제거와 최신 상태 유지의 비결Kafka는 대용량의 실시간 데이터 스트림을 처리하는 데 최적화된 메시지 브로커 시스템으로, 다양한 데이터 보관 옵션을 제공하여 데이터 관리의 유연성을 높여줍니다. 그중에서도 컴팩션(compaction)은 특정 상황에서 중복된 데이터를 줄이고, 최신 상태를 유지하기 위해 매우 유용한 기능입니다. 이번 글에서는 Kafka의 컴팩션이란 무엇인지, 어떤 상황에서 활용되는지와 함께 구체적인 예시로 알아보겠습니다.컴팩션이란?Kafka의 컴팩션은 Log Compaction이라고도 하며, 다음과 같은 주요 기능을 제공합니다:  키 기반 중복 제거: Kafka의 메시지는 “키-값” 형태로 저장되며, 컴팩션은 같은 키를 가진 메시지들 중 가장 최신의 레코드만 남기고 이전 레코드는 삭제하는 방식으로 작동합니다.  데이터 영구적 유지: 일반적인 Kafka의 보관 정책(retention policy)와는 별개로, 컴팩션된 데이터는 원하는 만큼 오래 보관할 수 있습니다. 이로 인해 장기 데이터 보관이 필요한 경우에도 유용하게 사용됩니다.  삭제 키(tombstone): 특정 키에 대한 데이터를 완전히 삭제하려면 null 값을 가진 특별한 레코드인 “tombstone”을 사용합니다. 컴팩션은 이 tombstone을 만나면 해당 키의 데이터를 완전히 제거할 수 있습니다.컴팩션의 특징  최신 상태 유지: 컴팩션을 통해 모든 데이터 중 가장 최신 상태만 유지되므로, 특히 변경이 빈번한 데이터에서 유용합니다.  효율적인 메모리 사용: 중복된 키를 제거함으로써 저장 공간을 절약하고, 검색 속도를 높일 수 있습니다.  비동기적 컴팩션: 컴팩션은 Kafka의 백그라운드에서 비동기적으로 수행되며, 모든 메시지가 즉시 컴팩션되는 것은 아닙니다. 즉, 데이터 순서는 보장되지 않습니다.컴팩션이 사용되는 사례컴팩션은 주로 최신 상태만 중요하거나 중복 데이터가 필요하지 않은 경우에 유용하게 사용됩니다. 아래에서는 컴팩션을 활용할 수 있는 몇 가지 일반적인 사례를 다루어 보겠습니다.1. 사용자 프로필 관리 (user_profile 토픽)사용자 프로필 정보와 같이 사용자의 최신 정보만 필요할 경우에 적합합니다. 사용자가 프로필을 업데이트할 때마다 Kafka 토픽에 새 메시지가 기록되며, 이때 각 사용자 ID를 키로 사용하여 컴팩션을 통해 최신 프로필 정보만 남길 수 있습니다.예시:  토픽 이름: user_profile  키: 사용자 ID (user_id)  값: {name: \"Alice\", age: 26, location: \"Seoul\"}  사용 예시: 사용자가 자신의 프로필을 업데이트할 때마다 해당 사용자 ID에 대한 최신 정보만 남기고, 이전 기록은 삭제됩니다.컴팩션 후에는 각 사용자 ID에 대한 최신 프로필 정보만 남아 데이터베이스와 유사한 최신 상태 저장소 역할을 할 수 있습니다.2. 상품 재고 관리 (product_inventory 토픽)재고 관리에서는 상품의 최신 재고 상태만 중요합니다. 과거 재고 수량 기록은 필요하지 않기 때문에, 컴팩션을 통해 각 상품 ID에 대한 최신 재고 정보만 남기면 효율적입니다.예시:  토픽 이름: product_inventory  키: 상품 ID (product_id)  값: {productName: \"Laptop\", stock: 15}  사용 예시: 상품의 재고가 변경될 때마다 최신 재고 정보만 유지하고 이전 기록은 삭제됩니다.컴팩션 적용 후에는 각 상품의 현재 재고 수량만 남아있어, 저장 공간을 절약하고 재고 조회 속도를 높일 수 있습니다.3. 장비 상태 모니터링 (device_status 토픽)사물인터넷(IoT) 시스템이나 네트워크 관리 시스템에서는 각 장비의 최신 상태만 유지하는 것이 중요합니다. 장비가 오프라인에서 온라인으로 전환되거나 배터리 상태가 변경되는 경우 최신 상태만을 남기고 이전 상태는 삭제하는 방식으로 관리할 수 있습니다.예시:  토픽 이름: device_status  키: 장비 ID (device_id)  값: {status: \"online\", battery: 85}  사용 예시: 장비 상태가 변경될 때마다 최신 상태만 남기고 이전 상태는 삭제됩니다.이렇게 컴팩션을 적용하면 각 장비의 최신 상태 정보만 남아 실시간 모니터링 시스템에 적합하게 유지할 수 있습니다.4. 주문 상태 관리 (order_status 토픽)전자상거래나 주문 관리 시스템에서는 특정 주문의 최신 상태만 중요할 때가 많습니다. 예를 들어, 주문이 “처리 중”에서 “배송됨”으로 변경되면, “처리 중” 상태는 불필요해지므로 최신 상태만 유지할 수 있습니다.예시:  토픽 이름: order_status  키: 주문 ID (order_id)  값: {status: \"shipped\", estimatedDelivery: \"2024-11-10\"}  사용 예시: 주문 상태가 변경될 때마다 최신 상태만 남기고 이전 상태 기록은 삭제됩니다.이렇게 컴팩션이 적용되면 각 주문의 최신 상태만 유지할 수 있어 주문 추적 시스템의 효율성을 높입니다.5. 마지막 로그인 정보 관리 (user_last_login 토픽)사용자의 로그인 기록 중 최신 로그인 정보만 필요할 때 컴팩션이 유용합니다. 특정 사용자의 로그인 기록을 저장하고, 최신 로그인 정보만 유지하면 데이터 관리에 큰 도움이 됩니다.예시:  토픽 이름: user_last_login  키: 사용자 ID (user_id)  값: {lastLogin: \"2024-11-02T15:30:00Z\"}  사용 예시: 사용자가 로그인할 때마다 최신 로그인 정보만 유지하고, 이전 로그인 기록은 삭제됩니다.컴팩션을 통해 각 사용자의 최신 로그인 시간만 유지할 수 있어 불필요한 데이터 저장을 줄일 수 있습니다.6. 상품 가격 정보 (product_price 토픽)가격 변동이 빈번한 상품의 경우 최신 가격 정보만 남기고 이전 기록은 삭제할 수 있습니다. 이를 통해 각 상품의 현재 가격만 유지할 수 있습니다.예시:  토픽 이름: product_price  키: 상품 ID (product_id)  값: {price: 299.99}  사용 예시: 상품의 가격이 변경될 때마다 최신 가격 정보만 유지하고, 이전 가격 기록은 삭제됩니다.각 상품의 최신 가격 정보만 유지하여 가격 조회 속도와 데이터 저장 효율을 높일 수 있습니다.컴팩션 설정하기Kafka에서 컴팩션을 활성화하려면 토픽 설정에서 cleanup.policy를 \"compact\"으로 설정해야 합니다.# Kafka 토픽 설정 예제cleanup.policy=compact이 설정을 추가하면, 해당 토픽에 대해 Kafka가 백그라운드에서 컴팩션을 주기적으로 수행합니다.주의 사항컴팩션이 활성화되면 데이터는 항상 최신 상태로 유지되지만, 모든 데이터가 즉시 컴팩션되지 않으며 순서도 보장되지 않습니다. Kafka는 비동기적으로 컴팩션을 수행하기 때문에, 일부 레코드는 잠시 남아 있을 수 있으며 즉각적인 최신 상태가 반영되지는 않을 수 있습니다."
  },
  
  {
    "title": "카프카 커스텀파티셔닝",
    "url": "/posts/%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%BB%A4%EC%8A%A4%ED%85%80%ED%8C%8C%ED%8B%B0%EC%85%94%EB%8B%9D/",
    "categories": "",
    "tags": "",
    "date": "2024-11-02 00:00:00 +0900",
    





    
    "snippet": "센서 데이터를 처리하고 운영자에게 심각한 중단 상황을 신속하게 알리기 위해, Apache Kafka와 NestJS를 활용하여 시스템을 구축할 수 있습니다. 이 글에서는 알림 수준에 따라 메시지를 특정 파티션에 할당하고, 컨슈머가 Critical 알림을 우선 처리하도록 구현하는 방법을 단계별로 설명하겠습니다.1. Kafka 토픽 및 파티션 설계...",
    "content": "센서 데이터를 처리하고 운영자에게 심각한 중단 상황을 신속하게 알리기 위해, Apache Kafka와 NestJS를 활용하여 시스템을 구축할 수 있습니다. 이 글에서는 알림 수준에 따라 메시지를 특정 파티션에 할당하고, 컨슈머가 Critical 알림을 우선 처리하도록 구현하는 방법을 단계별로 설명하겠습니다.1. Kafka 토픽 및 파티션 설계먼저, Kafka에서 알림을 처리하기 위한 alerts 토픽을 생성하고, 알림 수준에 따라 파티션을 분리합니다:  파티션 0: Critical  파티션 1: Major  파티션 2: Minor  파티션 3: Warning이러한 구조를 통해 각 알림 수준에 따라 메시지를 분리하여 처리할 수 있습니다.2. 커스텀 파티셔너 구현알림 수준에 따라 메시지를 특정 파티션에 할당하기 위해 커스텀 파티셔너를 작성합니다. kafkajs 라이브러리를 사용하여 파티셔너를 구현하고, NestJS에서 이를 활용합니다.import { Partitioners } from 'kafkajs';class AlertPartitioner extends Partitioners.DefaultPartitioner {  partition({ topic, partitionMetadata, message }) {    const alertLevel = message.value.alertLevel;    switch (alertLevel) {      case 'Critical':        return 0; // Critical은 파티션 0으로 보냄      case 'Major':        return 1;      case 'Minor':        return 2;      case 'Warning':        return 3;      default:        // 기본 파티셔너의 로직을 사용        return super.partition({ topic, partitionMetadata, message });    }  }}이 파티셔너는 메시지의 alertLevel에 따라 해당 파티션에 메시지를 할당합니다.3. NestJS에서 Kafka 프로듀서 설정@nestjs/microservices 패키지를 사용하여 Kafka 프로듀서를 설정하고, 커스텀 파티셔너를 적용합니다.import { Injectable, OnModuleInit } from '@nestjs/common';import { ClientKafka, Transport } from '@nestjs/microservices';import { Kafka, Producer } from 'kafkajs';import { AlertPartitioner } from './alert.partitioner';@Injectable()export class AlertService implements OnModuleInit {  private producer: Producer;  async onModuleInit() {    const kafka = new Kafka({      clientId: 'alert-service',      brokers: ['localhost:9092'],    });    this.producer = kafka.producer({      createPartitioner: () =&gt; new AlertPartitioner(),    });    await this.producer.connect();  }  async sendAlert(alertLevel: string, message: string) {    try {      await this.producer.send({        topic: 'alerts',        messages: [          {            key: alertLevel,            value: JSON.stringify({ alertLevel, message }),          },        ],      });      console.log(`Alert sent: ${alertLevel} - ${message}`);    } catch (error) {      console.error(`Failed to send alert: ${error.message}`);    }  }}여기서 sendAlert 메서드는 알림 수준과 메시지를 받아 해당 파티션에 메시지를 전송합니다. 전송 중 에러가 발생하면 catch 블록에서 에러를 처리하고 로그를 남깁니다.4. NestJS에서 Kafka 컨슈머 설정컨슈머는 alerts 토픽의 모든 파티션을 구독하되, Critical 알림을 우선 처리하도록 구현합니다.import { Injectable, OnModuleInit } from '@nestjs/common';import { ClientKafka, Transport, EventPattern, Payload } from '@nestjs/microservices';@Injectable()export class AlertConsumerService implements OnModuleInit {  private kafkaConsumer: ClientKafka;  constructor() {    this.kafkaConsumer = new ClientKafka({      transport: Transport.KAFKA,      options: {        client: {          clientId: 'alert-consumer',          brokers: ['localhost:9092'],        },        consumer: {          groupId: 'alert-consumer-group',        },      },    });  }  async onModuleInit() {    await this.kafkaConsumer.connect();    this.kafkaConsumer.subscribeToResponseOf('alerts');  }  @EventPattern('alerts')  async handleAlert(@Payload() message: any) {    const { alertLevel, message: alertMessage } = message.value;    if (alertLevel === 'Critical') {      // Critical 알림 처리 로직      console.log(`Critical alert received: ${alertMessage}`);    } else {      // 다른 알림 처리 로직      console.log(`Alert received: ${alertLevel} - ${alertMessage}`);    }  }}이렇게 하면 컨슈머는 alerts 토픽의 모든 파티션을 구독하고, Critical 알림을 우선 처리하게 됩니다."
  },
  
  {
    "title": "카프카 스타터팩 모듈 구성",
    "url": "/posts/%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%8A%A4%ED%83%80%ED%84%B0%ED%8C%A9-%EB%AA%A8%EB%93%88-%EA%B5%AC%EC%84%B1/",
    "categories": "",
    "tags": "",
    "date": "2024-11-02 00:00:00 +0900",
    





    
    "snippet": "NestJS에서 토픽별 Kafka 설정을 위한 인터페이스 기반 구성 가이드Kafka는 MSA 아키텍처에서 안정적이고 확장 가능한 메시징 솔루션으로 널리 사용됩니다. 여러 서비스가 동일한 Kafka 인프라를 사용할 때 특정 토픽에 대해 맞춤 설정(예: ACK 설정, 그룹 ID, 오프셋 관리 방식 등)이 필요할 수 있습니다. 이 글에서는 NestJS 기반...",
    "content": "NestJS에서 토픽별 Kafka 설정을 위한 인터페이스 기반 구성 가이드Kafka는 MSA 아키텍처에서 안정적이고 확장 가능한 메시징 솔루션으로 널리 사용됩니다. 여러 서비스가 동일한 Kafka 인프라를 사용할 때 특정 토픽에 대해 맞춤 설정(예: ACK 설정, 그룹 ID, 오프셋 관리 방식 등)이 필요할 수 있습니다. 이 글에서는 NestJS 기반 서버에서 Kafka의 토픽별 설정을 인터페이스 기반으로 구성하여 직관적이고 확장성 있는 코드를 작성하는 방법을 소개합니다.목표  프로듀서: 각 토픽에 대한 ACK 설정을 인터페이스로 관리하여 메시지 신뢰성을 높임.  컨슈머: 수동 커밋을 통해 데이터 신뢰성을 높이고, 토픽별 그룹 ID와 오프셋 관리 방식을 인터페이스로 관리.  모듈화: 토픽별 설정을 인터페이스로 분리하여 명확하고 재사용 가능한 Kafka 설정 제공.토픽별 인터페이스 구성각 토픽에 대해 필요한 설정을 interface로 정의하여 구성합니다. 이 인터페이스를 통해 topic, ack, groupId, fromBeginning, 그리고 schemaId와 같은 필수 속성을 관리할 수 있습니다.1. Kafka Topic Interface 정의Kafka 설정을 위한 각 토픽 인터페이스를 정의합니다. 모든 토픽이 동일한 구조를 가지도록 KafkaTopicConfig라는 기본 인터페이스를 두고, 각 토픽의 고유한 설정을 구현하는 방식입니다.// kafka-topics.interface.ts// 기본 Kafka 토픽 설정 인터페이스interface KafkaTopicConfig {  topic: string;  ack: \"all\" | 1 | 0;  groupId: string;  fromBeginning: boolean;  schemaId: number;}// 각 토픽별 인터페이스 정의export const KafkaTopicsConfig: Record&lt;string, KafkaTopicConfig&gt; = {  MY_TOPIC: {    topic: \"my-topic\",    ack: \"all\", // 모든 복제본에 저장되어야 성공    groupId: \"group1\", // 그룹 ID 설정    fromBeginning: true, // 처음부터 데이터 수신    schemaId: 1 // Schema registry에서 가져온 schema ID  },  ANOTHER_TOPIC: {    topic: \"another-topic\",    ack: 1, // 최소 1개의 복제본에 저장되면 성공    groupId: \"group2\", // 그룹 ID 설정    fromBeginning: false, // 최신 메시지만 수신    schemaId: 2 // Schema registry에서 가져온 schema ID  }};2. 프로듀서 및 컨슈머 코드에서 인터페이스 적용이제 위에서 정의한 KafkaTopicsConfig 인터페이스를 사용하여 각 토픽에 대해 설정을 불러오도록 프로듀서와 컨슈머 코드를 작성합니다.프로듀서 코드sendMessage 메서드에서 KafkaTopicsConfig의 설정을 기반으로 각 토픽에 맞는 ACK 설정과 토픽 이름을 불러와 메시지를 전송합니다.// kafka-producer.service.tsimport { Inject, Injectable } from \"@nestjs/common\";import { Kafka, Producer, ProducerConfig } from \"kafkajs\";import { SchemaRegistry } from \"@kafkajs/confluent-schema-registry\";import { KafkaTopicsConfig } from \"./kafka-topics.interface\";@Injectable()export class KafkaProducerService {  private readonly producers: Record&lt;string, Producer&gt; = {};  constructor(    @Inject(\"KAFKA_CLIENT\") private readonly kafkaClient: Kafka,    @Inject(\"SCHEMA_REGISTRY\") private readonly schemaRegistry: SchemaRegistry  ) {}  // 토픽별 프로듀서 생성 함수  private async getProducer(    topicKey: keyof typeof KafkaTopicsConfig  ): Promise&lt;Producer&gt; {    const topicConfig = KafkaTopicsConfig[topicKey];    if (!this.producers[topicConfig.topic]) {      const producerConfig: ProducerConfig = { acks: topicConfig.ack };      const producer = this.kafkaClient.producer(producerConfig);      await producer.connect();      this.producers[topicConfig.topic] = producer;    }    return this.producers[topicConfig.topic];  }  // 메시지 전송 함수  async sendMessage(    topicKey: keyof typeof KafkaTopicsConfig,    key: string,    message: any  ) {    const topicConfig = KafkaTopicsConfig[topicKey];    const producer = await this.getProducer(topicKey);    const encodedMessage = await this.schemaRegistry.encode(      topicConfig.schemaId,      message    );    await producer.send({      topic: topicConfig.topic,      messages: [{ key, value: encodedMessage }]    });  }}사용 예시이제 sendMessage 메서드를 호출할 때, KafkaTopicsConfig 인터페이스에 정의된 설정을 토대로 토픽별로 다른 ACK 설정을 적용할 수 있습니다.await kafkaProducerService.sendMessage(\"MY_TOPIC\", \"key\", { data: \"example\" });await kafkaProducerService.sendMessage(\"ANOTHER_TOPIC\", \"key\", {  data: \"example\"});컨슈머 코드컨슈머 코드에서도 KafkaTopicsConfig의 설정을 기반으로 각 토픽에 대해 그룹 ID, 오프셋 관리 방식을 불러와 메시지를 처리합니다.// kafka-consumer.service.tsimport { Inject, Injectable, OnModuleInit } from \"@nestjs/common\";import { Kafka, Consumer, EachMessagePayload } from \"kafkajs\";import { SchemaRegistry } from \"@kafkajs/confluent-schema-registry\";import { KafkaTopicsConfig } from \"./kafka-topics.interface\";@Injectable()export class KafkaConsumerService implements OnModuleInit {  private consumers: Record&lt;string, Consumer&gt; = {};  constructor(    @Inject(\"KAFKA_CLIENT\") private readonly kafkaClient: Kafka,    @Inject(\"SCHEMA_REGISTRY\") private readonly schemaRegistry: SchemaRegistry  ) {}  // 토픽별 컨슈머 생성 함수  private async getConsumer(    topicKey: keyof typeof KafkaTopicsConfig  ): Promise&lt;Consumer&gt; {    const topicConfig = KafkaTopicsConfig[topicKey];    if (!this.consumers[topicConfig.topic]) {      const consumer = this.kafkaClient.consumer({        groupId: topicConfig.groupId,        autoCommit: true      });      await consumer.connect();      await consumer.subscribe({        topic: topicConfig.topic,        fromBeginning: topicConfig.fromBeginning      });      this.consumers[topicConfig.topic] = consumer;    }    return this.consumers[topicConfig.topic];  }  // 메시지 수신 및 오프셋 관리  async consumeMessages(topicKey: keyof typeof KafkaTopicsConfig) {    const topicConfig = KafkaTopicsConfig[topicKey];    const consumer = await this.getConsumer(topicKey);    await consumer.run({      eachMessage: async (payload: EachMessagePayload) =&gt; {        const { message } = payload;        const decodedMessage = await this.schemaRegistry.decode(message.value);        console.log(          `Received message from ${topicConfig.topic}:`,          decodedMessage        );        if (!topicConfig.fromBeginning) {          await this.handleManualCommit(payload);        }      }    });  }  // 수동 커밋 로직  private async handleManualCommit(payload: EachMessagePayload) {    const { topic, partition, message } = payload;    try {      console.log(\"Processing message:\", message.value.toString());      await this.consumers[topic].commitOffsets([        { topic, partition, offset: (parseInt(message.offset) + 1).toString() }      ]);    } catch (error) {      console.error(\"Failed to commit offset:\", error);    }  }}사용 예시consumeMessages 메서드를 호출할 때도 KafkaTopicsConfig 인터페이스에 정의된 설정을 토대로 각 토픽에 대한 그룹 ID와 오프셋 관리 방식을 적용할 수 있습니다.await kafkaConsumerService.consumeMessages(\"MY_TOPIC\");await kafkaConsumerService.consumeMessages(\"ANOTHER_TOPIC\");요약이 구성을 통해 NestJS 환경에서 Kafka를 유연하게 사용할 수 있습니다. 각 토픽에 대해 인터페이스 기반으로 ACK 설정, 그룹 ID, 오프셋 관리 방식을 관리하여 데이터 신뢰성을 보장하고 효율성을 높일 수 있습니다. 특히 메시지 정합성이 중요한 경우 수동 커밋과 fromBeginning 옵션을 통해 서버 중단 이후에도 데이터를 손실 없이 처리할 수 있도록 설계할 수 있습니다.이와 같은 인터페이스 기반 접근은 다양한 요구사항을 충족하면서도 간결하고 재사용 가능한 Kafka 설정을 제공합니다."
  },
  
  {
    "title": "카프카 기본이해",
    "url": "/posts/%EC%B9%B4%ED%94%84%EC%B9%B4-%EA%B8%B0%EB%B3%B8%EC%9D%B4%ED%95%B4/",
    "categories": "",
    "tags": "",
    "date": "2024-11-02 00:00:00 +0900",
    





    
    "snippet": "Kafka의 개념을 가장 높은 개념인 클러스터에서부터 가장 낮은 개념인 레코드 필드까지 차례로 설명하고, 메시지 전송 프로세스에 대한 설명을 블로그 글 형식으로 작성해보겠습니다.Kafka 클러스터│├── 브로커 1│ ├── 토픽 A│ │ ├── 파티션 1│ │ │ ├── 리더 (메시지 저장 및 관리)│ │ │ └── 팔로워 레플리카 (리더 복제)│ │...",
    "content": "Kafka의 개념을 가장 높은 개념인 클러스터에서부터 가장 낮은 개념인 레코드 필드까지 차례로 설명하고, 메시지 전송 프로세스에 대한 설명을 블로그 글 형식으로 작성해보겠습니다.Kafka 클러스터│├── 브로커 1│ ├── 토픽 A│ │ ├── 파티션 1│ │ │ ├── 리더 (메시지 저장 및 관리)│ │ │ └── 팔로워 레플리카 (리더 복제)│ │ └── 파티션 2│ │ ├── 리더 (메시지 저장 및 관리)│ │ └── 팔로워 레플리카 (리더 복제)│ └── 토픽 B│ ├── 파티션 1│ │ ├── 리더 (메시지 저장 및 관리)│ │ └── 팔로워 레플리카 (리더 복제)│ └── 파티션 2│ ├── 리더 (메시지 저장 및 관리)│ └── 팔로워 레플리카 (리더 복제)│├── 브로커 2│ ├── 토픽 A│ │ ├── 파티션 1│ │ │ ├── 리더 (메시지 저장 및 관리)│ │ │ └── 팔로워 레플리카 (리더 복제)│ │ └── 파티션 2│ │ ├── 리더 (메시지 저장 및 관리)│ │ └── 팔로워 레플리카 (리더 복제)│ └── 토픽 B│ ├── 파티션 1│ │ ├── 리더 (메시지 저장 및 관리)│ │ └── 팔로워 레플리카 (리더 복제)│ └── 파티션 2│ ├── 리더 (메시지 저장 및 관리)│ └── 팔로워 레플리카 (리더 복제)│└── 브로커 3├── 토픽 A│ ├── 파티션 1│ │ ├── 리더 (메시지 저장 및 관리)│ │ └── 팔로워 레플리카 (리더 복제)│ └── 파티션 2│ ├── 리더 (메시지 저장 및 관리)│ └── 팔로워 레플리카 (리더 복제)└── 토픽 B├── 파티션 1│ ├── 리더 (메시지 저장 및 관리)│ └── 팔로워 레플리카 (리더 복제)└── 파티션 2├── 리더 (메시지 저장 및 관리)└── 팔로워 레플리카 (리더 복제)---Kafka 메시지 구조│├── 레코드 배치 (Record Batch)│ ├── 레코드 1 (Record)│ │ ├── 키 (Key) - 파티션 할당에 사용됨│ │ ├── 값 (Value) - 메시지 내용│ │ ├── 타임스탬프 (Timestamp) - 메시지 생성 또는 기록 시간│ │ └── 헤더 (Header) - 추가 메타데이터 (키-값 쌍)│ ├── 레코드 2 (Record)│ │ ├── 키 (Key) - 파티션 할당에 사용됨│ │ ├── 값 (Value) - 메시지 내용│ │ ├── 타임스탬프 (Timestamp) - 메시지 생성 또는 기록 시간│ │ └── 헤더 (Header) - 추가 메타데이터 (키-값 쌍)│ └── ...│└── 레코드 N (Record)├── 키 (Key) - 파티션 할당에 사용됨├── 값 (Value) - 메시지 내용├── 타임스탬프 (Timestamp) - 메시지 생성 또는 기록 시간└── 헤더 (Header) - 추가 메타데이터 (키-값 쌍)---Kafka 클러스터 구조와 메시지 전송 프로세스Apache Kafka는 대규모 데이터 스트림을 처리하기 위한 분산 메시징 시스템으로, 데이터의 일관성과 내구성을 보장하면서도 높은 처리 성능을 제공합니다. Kafka의 구조는 크게 클러스터부터 시작하여 가장 작은 단위인 레코드의 필드까지 다양한 구성 요소로 이루어져 있으며, 이 구조가 데이터 전송 및 관리에 중요한 역할을 합니다.1. Kafka 클러스터 (Kafka Cluster)Kafka 클러스터는 Kafka 시스템의 최상위 개념으로, 여러 개의 브로커(Broker)가 모여 구성된 서버 집합입니다. 클러스터는 분산된 데이터 저장 및 관리 시스템을 제공하며, 고가용성과 내구성을 보장합니다. 각 브로커는 특정 데이터를 저장하고, 클러스터 내에서 데이터가 적절히 분산될 수 있도록 관리됩니다. 이로 인해 Kafka 클러스터는 대규모 데이터의 안정적인 저장과 빠른 전송을 지원합니다.2. 브로커 (Broker)브로커는 Kafka 클러스터를 구성하는 개별 서버로, 데이터 저장과 전송 요청을 처리합니다. 각 브로커는 하나 이상의 토픽과 파티션을 관리하고, 다른 브로커와 협력하여 데이터 분산 처리와 중복 저장을 담당합니다. Kafka 클러스터 내에서는 여러 브로커가 역할을 분담하며, 각 브로커가 처리하는 데이터를 고르게 분산하여 대용량 데이터를 효율적으로 처리합니다.3. 토픽 (Topic)토픽은 Kafka에서 데이터가 저장되는 논리적인 구분 단위입니다. 애플리케이션이 특정 주제의 데이터를 전송하거나 구독할 수 있도록 도와주며, 같은 종류의 데이터를 담는 컨테이너 역할을 합니다. 예를 들어, user_activity 토픽은 사용자 활동 로그를 저장하고, order_data 토픽은 주문 정보를 저장할 수 있습니다. 토픽은 여러 개의 파티션으로 나누어져 데이터가 병렬로 저장되고, 병렬 처리가 가능합니다.4. 파티션 (Partition)파티션은 각 토픽을 물리적으로 분할한 단위로, 데이터의 병렬 처리와 확장성을 높이는 역할을 합니다. Kafka는 파티션 단위로 데이터를 저장하며, 각 파티션 내에서는 메시지 순서가 보장됩니다. 이를 통해 여러 개의 컨슈머가 하나의 토픽을 병렬로 처리할 수 있습니다. 또한, 파티션은 장애 발생 시에도 데이터를 안전하게 복구할 수 있도록 리더-팔로워 구조로 구성됩니다.5. 리더와 팔로워 레플리카 (Leader and Follower Replica)Kafka의 각 파티션은 리더와 하나 이상의 팔로워 레플리카로 구성됩니다. 리더는 파티션의 주 인스턴스로, 모든 읽기와 쓰기 요청을 처리합니다. 반면, 팔로워 레플리카는 리더의 데이터를 복제하여 보관하며, 리더가 장애가 발생할 경우 팔로워 중 하나가 리더로 승격됩니다. 이를 통해 Kafka는 데이터의 내구성과 고가용성을 보장할 수 있습니다.6. 메시지 (Message)메시지는 Kafka를 통해 애플리케이션 간에 전송되는 데이터의 기본 단위입니다. 일반적으로 메시지는 레코드(Record)라고도 하며, 이 레코드가 여러 개 모여 레코드 배치(Record Batch)로 전송됩니다. 메시지는 데이터 전송의 실질적인 내용을 담고 있으며, 레코드 배치로 묶여 브로커에 효율적으로 전달됩니다.7. 레코드 배치 (Record Batch)레코드 배치는 여러 개의 레코드를 묶어 전송하는 단위로, Kafka는 네트워크 성능을 최적화하기 위해 데이터를 배치로 묶어 전송합니다. 레코드 배치는 압축 및 일괄 처리가 가능하여 대규모 데이터를 효율적으로 처리할 수 있습니다.8. 레코드 (Record)Kafka의 레코드는 메시지의 실제 데이터 단위로, 키(Key), 값(Value), 타임스탬프(Timestamp), 헤더(Header) 등의 필드를 포함합니다. 각 레코드는 파티션 내에서 고유한 오프셋(Offset)을 가지며, 이 오프셋을 기준으로 순차적으로 읽거나 처리할 수 있습니다.9. 레코드 필드 (Record Fields)  키 (Key): 메시지를 특정 파티션에 할당할 때 사용되는 필드로, 같은 키를 가진 메시지는 동일한 파티션에 저장됩니다.  값 (Value): 실제 메시지 내용이 담긴 필드로, 애플리케이션 간의 전송 데이터 본문에 해당합니다.  타임스탬프 (Timestamp): 메시지가 생성되거나 Kafka에 기록된 시간을 나타내며, 메시지의 순서나 재처리 시점을 추적할 수 있습니다.  헤더 (Header): 추가적인 메타데이터를 포함하는 필드로, 키-값 형태의 데이터를 담아 메시지 처리 로직에 도움을 줄 수 있습니다.Kafka 메시지 전송 프로세스Kafka의 메시지 전송은 다음과 같은 순서로 이루어집니다:      프로듀서가 메시지를 생성: 프로듀서 애플리케이션은 메시지(레코드)를 생성하며, 각 메시지에는 키, 값, 타임스탬프, 헤더와 같은 정보가 포함될 수 있습니다.        레코드 배치로 묶어 전송: 프로듀서는 여러 개의 메시지를 레코드 배치로 묶어 브로커로 전송합니다. 이 배치 전송 방식은 성능을 최적화하고 네트워크 비용을 절감하는 데 도움을 줍니다.        리더에게 전송: 프로듀서는 특정 파티션의 리더에게 배치를 전송합니다. Kafka는 메시지의 키 또는 라운드 로빈 방식으로 파티션을 결정하며, 리더는 이 데이터를 저장하고 관리합니다.        팔로워 레플리카로 복제: 리더가 데이터를 수신한 후, 이를 동일한 파티션의 팔로워 레플리카에 복제합니다. 이로 인해 데이터의 내구성이 보장되고, 장애 발생 시에도 데이터 손실을 최소화할 수 있습니다.        컨슈머가 리더로부터 메시지를 읽음: Kafka의 컨슈머 애플리케이션은 파티션 내의 리더에서 데이터를 읽으며, 오프셋을 통해 데이터를 순차적으로 처리할 수 있습니다. Kafka는 각 컨슈머의 오프셋을 추적하여 중단된 지점에서 다시 읽을 수 있도록 지원합니다.  이와 같은 전송 구조 덕분에 Kafka는 고성능, 고가용성, 데이터 내구성을 동시에 유지하며 대규모 데이터 스트림을 안정적으로 처리할 수 있습니다."
  },
  
  {
    "title": "차기 추천시스템도입 아키텍쳐 기초",
    "url": "/posts/%EC%B0%A8%EA%B8%B0-%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C%EB%8F%84%EC%9E%85-%EC%95%84%ED%82%A4%ED%85%8D%EC%B3%90-%EA%B8%B0%EC%B4%88/",
    "categories": "",
    "tags": "",
    "date": "2024-11-02 00:00:00 +0900",
    





    
    "snippet": "아래는 Redis, Kafka, Hive, Spark, 딥러닝 모델을 연동하여 실시간으로 추천 시스템을 개선하는 구조에 대한 설계입니다. 이 아키텍처는 유튜버가 제시한 구성과 유사하게 작동하면서, 사용자 피드백을 반영해 추천 모델을 실시간으로 개선하고 최적화하는 것을 목표로 합니다.1. 시스템 아키텍처 개요  Redis: 추천 피드를 구역화하고 빠른 ...",
    "content": "아래는 Redis, Kafka, Hive, Spark, 딥러닝 모델을 연동하여 실시간으로 추천 시스템을 개선하는 구조에 대한 설계입니다. 이 아키텍처는 유튜버가 제시한 구성과 유사하게 작동하면서, 사용자 피드백을 반영해 추천 모델을 실시간으로 개선하고 최적화하는 것을 목표로 합니다.1. 시스템 아키텍처 개요  Redis: 추천 피드를 구역화하고 빠른 접근을 제공합니다. 예를 들어, 사용자 성별, 관심 키워드, 연령대를 기반으로 분류된 데이터를 Redis에 저장하여, 요청 시 빠르게 추천 피드를 제공합니다.      Kafka: 실시간 데이터 수집 및 피드백 전달을 담당합니다. 사용자가 추천 피드에서 특정 링크를 클릭하거나 페이지에서 일정 시간 이상 머무르면 이를 이벤트로 Kafka에 전송하여 실시간 피드백으로 활용합니다.        Spark + 딥러닝 모델: Spark는 실시간 스트리밍 처리를 통해 Redis와 Kafka에서 수집된 데이터를 기반으로 추천 모델을 추론하고, 새로운 사용자 행동에 따라 추천 모델을 업데이트하는 역할을 합니다. Spark MLlib이나 PyTorch, TensorFlow와 연동해 사용자 맞춤형 추천 알고리즘을 제공합니다.    Hive (Hadoop): 장기적으로 모든 사용자 피드백 데이터를 저장하며, 주기적으로 Spark와 연동하여 모델을 재학습시키는 데 사용합니다. 이로 인해 장기적인 성능 향상을 도모합니다.2. 추천 시스템 흐름A. 추천 피드 생성 및 제공  사용자 프로필 기반 구역화 (Redis): 성별, 연령, 관심 키워드 등을 기반으로 구역화된 추천 피드를 Redis에 저장합니다. 이를 통해 사용자가 웹사이트나 앱에 접속할 때 Redis에서 즉각적으로 맞춤형 추천 피드를 제공합니다.  딥러닝 모델 기반 추천 생성 (Spark): Spark는 Redis에서 가져온 사용자 데이터를 바탕으로 추천 모델을 통해 실시간으로 새로운 추천 항목을 생성합니다. 이를 통해 Redis 캐시의 데이터를 보완하고 실시간으로 업데이트된 추천을 제공합니다.B. 사용자 피드백 수집 및 분석  실시간 피드백 수집 (Kafka): 사용자가 특정 추천 링크를 클릭하거나 평균 이상 머무르면, 해당 행동 데이터를 Kafka에 이벤트로 저장합니다. 이를 통해 사용자의 관심 정도와 추천 모델의 유효성을 확인할 수 있습니다.  피드백 분석 및 전처리 (Spark): Kafka에 수집된 피드백 데이터를 Spark가 실시간으로 수신하여 유효한 행동(예: 링크 클릭, 장시간 머무름 등)을 선별합니다. 이 데이터를 분석해 추천 알고리즘의 효율성을 평가하고, 즉각적으로 개선 포인트를 확인할 수 있습니다.C. 추천 모델 업데이트 및 튜닝  Hive에 피드백 저장: 모든 피드백 데이터는 Hive에 장기 저장되어, 이후 배치 학습에 활용됩니다. 예를 들어, 하루에 한 번씩 추천 모델이 전체 피드백 데이터를 학습하여 장기적인 성능을 개선할 수 있습니다.  모델 튜닝 및 실시간 재학습 (Spark + 딥러닝 모델): 실시간으로 수집된 피드백을 기반으로 Spark에서 딥러닝 모델을 재훈련하거나 파라미터를 조정합니다. 이로 인해 추천 모델이 지속적으로 사용자 행동에 맞춰 튜닝됩니다. 특정 기준(예: 평균 이상 머무는 시간)이 충족될 때마다 모델을 업데이트할 수 있습니다.D. 실시간 추천 제공  향상된 추천 모델 배포: Spark에서 재학습된 모델을 기반으로 Redis의 추천 피드를 업데이트하여 사용자에게 더욱 맞춤화된 추천을 실시간으로 제공합니다.  Kafka를 통한 실시간 모델 개선: 새로운 사용자 행동에 대해 수집된 피드백이 Kafka를 통해 지속적으로 전달되며, 모델을 더욱 고도화합니다.3. 주요 고려 사항 및 최적화 포인트  Redis를 이용한 캐싱: Redis에 사용자 프로필에 맞는 추천 데이터를 캐싱하여, 요청 시 빠르게 추천 피드를 제공함으로써 지연을 최소화합니다.  Spark와 딥러닝 모델의 결합: Spark Streaming을 통해 실시간 데이터를 처리하고, 딥러닝 모델과 연동해 추천 모델이 최신 사용자 행동을 반영할 수 있도록 설계합니다. Spark의 MLlib이나 외부 딥러닝 라이브러리(PyTorch, TensorFlow 등)를 사용해 유연성을 높일 수 있습니다.  Kafka의 피드백 루프 강화: Kafka를 통해 실시간으로 수집된 피드백을 이용해 추천 모델을 지속적으로 튜닝합니다. 이를 통해 사용자의 행동 변화에 신속하게 반응할 수 있습니다.이 설계를 통해 추천 시스템은 실시간 피드백을 반영해 개인화된 추천 모델을 지속적으로 개선하며, 사용자에게 맞춤형 추천을 제공합니다. Redis를 통해 빠르게 구역화된 피드를 제공하고, Kafka와 Spark가 실시간으로 사용자 피드백을 반영해 추천 모델을 개선함으로써 초개인화된 추천 시스템을 구축할 수 있습니다."
  },
  
  {
    "title": "Nestjs에서 kafka와 avro를 이용한 데이터 스트리밍 구축하기",
    "url": "/posts/NestJS%EC%97%90%EC%84%9C-Kafka%EC%99%80-Avro%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8A%A4%ED%8A%B8%EB%A6%AC%EB%B0%8D-%EA%B5%AC%EC%B6%95%ED%95%98%EA%B8%B0/",
    "categories": "",
    "tags": "",
    "date": "2024-11-02 00:00:00 +0900",
    





    
    "snippet": "NestJS에서 Kafka와 Avro를 이용한 데이터 스트리밍 구축하기데이터가 분산되고 실시간으로 처리가 필요한 시스템에서 Kafka와 Avro를 결합해 메시징 시스템을 구축하는 것은 효율적이고 확장 가능한 선택입니다. 이 글에서는 NestJS와 Kafka, 그리고 Confluent Schema Registry를 사용하여 Avro 직렬화를 구현하고, ...",
    "content": "NestJS에서 Kafka와 Avro를 이용한 데이터 스트리밍 구축하기데이터가 분산되고 실시간으로 처리가 필요한 시스템에서 Kafka와 Avro를 결합해 메시징 시스템을 구축하는 것은 효율적이고 확장 가능한 선택입니다. 이 글에서는 NestJS와 Kafka, 그리고 Confluent Schema Registry를 사용하여 Avro 직렬화를 구현하고, 이를 통해 다양한 데이터 구조를 안전하고 일관되게 처리하는 방법을 설명합니다.NestJS는 직관적인 구조와 모듈화를 지원하는 Node.js 프레임워크로, Kafka와 결합하여 데이터 스트리밍 시스템을 쉽게 확장할 수 있습니다. Schema Registry를 통해 Avro 스키마를 중앙에서 관리하고, 다양한 데이터 형식을 다루는 사례들을 소개합니다.1. 왜 Avro인가?Kafka는 JSON, XML 등 다양한 포맷을 지원하지만, Avro는 빠르고, 바이너리 포맷으로 크기가 작아 네트워크 효율성이 높습니다. 또한, 스키마 기반으로 직렬화되므로 데이터 일관성을 보장합니다. Confluent Schema Registry와 함께 Avro를 사용하면 각 메시지가 동일한 스키마를 따르도록 관리하고, 변경이 필요할 때에도 기존 데이터를 안전하게 호환할 수 있습니다.2. 시스템 구성 요소아래의 세 가지 서비스가 주요 구성 요소입니다.  SchemaRegistryService: Avro 스키마를 관리하고, 데이터 직렬화와 역직렬화를 담당합니다.  KafkaProducerService: Avro로 직렬화된 데이터를 Kafka로 전송하는 역할을 합니다.  KafkaConsumerService: Kafka에서 데이터를 수신하고, 역직렬화하여 데이터를 처리합니다.3. 다양한 Avro 스키마 정의 예시사용자 등록 정보 (User Registration)사용자 정보에는 필수 데이터(이메일, 비밀번호 등)와 선택적 데이터(프로필)가 포함됩니다. 아래는 해당 데이터를 정의한 Avro 스키마입니다.{  \"type\": \"record\",  \"name\": \"UserRegistration\",  \"fields\": [    { \"name\": \"userId\", \"type\": \"string\" },    { \"name\": \"email\", \"type\": \"string\" },    { \"name\": \"password\", \"type\": \"string\" },    { \"name\": \"createdAt\", \"type\": \"long\" },    {      \"name\": \"profile\",      \"type\": [        \"null\",        {          \"type\": \"record\",          \"name\": \"UserProfile\",          \"fields\": [            { \"name\": \"firstName\", \"type\": \"string\" },            { \"name\": \"lastName\", \"type\": \"string\" },            { \"name\": \"age\", \"type\": [\"null\", \"int\"], \"default\": null },            { \"name\": \"address\", \"type\": [\"null\", \"string\"], \"default\": null }          ]        }      ],      \"default\": null    }  ]}주문 데이터 (Order Data)주문 데이터는 사용자 ID, 주문 날짜, 제품 목록을 포함하며, 각 제품에는 상품 ID, 이름, 수량, 가격이 포함됩니다.{  \"type\": \"record\",  \"name\": \"Order\",  \"fields\": [    { \"name\": \"orderId\", \"type\": \"string\" },    { \"name\": \"userId\", \"type\": \"string\" },    { \"name\": \"orderDate\", \"type\": \"long\" },    {      \"name\": \"products\",      \"type\": {        \"type\": \"array\",        \"items\": {          \"type\": \"record\",          \"name\": \"Product\",          \"fields\": [            { \"name\": \"productId\", \"type\": \"string\" },            { \"name\": \"productName\", \"type\": \"string\" },            { \"name\": \"quantity\", \"type\": \"int\" },            { \"name\": \"price\", \"type\": \"double\" }          ]        }      }    },    { \"name\": \"totalAmount\", \"type\": \"double\" }  ]}센서 데이터 (Sensor Data)실시간으로 전송되는 센서 데이터는 센서 ID, 측정 시간, 온도와 습도를 포함하며, 센서 상태는 NORMAL, WARNING, CRITICAL로 구분됩니다.{  \"type\": \"record\",  \"name\": \"SensorData\",  \"fields\": [    { \"name\": \"sensorId\", \"type\": \"string\" },    { \"name\": \"timestamp\", \"type\": \"long\" },    { \"name\": \"temperature\", \"type\": [\"null\", \"float\"], \"default\": null },    { \"name\": \"humidity\", \"type\": [\"null\", \"float\"], \"default\": null },    {      \"name\": \"status\",      \"type\": {        \"type\": \"enum\",        \"name\": \"SensorStatus\",        \"symbols\": [\"NORMAL\", \"WARNING\", \"CRITICAL\"]      }    }  ]}4. SchemaRegistryService 구현Schema Registry를 통해 Avro 스키마를 관리하는 서비스를 생성합니다.// schema-registry.service.tsimport { Injectable, Logger } from \"@nestjs/common\";import { SchemaRegistry } from \"@kafkajs/confluent-schema-registry\";@Injectable()export class SchemaRegistryService {  private registry: SchemaRegistry;  private readonly logger = new Logger(SchemaRegistryService.name);  constructor() {    this.registry = new SchemaRegistry({ host: \"http://localhost:8081\" });  }  async encode(data: any, subject: string) {    try {      const { id } = await this.registry.getLatestSchemaId(subject);      return await this.registry.encode(id, data);    } catch (error) {      this.logger.error(`Encoding failed: ${error.message}`);      throw error;    }  }  async decode(encodedData: Buffer) {    try {      return await this.registry.decode(encodedData);    } catch (error) {      this.logger.error(`Decoding failed: ${error.message}`);      throw error;    }  }}5. Kafka Producer 구현아래는 사용자 등록 정보를 Kafka 주제(user-registration)로 전송하는 예제입니다. KafkaProducerService는 데이터를 직렬화한 후 전송합니다.// kafka-producer.service.tsimport { Injectable, Logger } from \"@nestjs/common\";import { ClientKafka } from \"@nestjs/microservices\";import { SchemaRegistryService } from \"./schema-registry.service\";@Injectable()export class KafkaProducerService {  private readonly logger = new Logger(KafkaProducerService.name);  constructor(    private readonly kafkaClient: ClientKafka,    private readonly schemaRegistryService: SchemaRegistryService  ) {}  async sendUserRegistration(topic: string, data: any) {    try {      const serializedData = await this.schemaRegistryService.encode(        data,        \"UserRegistration-value\"      );      await this.kafkaClient.emit(topic, { value: serializedData });      this.logger.log(`User registration data sent to topic ${topic}`);    } catch (error) {      this.logger.error(`Failed to send data: ${error.message}`);      throw error;    }  }}6. Kafka Consumer 구현Kafka로부터 user-registration 주제를 구독하여 데이터를 수신하고, Avro를 통해 역직렬화하여 처리합니다.// kafka-consumer.service.tsimport { Injectable, OnModuleInit, Logger } from \"@nestjs/common\";import { Consumer, Kafka } from \"kafkajs\";import { SchemaRegistryService } from \"./schema-registry.service\";@Injectable()export class KafkaConsumerService implements OnModuleInit {  private readonly logger = new Logger(KafkaConsumerService.name);  private consumer: Consumer;  constructor(private readonly schemaRegistryService: SchemaRegistryService) {    const kafka = new Kafka({ brokers: [\"localhost:9092\"] });    this.consumer = kafka.consumer({ groupId: \"user-group\" });  }  async onModuleInit() {    await this.consumer.connect();    await this.consumer.subscribe({      topic: \"user-registration\",      fromBeginning: true    });    await this.consumer.run({      eachMessage: async ({ message }) =&gt; {        try {          const decodedData = await this.schemaRegistryService.decode(            message.value          );          this.logger.log(            `Received user registration data: ${JSON.stringify(decodedData)}`          );          this.processUserRegistration(decodedData);        } catch (error) {          this.logger.error(`Failed to process message: ${error.message}`);        }      }    });  }  processUserRegistration(userData: any) {    this.logger.log(      `Processing user registration: ${JSON.stringify(userData)}`    );  }}7. 모듈 구성마지막으로 Kafka 클라이언트를 NestJS 모듈에 설정하고, 프로듀서와 컨슈머를 모듈로 구성합니다.// app.module.tsimport { Module } from '@nestjs/common';import { ClientsModule, Transport } from '@nestjs/microservices';import { KafkaProducerService } from './kafka-producer.service';import { KafkaConsumerService } from './kafka-consumer.service';import { SchemaRegistryService } from './schema-registry.service';@Module({  imports: [    ClientsModule.register([      {        name: 'KAFKA_SERVICE',        transport: Transport.KAFKA,        options: {          client: {            brokers: ['localhost:9092'],          },          consumer: {            groupId: 'user-group',          },        },      },    ]),  ],  providers: [KafkaProducerService, KafkaConsumerService, SchemaRegistryService],})export class AppModule {}NestJS에서 Kafka와 Avro를 사용해 데이터 스트리밍 시스템을 구축하는 방법을 살펴보았습니다. Schema Registry를 이용해 다양한 데이터를 일관된 스키마로 관리하고, Kafka를 통해 실시간으로 데이터를 전송, 수신하는 시스템을 구현할 수 있습니다.각 acks 옵션에 따른 플로우차트를 Markdown의 Mermaid 형식으로 도식화해 보겠습니다."
  },
  
  {
    "title": "Docker Compose 만으로는 안되는것을 느낀하루",
    "url": "/posts/docker-compose-%EB%A7%8C%EC%9C%BC%EB%A1%9C%EB%8A%94-%EC%95%88%EB%90%98%EB%8A%94%EA%B2%83%EC%9D%84-%EB%8A%90%EB%82%80%ED%95%98%EB%A3%A8/",
    "categories": "",
    "tags": "",
    "date": "2024-10-29 00:00:00 +0900",
    





    
    "snippet": "Docker Compose의 한계와 Kubernetes의 필요성: 실제 경험을 통해 얻은 교훈들어가며개발 초기 단계에서 Docker Compose는 여러 컨테이너를 손쉽게 관리할 수 있는 훌륭한 도구입니다. 그러나 프로젝트의 규모가 커지고, 서비스 간 의존성이 복잡해지면 Docker Compose만으로는 그 한계에 부딪히게 됩니다. 이번 글에서는 제가...",
    "content": "Docker Compose의 한계와 Kubernetes의 필요성: 실제 경험을 통해 얻은 교훈들어가며개발 초기 단계에서 Docker Compose는 여러 컨테이너를 손쉽게 관리할 수 있는 훌륭한 도구입니다. 그러나 프로젝트의 규모가 커지고, 서비스 간 의존성이 복잡해지면 Docker Compose만으로는 그 한계에 부딪히게 됩니다. 이번 글에서는 제가 실제로 겪은 Docker Compose의 복잡성 문제와 Kubernetes로 전환하게 된 이유를 공유하고자 합니다.Docker Compose로 구성한 복잡한 서비스들프로젝트에서는 다음과 같은 다양한 서비스를 Docker Compose로 관리하고 있었습니다:  서비스 레이어: backend, mysql  메시지 브로커 레이어: kafka, zookeeper  인메모리 캐싱 DB 레이어: redis  로깅 레이어: ELK 스택 (elasticsearch, logstash, kibana)  CI/CD 레이어: jenkins아래는 이 모든 서비스를 하나의 docker-compose.yml 파일로 구성한 전체 코드입니다.version: \"3.8\"services:  backend:    build:      context: ../backend      dockerfile: ../docker/dockerfiles/dockerfile.backend    container_name: ${DOMAIN_NAME}_backend    ports:      - \"7778:7778\"    environment:      - DB_HOST=mysql # mysql 컨테이너 이름      - DB_PORT=3306      - DB_USER=${DB_USER}      - DB_PASSWORD=${DB_PASSWORD}      - DB_NAME=${DB_NAME}      - IS_DEV=${IS_DEV}      - JWT_SECRET=${JWT_SECRET}      - BACKEND_PORT=${BACKEND_PORT}      - REDIS_HOST=redis      - REDIS_PORT=6379    depends_on:      mysql:        condition: service_healthy      redis:        condition: service_healthy    networks:      - mynetwork    restart: always  mysql:    build:      context: ./      dockerfile: ./dockerfiles/dockerfile.mysql    container_name: ${DOMAIN_NAME}_mysql    environment:      - MYSQL_ROOT_PASSWORD=${DB_PASSWORD}      - MYSQL_DATABASE=${DB_NAME}    ports:      - \"6654:3306\"    volumes:      - db_starter_data:/var/lib/mysql      - ./mysql/my.cnf:/etc/mysql/my.cnf      - ./mysql/init.sql:/docker-entrypoint-initdb.d/init.sql    healthcheck:      test:        [          \"CMD-SHELL\",          \"mysqladmin ping -h mysql -u root -p${MYSQL_ROOT_PASSWORD} || exit 1\"        ]      interval: 30s      timeout: 10s      retries: 5      start_period: 40s    networks:      - mynetwork  elasticsearch:    image: docker.elastic.co/elasticsearch/elasticsearch:8.9.0    container_name: ${DOMAIN_NAME}_elasticsearch    environment:      - discovery.type=single-node      - xpack.security.enabled=false    ports:      - \"9200:9200\"    networks:      - mynetwork    volumes:      - es_starter_data:/usr/share/elasticsearch/data  logstash:    image: docker.elastic.co/logstash/logstash:8.9.0    container_name: ${DOMAIN_NAME}_logstash    ports:      - \"5044:5044\"    volumes:      - ./elk/logstash.conf:/usr/share/logstash/pipeline/logstash.conf      - ./elk/pipelines.yml:/usr/share/logstash/config/pipelines.yml    networks:      - mynetwork    depends_on:      - elasticsearch  kibana:    image: docker.elastic.co/kibana/kibana:8.9.0    container_name: ${DOMAIN_NAME}_kibana    ports:      - \"5601:5601\"    environment:      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200      - xpack.security.enabled=false    networks:      - mynetwork    depends_on:      - elasticsearch  jenkins:    image: jenkins/jenkins:lts    container_name: ${DOMAIN_NAME}_jenkins    ports:      - \"8080:8080\"      - \"50000:50000\"    volumes:      - ./jenkins_starter_home:/var/jenkins_home    networks:      - mynetwork    environment:      - JAVA_OPTS=-Djenkins.install.runSetupWizard=false    restart: always    depends_on:      - mysql      - elasticsearch  zookeeper:    image: confluentinc/cp-zookeeper:latest    container_name: ${DOMAIN_NAME}_zookeeper    ports:      - \"2181:2181\"    environment:      - ZOOKEEPER_CLIENT_PORT=2181    networks:      - mynetwork    restart: always  kafka:    image: wurstmeister/kafka:latest    container_name: ${DOMAIN_NAME}_kafka    ports:      - \"9092:9092\"    environment:      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092    depends_on:      - zookeeper    networks:      - mynetwork    restart: always  redis:    image: redis:latest    container_name: ${DOMAIN_NAME}_redis    ports:      - \"6379:6379\"    networks:      - mynetwork    healthcheck:      test: [\"CMD\", \"redis-cli\", \"ping\"]      interval: 30s      timeout: 10s      retries: 5      start_period: 10s    restart: alwaysvolumes:  db_starter_data:  es_starter_data:  jenkins_starter_home:networks:  mynetwork:    driver: bridgeDocker Compose의 한계1. 네트워크 구성의 복잡성 증가다양한 클러스터링 환경에서의 어려움5개의 레이어로 나누어 각 Compose 파일을 구성하는 작업은 처음에는 논리적이고 명확해 보였습니다. 그러나 각 레이어가 서로 다른 로컬 머신에 배포되거나, 한 머신 내에서 여러 레이어가 결합된 형태로 구성될 때 네트워크와 의존성 관리에 큰 어려움이 생겼습니다.  로컬 호스트 간 네트워크: 같은 로컬 호스트에서 여러 레이어가 존재할 경우에는 bridge 네트워크를 통해 통신하도록 설정하면 됩니다. 그러나 서로 다른 호스트 머신에 각 레이어가 분리될 경우에는 외부 네트워크를 통해 통신해야 하므로 네트워크 설정이 복잡해졌습니다.  내부 통신과 외부 통신 간 전환의 어려움: 동일한 호스트에서 실행될 때는 내부 네트워크(shared network)를 사용하여 효율적인 통신이 가능하지만, 여러 호스트에 걸쳐 있는 경우에는 외부 네트워크 통신으로 전환이 필요합니다. 이 과정에서 네트워크 설정을 유연하게 유지하기 어려웠습니다.2. 환경별 네트워크 구성의 불일치각 환경마다 네트워크 구성이 다르기 때문에 Compose 파일을 일관되게 유지하기 어려웠습니다. 예를 들어, 로컬 개발 환경에서는 모든 레이어를 하나의 머신에 올려도 문제가 없었지만, 프로덕션 환경에서는 레이어별로 여러 서버에 분산 배치해야 했습니다.  공유 네트워크 설정의 어려움: Docker Compose에서는 네트워크 이름을 외부에서 생성하고 이를 공유하도록 설정해야 합니다. 그러나 네트워크 이름을 환경 변수로 설정하는 것이 불가능하여 각 환경에 맞춰 파일을 수동으로 수정해야 했습니다.  서비스 설정의 복잡성 증가: 각 환경마다 서비스가 통신할 호스트나 포트가 달라 이를 관리하기 위한 추가적인 스크립트나 설정이 필요했습니다.3. 서비스 의존성 관리의 복잡성depends_on 옵션을 통해 서비스 간의 의존성을 명시할 수 있었지만, 여러 Compose 파일로 분리되면서 서로 다른 Compose 파일에 정의된 서비스 간의 의존성을 관리하기가 어려워졌습니다. 특히 클러스터 내 여러 호스트에서 각 레이어가 분리되어 실행될 때 의존성 상태를 일관성 있게 관리하는 것이 매우 복잡해졌습니다.4. 서비스별 스케일링의 한계Docker Compose는 여러 서비스를 쉽게 관리할 수 있지만, 특정 서비스에만 부하가 집중될 때 해당 서비스의 클러스터 가용성을 늘리는 데에는 한계가 있습니다.  개별 서비스의 스케일링 어려움: Docker Compose에서는 docker-compose up --scale 명령어를 통해 서비스의 컨테이너 수를 늘릴 수 있지만, 이는 단순히 컨테이너 수를 늘리는 것에 불과합니다. 부하 분산이나 서비스 디스커버리와 같은 고급 기능을 제공하지 않아, 추가적인 설정이 필요합니다.  자동화된 스케일링 미지원: 부하에 따라 자동으로 스케일링하는 기능이 없어, 수동으로 컨테이너 수를 조절해야 하는 불편함이 있습니다.5. 부분적인 가용성 향상의 어려움다수의 서비스 중 일부 서비스만 가용성을 늘리고자 할 때, Docker Compose는 이에 대한 유연한 대처가 어렵습니다.  의존성 관리의 복잡성: 특정 서비스만 스케일링하면, 해당 서비스와 연관된 다른 서비스들의 설정도 함께 변경해야 할 수 있어 관리가 복잡해집니다.  서비스 간 영향: 하나의 Compose 파일 내에서 서비스들이 밀접하게 연결되어 있어, 일부 서비스를 변경하는 것이 다른 서비스에 영향을 줄 수 있습니다.6. 네트워크 전환 및 로드밸런싱의 어려움다중 클러스터링 환경에서 로컬 머신에 여러 컨테이너를 두고 공유 네트워크로 관리하고 싶을 때, 내부 네트워크의 컨테이너들이 트래픽 과부하에 시달린다면 외부 네트워크로 자연스럽게 전환하여 로드밸런싱을 하고자 합니다. 그러나 Docker Compose에서는 이러한 전략을 구현하기가 어렵습니다.  동적인 네트워크 설정의 부재: Docker Compose는 정적인 네트워크 설정만을 지원하며, 트래픽 상황에 따라 네트워크 구성을 동적으로 변경하는 기능이 없습니다.  로드밸런싱 기능의 한계: 기본적으로 로드밸런싱을 지원하지 않아, 외부 도구나 추가적인 설정이 필요합니다.Kubernetes의 필요성 인식이러한 문제들을 해결하기 위해 Kubernetes를 도입하게 되었습니다. Kubernetes는 복잡한 마이크로서비스 아키텍처를 관리하고 확장할 수 있는 강력한 기능을 제공합니다.Kubernetes의 주요 이점1. 유연한 네트워킹  자동화된 네트워크 구성: Kubernetes에서는 모든 파드가 클러스터 내에서 일관된 네트워크를 공유하므로, 서비스 간 통신을 위해 별도의 네트워크 설정이 필요하지 않습니다.  서비스 디스커버리: Kubernetes의 Service 리소스를 통해 동적으로 생성되는 파드의 IP를 추적하지 않고도 안정적인 서비스 엔드포인트를 제공합니다.2. 환경별 일관성 제공  매니페스트 파일 관리: YAML 매니페스트 파일을 통해 환경에 관계없이 동일한 설정으로 배포가 가능합니다.  ConfigMap과 Secret: 환경별 설정 값을 관리하기 용이하며, 이는 환경 변수로 쉽게 주입할 수 있습니다.3. 자동화된 의존성 및 상태 관리  헬스 체크와 레디니스 프로브: 서비스의 상태를 지속적으로 모니터링하여 자동으로 재시작하거나 트래픽을 조절합니다.  의존성 관리: Init Containers나 PostStart 훅을 통해 서비스 간의 의존성을 관리할 수 있습니다.4. 서비스별 스케일링의 유연성  자동 스케일링 지원: Kubernetes의 HPA(Horizontal Pod Autoscaler)를 통해 부하에 따라 특정 서비스의 파드(Pod) 수를 자동으로 조절할 수 있습니다.  개별 서비스 관리 용이: Deployment 리소스를 사용하여 서비스별로 독립적인 스케일링이 가능합니다.5. 부분적인 가용성 향상  선택적 스케일링: 필요한 서비스만 선택적으로 스케일링할 수 있어, 리소스 활용의 효율성을 높일 수 있습니다.  의존성 분리: 서비스 간 의존성을 명확하게 정의하고 분리하여, 한 서비스의 변경이 다른 서비스에 미치는 영향을 최소화합니다.6. 네트워크 전환 및 로드밸런싱  서비스 디스커버리 및 로드밸런싱 내장: Kubernetes의 Service 리소스는 클러스터 내에서 자동으로 로드밸런싱을 제공하며, DNS를 통해 서비스 디스커버리를 지원합니다.  동적인 네트워크 관리: 네트워크 정책(Network Policy)을 사용하여 트래픽을 동적으로 관리하고, 필요에 따라 외부로의 네트워크 전환이 가능합니다.  Ingress 컨트롤러: 외부 트래픽에 대한 로드밸런싱과 라우팅을 관리하여, 내부 및 외부 네트워크 간의 유연한 전환을 지원합니다.Kubernetes 도입 후의 변화Kubernetes를 도입한 후, 우리는 다음과 같은 이점을 얻을 수 있었습니다.  운영 효율성 향상: 자동화된 배포와 스케일링으로 운영 부담이 크게 감소했습니다.  높은 가용성 확보: 헬스 체크와 자동 복구 기능을 통해 서비스의 안정성이 향상되었습니다.  리소스 최적화: 필요한 서비스에만 리소스를 집중 투입하여 비용 효율성을 높였습니다.  유연한 네트워크 구성: 네트워크 정책과 Ingress를 활용하여 복잡한 네트워크 환경에서도 유연한 트래픽 관리가 가능해졌습니다.결론Docker Compose는 초기 개발 단계에서 여러 컨테이너를 쉽게 관리할 수 있는 훌륭한 도구입니다. 그러나 서비스 규모가 커지고 복잡성이 증가하면 Docker Compose만으로는 한계에 부딪히게 됩니다. 특히, 서비스별 스케일링, 부분적인 가용성 향상, 네트워크 전환 및 로드밸런싱과 같은 복잡한 요구 사항을 처리하기 위해서는 Kubernetes와 같은 컨테이너 오케스트레이션 도구의 도입이 필요합니다.실제 경험을 통해, Kubernetes는 복잡한 서비스 아키텍처를 효과적으로 관리하고 확장할 수 있는 강력한 기능을 제공한다는 것을 알게 되었습니다. 초기 설정과 학습 곡선이 다소 가파를 수 있지만, 장기적으로 볼 때 그 이점은 투자할 가치가 충분하다고 생각합니다.Docker Compose의 한계를 직접 경험하면서, 복잡한 서비스 환경에서 Kubernetes의 필요성을 절실히 느꼈습니다. 이 글이 비슷한 고민을 하고 있는 분들께 도움이 되길 바랍니다."
  },
  
  {
    "title": "카프카 설계의 방법론",
    "url": "/posts/%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%84%A4%EA%B3%84%EC%9D%98-%EB%B0%A9%EB%B2%95%EB%A1%A0/",
    "categories": "",
    "tags": "",
    "date": "2024-10-28 00:00:00 +0900",
    





    
    "snippet": "Kafka 설계 시 고려 사항 및 엔터프라이즈 사용 사례Apache Kafka는 대규모 데이터 스트리밍과 실시간 데이터 처리에 최적화된 분산 메시징 시스템으로, 다양한 엔터프라이즈 환경에서 필수적인 요소로 자리 잡고 있습니다. 그러나 Kafka를 설계할 때는 각 시스템의 요구 사항에 따라 신중하게 아키텍처를 구성해야 합니다. 이번 글에서는 Kafka ...",
    "content": "Kafka 설계 시 고려 사항 및 엔터프라이즈 사용 사례Apache Kafka는 대규모 데이터 스트리밍과 실시간 데이터 처리에 최적화된 분산 메시징 시스템으로, 다양한 엔터프라이즈 환경에서 필수적인 요소로 자리 잡고 있습니다. 그러나 Kafka를 설계할 때는 각 시스템의 요구 사항에 따라 신중하게 아키텍처를 구성해야 합니다. 이번 글에서는 Kafka 설계 시 중요한 질문을 바탕으로 실제 사례와 함께 엔터프라이즈급 기업에서의 Kafka 활용 방식을 알아보겠습니다.1. 메시지 손실이 허용되는가?Kafka 설계 시 첫 번째로 고려해야 할 것은 메시지 손실에 대한 허용 여부입니다.      고려사항: 메시지 손실을 허용할 수 없다면, acks=all 설정을 사용하여 모든 복제본에 메시지가 기록될 때까지 대기하도록 설정할 수 있습니다. 또한, 복제본 동기화 상태를 관리하는 min.insync.replicas 설정을 통해 메시지의 안전한 처리를 보장할 수 있습니다.        실제 사례: 은행 거래 시스템에서는 메시지 손실이 치명적입니다. 모든 거래 정보는 반드시 복제되어야 하며, 메시지 손실이 발생하면 트랜잭션 처리에 문제가 생길 수 있기 때문에 acks=all과 복제 설정을 강화하여 메시지의 안전한 전달을 보장합니다. 반면, 소셜 미디어 알림 서비스에서는 일부 메시지가 손실되더라도 큰 문제가 없을 수 있습니다. 이러한 경우에는 acks=1로 설정하여 메시지 전송 속도를 우선시하고, 메시지 손실을 허용할 수 있습니다.  2. 데이터를 그룹화해야 하는가?데이터 그룹화는 Kafka 파티셔닝과 관련이 있습니다. 파티셔닝을 통해 데이터를 논리적으로 구분하고, 데이터 일관성을 보장할 수 있습니다.      고려사항: 특정 기준으로 데이터를 그룹화해야 한다면, Kafka 파티셔닝을 활용해 동일한 키에 대해 데이터가 같은 파티션에 기록되도록 할 수 있습니다. 이를 통해 그룹화된 데이터에 대한 순차 처리가 가능합니다.        실제 사례: 이커머스 시스템에서 고객별 주문 처리를 할 때는 고객 ID를 파티션 키로 사용하여, 동일한 고객의 모든 주문이 같은 파티션에 저장되도록 합니다. 이를 통해 고객별로 주문 데이터 일관성을 유지할 수 있습니다. 로그 수집 시스템에서는 서버별 로그를 독립적으로 관리하기 위해 서버 ID를 파티션 키로 설정할 수 있습니다. 서버별로 로그 데이터를 그룹화함으로써 로그 분석을 더 쉽게 수행할 수 있습니다.  3. 특정 순서로 데이터를 전달해야 하는가?메시지 순서가 중요한 시스템에서는 파티션 내에서 순서를 보장하는 Kafka의 특성을 활용할 수 있습니다.      고려사항: 파티션 내에서는 메시지의 순서가 보장됩니다. 따라서 순서가 중요한 데이터는 반드시 같은 파티션에 기록되어야 하며, 파티션 키 선택이 매우 중요합니다. 여러 파티션에 데이터를 분산할 경우 순서 보장이 어렵기 때문에 주의해야 합니다.        실제 사례: 결제 시스템에서 거래의 순서는 매우 중요합니다. 고객의 결제 요청이 순서대로 처리되어야 하기 때문에, 고객 ID를 파티션 키로 설정하여 고객의 모든 결제 요청이 동일한 파티션에서 처리되도록 해야 합니다. 반면, SNS 댓글 시스템에서는 전체적인 순서보다는 게시글 내의 댓글 순서가 더 중요합니다. 이 경우 게시글 ID를 파티션 키로 설정하여 댓글이 순서대로 처리되도록 설계할 수 있습니다.  4. 특정 항목의 마지막 값만 필요한가? 혹은 해당 항목의 이력이 중요한가?Kafka에서는 모든 메시지를 로그로 남길지, 아니면 특정 항목의 마지막 값만 유지할지 결정해야 합니다.      고려사항: 마지막 값만 필요할 경우 Kafka의 압축(compaction) 기능을 사용할 수 있습니다. 압축을 통해 동일한 키를 가진 이전 메시지를 삭제하고, 최신 메시지만 남겨놓을 수 있습니다. 반대로, 이력이 중요한 경우 모든 메시지를 로그에 남겨야 합니다.        실제 사례: 기기 상태 모니터링 시스템에서 최신 기기 상태 정보만 필요하다면, Kafka의 로그 압축 기능을 활용하여 기기 ID별로 마지막 상태 정보만 유지할 수 있습니다. 반면, 재고 관리 시스템에서는 모든 재고 변동 이력이 필요합니다. 따라서 압축을 사용하지 않고 모든 메시지를 기록하여 재고 변화 추적이 가능하도록 합니다.  5. 얼마나 많은 컨슈머를 가질 것인가?Kafka에서 컨슈머는 시스템의 성능을 좌우하는 중요한 요소입니다. 파티션 수와 컨슈머 수의 균형을 맞추는 것이 매우 중요합니다.      고려사항: 파티션 수가 컨슈머 수보다 많을 경우, 각 컨슈머는 여러 파티션을 동시에 처리합니다. 반대로 컨슈머 수가 파티션 수보다 많으면, 일부 컨슈머는 대기 상태에 놓이게 됩니다. 따라서 적절한 파티션 수와 컨슈머 수를 설정해야 합니다.        실제 사례: 데이터 분석 시스템에서는 대규모 데이터를 빠르게 처리하기 위해 여러 컨슈머를 사용해 파티션별로 병렬 처리를 수행합니다. 파티션과 컨슈머 수를 맞춰 성능을 극대화할 수 있습니다. 반면, 주문 처리 시스템에서는 메시지 순서가 중요하기 때문에 파티션당 하나의 컨슈머만 할당하여 데이터를 처리합니다. 이렇게 하면 순서를 유지하면서도 안정적으로 주문 처리를 할 수 있습니다.  Kafka 설계 실제 사례 표다음 표는 다양한 Kafka 사용 사례에서 메시지 손실 허용 여부, 데이터 그룹화 필요성, 순서 보장 필요성, 최종 값 필요 여부, 독립된 컨슈머 지원 여부를 바탕으로 설계된 예시입니다.            사용 용례      메시지 유실 가능성      데이터 그룹화 필요성      순서 보장 필요성      최종값만 필요      독립된 컨슈머 지원 필요성                  센서 API 감사 로깅      NO      YES      NO      NO      YES              은행 거래 시스템      NO      YES      YES      NO      NO              소셜 미디어 알림 서비스      YES      NO      NO      YES      YES              고객 주문 처리 시스템      NO      YES      YES      NO      NO              기기 상태 모니터링      YES      NO      NO      YES      YES              센서 Alert 관리      NO      YES      NO      YES      YES      이 표는 각 사용 사례에 맞춘 Kafka 설계를 설명하며, 시스템의 성격에 따라 Kafka를 어떻게 설계해야 하는지에 대한 인사이트를 제공합니다.결론Kafka 설계는 각 시스템의 요구 사항에 맞춰 최적화되어야 합니다. 메시지 손실 여부, 데이터 그룹화, 순서 보장, 데이터 보존 방식 및 컨슈머 수와 같은 중요한 요소들을 고려하여 적절한 아키텍처를 선택하는 것이 중요합니다. 위에서 설명한 엔터프라이즈 사례들을 바탕으로, Kafka를 통해 안정적이고 확장 가능한 시스템을 구축할 수 있습니다.Kafka를 처음 설계하거나 엔터프라이즈 시스템에서 Kafka를 도입하는 경우, 이와 같은 설계 패턴을 통해 성능과 안정성을 최적화해보세요."
  },
  
  {
    "title": "카프카 avro 직렬화를 이용하는 방법",
    "url": "/posts/%EC%B9%B4%ED%94%84%EC%B9%B4-Avro-%EC%A7%81%EB%A0%AC%ED%99%94%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95/",
    "categories": "",
    "tags": "",
    "date": "2024-10-28 00:00:00 +0900",
    





    
    "snippet": "NestJS에서 Kafka와 Avro를 사용하는 방법NestJS는 강력한 서버 측 프레임워크로, Kafka와 같은 메시징 시스템과의 통합을 통해 대규모 실시간 데이터를 효과적으로 처리할 수 있습니다. 이 글에서는 Avro라는 데이터 직렬화 포맷을 사용하여 NestJS에서 Kafka와 통합하는 방법을 설명하고, 이를 통해 데이터를 효율적으로 직렬화하고 ...",
    "content": "NestJS에서 Kafka와 Avro를 사용하는 방법NestJS는 강력한 서버 측 프레임워크로, Kafka와 같은 메시징 시스템과의 통합을 통해 대규모 실시간 데이터를 효과적으로 처리할 수 있습니다. 이 글에서는 Avro라는 데이터 직렬화 포맷을 사용하여 NestJS에서 Kafka와 통합하는 방법을 설명하고, 이를 통해 데이터를 효율적으로 직렬화하고 전송하는 다양한 사례를 소개하겠습니다. Avro는 스키마 기반 직렬화를 지원하며, Kafka와 함께 사용될 때 그 장점이 극대화됩니다.1. Avro 직렬화를 사용하는 이유NestJS에서 Kafka를 활용할 때 Avro를 사용하는 이유는 무엇일까요? 몇 가지 주요 장점을 살펴보겠습니다.1.1 스키마 기반 데이터 직렬화Avro는 스키마 기반 직렬화 포맷으로, 데이터를 직렬화할 때 스키마 레지스트리(Schema Registry)를 사용합니다. 이를 통해 각 메시지가 일관된 구조를 가지며, 메시지마다 스키마 정보를 포함할 필요 없이 중앙에서 관리할 수 있습니다. Avro와 Kafka를 결합하면 스키마 레지스트리에 저장된 스키마를 사용하여 데이터를 직렬화하고, 메시지에는 해당 스키마의 ID만 포함되므로 전송 데이터 크기가 줄어듭니다.1.2 데이터 일관성 보장Avro의 스키마 기반 관리 방식은 데이터를 일관되게 유지할 수 있는 장점을 제공합니다. 각 서비스가 다른 버전의 데이터를 주고받더라도, Avro는 스키마 호환성을 보장하므로 안정적으로 데이터 처리가 가능합니다.1.3 효율적인 데이터 압축Avro는 데이터를 바이너리 포맷으로 직렬화하므로, 텍스트 기반 포맷(JSON, XML 등)보다 데이터 크기가 작아 네트워크 전송 효율이 높고 저장 공간도 절약할 수 있습니다.1.4 빠른 직렬화/역직렬화 속도바이너리 기반의 Avro는 텍스트 기반 포맷보다 직렬화 및 역직렬화 속도가 훨씬 빠릅니다. 이는 실시간 데이터 처리가 중요한 시스템에서 매우 유리한 특성입니다.2. Kafka와 Avro를 사용하는 효과적인 사례Kafka와 Avro를 결합하여 사용하는 대표적인 사례 몇 가지를 소개하겠습니다.2.1 데이터 호환성 유지여러 서비스가 상호작용하는 대규모 엔터프라이즈 환경에서는 데이터 구조가 지속적으로 변경될 수 있습니다. 예를 들어, NestJS 기반의 고객 관리 시스템에서 고객 데이터 구조가 변경되었을 때, 새로운 필드가 추가되더라도 기존 데이터와의 충돌을 피할 수 있습니다. Avro의 스키마 호환성 덕분에 NestJS 서비스들이 새로운 필드를 쉽게 수용하거나 무시할 수 있습니다.2.2 대규모 실시간 데이터 처리IoT 기반 NestJS 시스템에서 센서 데이터를 실시간으로 Kafka를 통해 수집하고 처리할 때, Avro는 직렬화된 데이터 크기를 최소화하여 네트워크 효율성을 높이고 실시간 데이터 처리를 가능하게 합니다. 예를 들어, 스마트 홈 시스템에서 온도나 습도 데이터를 지속적으로 수집하여 분석하는 경우, Avro와 Kafka의 결합이 적합합니다.2.3 로그 수집 및 분석NestJS 애플리케이션에서는 여러 애플리케이션 로그를 실시간으로 Kafka를 통해 수집하고 분석해야 할 때가 많습니다. Avro를 사용하면 로그 데이터를 효율적으로 직렬화하여 Kafka를 통해 전송하고, 다양한 분석 도구와 연계할 수 있습니다.3. NestJS에서 Avro와 Kafka 통합하기NestJS에서 Kafka와 Avro를 통합하려면, 주로 Confluent Schema Registry를 활용하여 Avro 스키마를 중앙에서 관리하는 방법을 사용합니다. 이를 통해 데이터 직렬화와 역직렬화가 수월해지고, 각 클라이언트가 스키마에 맞춰 데이터를 처리할 수 있습니다.3.1 Avro 직렬화 및 예외 처리 강화기존의 SchemaRegistryService 코드에 예외 처리를 추가하여, 스키마를 가져오거나 스키마 ID를 불러올 때 발생할 수 있는 오류를 처리하고 로깅을 통해 문제를 추적할 수 있도록 개선하였습니다.또한, 스키마 레지스트리를 자주 조회하면 성능에 영향을 미칠 수 있으므로, 스키마를 캐시하여 불필요한 네트워크 호출을 줄였습니다.// schema-registry.service.tsimport { Injectable, Logger } from \"@nestjs/common\";import { SchemaRegistry } from \"@kafkajs/confluent-schema-registry\";import NodeCache from \"node-cache\";@Injectable()export class SchemaRegistryService {  private registry: SchemaRegistry;  private readonly logger = new Logger(SchemaRegistryService.name); // 로거 추가  private schemaCache = new NodeCache(); // 캐시 추가  constructor() {    this.registry = new SchemaRegistry({ host: \"http://localhost:8081\" });  }  async getSchema(schemaId: number) {    const cachedSchema = this.schemaCache.get(schemaId);    if (cachedSchema) {      return cachedSchema;    }    try {      const schema = await this.registry.getSchema(schemaId);      this.schemaCache.set(schemaId, schema); // 캐시에 저장      return schema;    } catch (error) {      this.logger.error(        `Failed to get schema with ID ${schemaId}: ${error.message}`      );      throw new Error(\"Schema fetching failed\");    }  }  async getLatestSchemaId(subject: string) {    try {      return await this.registry.getLatestSchemaId(subject);    } catch (error) {      this.logger.error(        `Failed to get latest schema ID for subject ${subject}: ${error.message}`      );      throw new Error(\"Latest schema ID fetching failed\");    }  }}4. Kafka 프로듀서와 컨슈머의 예외 처리 및 로깅 강화Kafka 프로듀서와 컨슈머 서비스에서는 데이터를 직렬화하고 전송하거나 소비하는 과정에서 발생할 수 있는 오류를 처리하고, 오류 발생 시 적절한 로그를 남기도록 개선하였습니다.4.1 Kafka 프로듀서 구현Kafka 프로듀서에서 데이터 직렬화 및 전송 중 오류가 발생할 수 있는 경우를 대비하여 예외 처리를 강화하고, 로깅을 추가하여 문제가 발생했을 때 원인을 쉽게 파악할 수 있도록 하였습니다. 또한, 스키마 ID를 메시지에 포함하도록 개선하였습니다.// kafka-producer.service.tsimport { Injectable, Logger } from \"@nestjs/common\";import { ClientKafka } from \"@nestjs/microservices\";import { SchemaRegistryService } from \"./schema-registry.service\";@Injectable()export class KafkaProducerService {  private readonly logger = new Logger(KafkaProducerService.name);  constructor(    private readonly kafkaClient: ClientKafka,    private readonly schemaRegistryService: SchemaRegistryService  ) {}  async sendCustomerData(topic: string, data: any) {    try {      const schemaId = await this.schemaRegistryService.getLatestSchemaId(        \"customer-value\"      );      const avroSchema = await this.schemaRegistryService.getSchema(schemaId);      // 데이터 직렬화 및 스키마 ID 추가      const schemaIdBuffer = Buffer.alloc(4);      schemaIdBuffer.writeUInt32BE(schemaId, 0);      const serializedData = Buffer.concat([        schemaIdBuffer,        avroSchema.toBuffer(data)      ]);      this.logger.debug(        `Sending data to topic ${topic}: ${JSON.stringify(data)}`      );      // 메시지 전송      await this.kafkaClient.emit(topic, { value: serializedData });      this.logger.log(`Successfully sent data to topic ${topic}`);    } catch (error) {      this.logger.error(        `Failed to send data to topic ${topic}: ${error.message}`      );      throw new Error(\"Kafka message send failed\");    }  }}4.2 Kafka 컨슈머 구현Kafka 컨슈머에서도 메시지를 처리하는 도중 발생할 수 있는 오류를 처리하고, 스키마 ID 추출 과정에서 문제가 발생할 수 있는 상황에 대비하여 예외 처리를 추가하였습니다. 또한, 스키마 ID를 메시지에서 추출하여 적절히 처리할 수 있도록 수정하였습니다.// kafka-consumer.service.tsimport { Injectable, OnModuleInit, Logger } from \"@nestjs/common\";import { Consumer, Kafka } from \"kafkajs\";import { SchemaRegistryService } from \"./schema-registry.service\";@Injectable()export class KafkaConsumerService implements OnModuleInit {  private readonly logger = new Logger(KafkaConsumerService.name);  private consumer: Consumer;  constructor(private readonly schemaRegistryService: SchemaRegistryService) {    const kafka = new Kafka({ brokers: [\"localhost:9092\"] });    this.consumer = kafka.consumer({ groupId: \"customer-group\" });  }  async onModuleInit() {    try {      await this.consumer.connect();      await this.consumer.subscribe({        topic: \"customer-data\",        fromBeginning: true      });      this.logger.log(        \"Kafka consumer connected and subscribed to topic: customer-data\"      );    } catch (error) {      this.logger.error(        `Kafka connection or subscription error: ${error.message}`      );      throw new Error(\"Kafka connection failed\");    }    await this.consumer.run({      eachMessage: async ({ message }) =&gt; {        try {          const schemaId = message.value.readUInt32BE(0); // 메시지에서 스키마 ID 추출          const avroSchema = await this.schemaRegistryService.getSchema(            schemaId          );          const customerData = avroSchema.fromBuffer(message.value.slice(4));          this.logger.log(            `Received customer data: ${JSON.stringify(customerData)}`          );        } catch (error) {          this.logger.error(`Failed to process message: ${error.message}`);          // 예외 처리 후 계속 처리 가능        }      }    });  }}5. 센서에서 치명적인 오류가 발생했을 때: 엔터프라이즈급 설계 예시엔터프라이즈 시스템에서는 센서에서 치명적인 오류나 임계 상황이 발생했을 때, 이를 빠르게 탐지하고 대응하는 것이 중요합니다. NestJS, Kafka, 그리고 Avro를 사용하여 이러한 경고(alert) 메시지를 전송하고 처리하는 방법을 살펴보겠습니다.5.1 Avro 스키마 정의 및 데이터 직렬화 전략센서 오류나 치명적인 상태 발생 시 전송할 Alert 메시지의 Avro 스키마를 정의하고, 이를 효과적으로 캐싱하고 직렬화하는 방법을 살펴보겠습니다. 이 스키마는 센서 ID, 경고 유형, 심각도, 메시지 등을 포함합니다. 이를 통해 오류 메시지를 표준화하고 일관성 있게 관리할 수 있습니다.{  \"type\": \"record\",  \"name\": \"SensorAlert\",  \"fields\": [    { \"name\": \"sensorId\", \"type\": \"string\" },    { \"name\": \"alertType\", \"type\": \"string\" },    { \"name\": \"timestamp\", \"type\": \"long\" },    {      \"name\": \"severity\",      \"type\": {        \"type\": \"enum\",        \"name\": \"SeverityLevel\",        \"symbols\": [\"INFO\", \"WARNING\", \"CRITICAL\"]      }    },    { \"name\": \"message\", \"type\": \"string\" }  ]}위 스키마를 통해, 경고의 심각도를 명확히 구분하고 필요한 대응을 할 수 있습니다. 스키마는 SchemaRegistryService를 통해 관리되고, 각 메시지 전송 시 스키마 ID를 사용하여 직렬화합니다. 스키마는 한 번 조회 후 캐싱되어, 불필요한 네트워크 호출을 줄여 성능을 최적화합니다.5.2 Kafka 프로듀서 및 컨슈머 구현 예시센서 오류 발생 시 경고 메시지를 전송하고 처리하는 Kafka 프로듀서와 컨슈머를 정의합니다. 이 과정에서 캐싱된 스키마를 활용하여 직렬화 및 역직렬화를 수행합니다.// sensor-alert-producer.service.tsimport { Injectable, Logger } from \"@nestjs/common\";import { ClientKafka } from \"@nestjs/microservices\";import { SchemaRegistryService } from \"./schema-registry.service\";@Injectable()export class SensorAlertProducerService {  private readonly logger = new Logger(SensorAlertProducerService.name);  constructor(    private readonly kafkaClient: ClientKafka,    private readonly schemaRegistryService: SchemaRegistryService  ) {}  // 센서 경고 메시지를 Kafka로 전송하는 메소드  async sendSensorAlert(    sensorId: string,    alertType: string,    severity: string,    message: string  ) {    try {      const schemaId = await this.schemaRegistryService.getLatestSchemaId(        \"sensor-alert-value\"      );      const avroSchema = await this.schemaRegistryService.getSchema(schemaId);      const sensorAlert = {        sensorId,        alertType,        timestamp: Date.now(),        severity,        message      };      // 스키마 ID 추가 및 데이터 직렬화      const schemaIdBuffer = Buffer.alloc(4);      schemaIdBuffer.writeUInt32BE(schemaId, 0);      const serializedData = Buffer.concat([        schemaIdBuffer,        avroSchema.toBuffer(sensorAlert)      ]);      this.logger.debug(        `Sending sensor alert to Kafka: ${JSON.stringify(sensorAlert)}`      );      // 메시지 전송      await this.kafkaClient.emit(\"sensor-alert\", { value: serializedData });      this.logger.log(        `Successfully sent sensor alert for sensorId ${sensorId}`      );    } catch (error) {      this.logger.error(`Failed to send sensor alert: ${error.message}`);      throw new Error(\"Kafka message send failed\");    }  }}6. 캐싱 전략을 활용한 성능 최적화대규모 시스템에서는 빈번한 스키마 조회가 성능에 영향을 미칠 수 있습니다. 이를 방지하기 위해 NodeCache와 같은 메모리 기반 캐싱을 사용하여 스키마 정보를 로컬 메모리에 저장하고, 동일한 스키마를 사용할 경우 불필요한 네트워크 호출을 줄일 수 있습니다. 이를 통해 시스템 성능을 최적화할 수 있으며, 특히 고빈도의 메시지 송수신이 이루어지는 환경에서 더욱 효과적입니다.6.1 캐시 초기화 및 스키마 조회캐시는 NestJS 서비스에 초기화될 때 자동으로 설정되며, getSchema() 메소드에서 캐시된 스키마가 있으면 이를 반환하고, 없을 경우에만 레지스트리에서 스키마를 가져옵니다. 이를 통해 스키마 조회 시간을 단축하고 네트워크 대역폭을 절약할 수 있습니다.// schema-registry.service.tsimport { Injectable, Logger } from \"@nestjs/common\";import { SchemaRegistry } from \"@kafkajs/confluent-schema-registry\";import NodeCache from \"node-cache\";@Injectable()export class SchemaRegistryService {  private registry: SchemaRegistry;  private readonly logger = new Logger(SchemaRegistryService.name);  private schemaCache = new NodeCache(); // 스키마 캐싱  constructor() {    this.registry = new SchemaRegistry({ host: \"http://localhost:8081\" });  }  // 캐싱된 스키마 반환 또는 레지스트리에서 조회  async getSchema(schemaId: number) {    const cachedSchema = this.schemaCache.get(schemaId);    if (cachedSchema) {      return cachedSchema;    }    try {      const schema = await this.registry.getSchema(schemaId);      this.schemaCache.set(schemaId, schema); // 스키마 캐시 저장      return schema;    } catch (error) {      this.logger.error(        `Failed to get schema with ID ${schemaId}: ${error.message}`      );      throw new Error(\"Schema fetching failed\");    }  }  // 최신 스키마 ID 반환  async getLatestSchemaId(subject: string) {    try {      return await this.registry.getLatestSchemaId(subject);    } catch (error) {      this.logger.error(        `Failed to get latest schema ID for subject ${subject}: ${error.message}`      );      throw new Error(\"Latest schema ID fetching failed\");    }  }}7. 엔터프라이즈급 시스템에서의 캐싱 및 스키마 최적화캐싱 전략은 단순한 메시지 송수신을 넘어서 대규모 엔터프라이즈 시스템에서 중요한 역할을 합니다. 실시간 데이터 처리가 필요한 IoT 시스템이나 금융 시스템에서는 성능 저하가 치명적일 수 있기 때문에, Avro 스키마와 Kafka 메시징 시스템을 효율적으로 관리하는 것이 필수적입니다.1. 캐싱 유효 기간 설정캐싱된 스키마가 항상 최신 상태를 유지하기 위해 유효 기간을 설정할 수 있습니다. NodeCache의 TTL(Time to Live)을 사용하여 스키마가 일정 시간이 지나면 자동으로 삭제되도록 설정할 수 있으며, 이는 자주 변경되는 스키마 환경에서 유용합니다.// 캐시 초기화 시 TTL을 1시간으로 설정private schemaCache = new NodeCache({ stdTTL: 3600 }); // TTL: 1시간2. 지연 로딩(Lazy Loading) 기법스키마를 미리 조회해 캐싱하는 방식이 아닌, 실제로 스키마가 필요할 때 조회하고 캐싱하는 지연 로딩 기법을 적용하면 필요할 때만 스키마 레지스트리에 접근할 수 있습니다. 이는 불필요한 데이터 조회를 방지하여 자원을 절약하는 효과를 가져옵니다.3. 분산 캐시 도입시스템 규모가 커짐에 따라 단일 노드에서의 캐싱 전략이 한계에 다다를 수 있습니다. 이럴 경우, Redis와 같은 분산 캐시 솔루션을 도입하여 여러 노드 간에 스키마 캐시를 공유할 수 있으며, 이는 시스템의 일관성과 성능을 더욱 향상시킬 수 있습니다.결론NestJS와 Kafka, Avro를 결합하여 대규모 실시간 데이터 처리 시스템을 구축하는 방법을 살펴보았습니다. Avro의 스키마 기반 직렬화 덕분에 데이터의 일관성을 보장하면서도, 바이너리 포맷을 통한 빠른 직렬화/역직렬"
  },
  
  {
    "title": "외부 네트워크에서 온프라미스 쿠버네티를 구성하는 방법",
    "url": "/posts/%EC%99%B8%EB%B6%80-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC%EC%97%90%EC%84%9C-%EC%98%A8%ED%94%84%EB%9D%BC%EB%AF%B8%EC%8A%A4-%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EB%A5%BC-%EA%B5%AC%EC%84%B1%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95/",
    "categories": "",
    "tags": "",
    "date": "2024-10-26 00:00:00 +0900",
    





    
    "snippet": "물리적으로 떨어진 여러 네트워크 대역의 쿠버네티스 클러스터 구성 및 관리저는 물리적으로 떨어진 여러 네트워크 대역에 있는 PC들을 이용하여 쿠버네티스 클러스터를 구성하고 관리하게 되었는데, 그 과정에서 발생한 문제들과 해결 방법을 블로그 형식으로 정리해보았습니다. 이 글에서는 각 노드의 네트워크가 다르고, 물리적 거리가 떨어진 환경에서 쿠버네티스 클러...",
    "content": "물리적으로 떨어진 여러 네트워크 대역의 쿠버네티스 클러스터 구성 및 관리저는 물리적으로 떨어진 여러 네트워크 대역에 있는 PC들을 이용하여 쿠버네티스 클러스터를 구성하고 관리하게 되었는데, 그 과정에서 발생한 문제들과 해결 방법을 블로그 형식으로 정리해보았습니다. 이 글에서는 각 노드의 네트워크가 다르고, 물리적 거리가 떨어진 환경에서 쿠버네티스 클러스터를 어떻게 설정하고 오케스트레이션할 수 있는지에 대해 설명합니다.환경 설정      마스터 노드:          라즈베리파이 5 (별장에서 안정적으로 구동 중)      도메인: yunjjang.duckdns.org      Nginx로 SSL 구성 및 포트포워딩 설정            워커 노드:          시골에 있는 PC      외부 회사의 PC      우리 집에 있는 2대의 PC      이동 중인 네트워크에 연결된 MacBook (맥북이 움직이면서 네트워크를 자주 변경함)      모든 워커 노드들은 서로 다른 네트워크에 위치하고 있으며, 공유기마다 네트워크 대역이 다르기 때문에 쿠버네티스 클러스터 설정 및 관리가 까다로웠습니다. 이 글에서는 이러한 환경에서 쿠버네티스를 설정하는 방법과 서버 배포 및 네트워크 관리 방법을 소개합니다.1. 마스터 노드 설정 (라즈베리파이)먼저, 라즈베리파이에서 마스터 노드를 설정하고 외부에서 접근할 수 있도록 SSL과 Nginx를 이용해 구성했습니다.      DuckDNS 도메인 설정:          DuckDNS에서 yunjjang.duckdns.org라는 도메인을 생성하고, 이를 이용해 외부에서 라즈베리파이에 접근할 수 있도록 설정했습니다.            Nginx로 SSL 설정:          Nginx를 이용해 SSL 인증서를 설정하고, 외부에서 보안된 연결로 접근할 수 있도록 구성했습니다. 이를 통해 Kubernetes Dashboard나 API 서버를 안전하게 관리할 수 있었습니다.            포트 포워딩:          라즈베리파이에 필요한 쿠버네티스 포트(6443)를 공유기에서 포트포워딩하여 외부에서 접근이 가능하게 했습니다.      # Nginx 설정 예시server {    listen 80;    server_name yunjjang.duckdns.org;    location / {        proxy_pass http://localhost:6443;        proxy_set_header Host $host;        proxy_set_header X-Real-IP $remote_addr;    }}2. 워커 노드 구성다음으로, 각 워커 노드(시골 PC, 외부 회사 PC, 집 PC, MacBook 등)에서 마스터 노드와 연결하여 클러스터에 포함시키는 작업을 진행했습니다.      각 워커 노드에서 포트 포워딩 설정:          마스터 노드와의 통신을 위해 모든 워커 노드에서 공유기 설정을 통해 10250 포트를 열었습니다. 이 포트는 마스터 노드가 워커 노드와 통신하기 위해 사용됩니다.            kubeadm을 이용한 클러스터 연결:          마스터 노드에서 kubeadm join 명령어를 통해 워커 노드를 클러스터에 추가했습니다. 각 워커 노드는 마스터 노드의 IP와 토큰을 이용해 클러스터에 연결되었습니다.      kubeadm join yunjjang.duckdns.org:6443 --token &lt;token&gt; --discovery-token-ca-cert-hash sha256:&lt;hash&gt;  워커 노드의 Ready 상태 확인:          모든 워커 노드가 성공적으로 클러스터에 연결되고 kubectl get nodes 명령어를 통해 Ready 상태로 표시되었습니다.      kubectl get nodes3. 서버 배포 및 네트워킹 오케스트레이션여기서부터는 서로 다른 네트워크 대역에 위치한 워커 노드들에 어떻게 서버를 배포하고, 네트워크를 어떻게 관리하는지에 대해 설명합니다.쿠버네티스 네트워킹의 문제쿠버네티스의 기본 네트워크 가정은 모든 파드가 NAT 없이 서로 통신할 수 있어야 한다는 것입니다. 하지만 현재 구성된 환경에서는 워커 노드들이 서로 다른 네트워크에 있기 때문에, 기본 네트워크 모델이 제대로 동작하지 않습니다. 이를 해결하기 위해 여러 방법을 고려했습니다.4. Submariner를 이용한 네트워크 통합서로 다른 네트워크 대역에 있는 워커 노드 간의 통신을 원활하게 하기 위해 Submariner라는 멀티 클러스터 네트워크 솔루션을 도입했습니다. Submariner를 통해 각 워커 노드는 마치 동일한 네트워크에 있는 것처럼 통신할 수 있습니다.Submariner 설치 과정  Broker 클러스터 설정 (라즈베리파이에 설치):          중앙 Broker 클러스터를 라즈베리파이에 설치하여, 각 워커 노드가 이 Broker를 통해 통신할 수 있도록 했습니다.      kubectl create ns submariner-k8s-brokerhelm repo add submariner-latest https://submariner-io.github.io/submariner-chartshelm repo updatehelm install submariner-broker submariner-latest/submariner-k8s-broker --namespace submariner-k8s-broker  각 워커 노드에 Submariner 설치:          시골 PC, 외부 회사 PC, 집 PC들에 Submariner Operator와 Gateway를 설치하여 네트워크를 통합했습니다.      kubectl create ns submariner-operatorhelm install submariner submariner-latest/submariner --namespace submariner-operator --set broker=k8s --set brokerK8sApiServer=https://yunjjang.duckdns.org --set brokerK8sApiServerToken=&lt;token&gt; --set cableDriver=libreswan  파드 간 통신 확인:          Submariner를 설치한 후, 각 워커 노드에 배포된 파드들이 서로 통신할 수 있는지 ping 명령어로 확인했습니다.      kubectl exec -it &lt;pod-name&gt; -- ping &lt;target-pod-ip&gt;5. 서버 배포 및 관리이제 Submariner로 네트워크가 통합된 상태에서, 각 워커 노드에 서버를 배포하고 관리할 수 있습니다.      서비스 배포:          각각의 워커 노드에 서버를 배포할 때는 kubectl apply 명령어를 통해 파드를 생성하고, 파드 간 통신이 Submariner를 통해 자연스럽게 이루어지도록 설정했습니다.            인그레스(Ingress) 설정:          모든 트래픽을 yunjjang.duckdns.org로 집중시키고, 인그레스를 통해 적절한 워커 노드로 트래픽을 라우팅했습니다. 이를 통해 외부에서 트래픽이 들어올 때, 쿠버네티스 인그레스 규칙을 따라 각 서버로 요청이 분산됩니다.      apiVersion: networking.k8s.io/v1kind: Ingressmetadata:  name: example-ingressspec:  rules:    - host: yunjjang.duckdns.org      http:        paths:          - path: /            pathType: Prefix            backend:              service:                name: my-service                port:                  number: 806. 결론 및 마무리이 글에서는 서로 다른 네트워크 대역에 위치한 워커 노드들을 하나의 쿠버네티스 클러스터로 묶고, Submariner를 통해 파드 간 통신을 원활하게 하는 방법을 소개했습니다. 이를 통해 각 워커 노드에 서버를 배포하고, 네트워크 관리의 복잡성을 줄일 수 있었습니다.이러한 방식으로 다양한 네트워크 환경에서도 쿠버네티스를 유연하게 활용할 수 있으며, Submariner 같은 멀티 클러스터 네트워크 솔루션을 통해 분산된 클러스터 환경을 통합적으로 관리할 수 있습니다.추가 고려사항:  VPN 대안: Submariner 대신 VPN을 사용하여 네트워크를 통합할 수 있지만, Submariner는 쿠버네티스에 특화된 멀티 클러스터 네트워크 관리 솔루션으로 더 적합할 수 있습니다.  보안 설정: SSL 인증서와 함께 방화벽 설정, IPsec 터널링 등을 통해 보안을 강화하는 것이 중요합니다."
  },
  
  {
    "title": "Wol와 k8s로 구현하는 홈서버 오토스케일링",
    "url": "/posts/WOL%EC%99%80-k8s%EB%A1%9C-%EA%B5%AC%ED%98%84%ED%95%98%EB%8A%94-%ED%99%88%EC%84%9C%EB%B2%84-%EC%98%A4%ED%86%A0%EC%8A%A4%EC%BC%80%EC%9D%BC%EB%A7%81/",
    "categories": "",
    "tags": "",
    "date": "2024-10-14 00:00:00 +0900",
    





    
    "snippet": "# 가정용 서버 환경 구축: 라즈베리파이와 PC를 활용한 오토스케일링최근 저는 집에서 가정용 서버 환경을 구축하며, 서버 자동화를 위한 스크립트를 작성했습니다. 이 스크립트는 워커 노드와 메인 노드 설정을 자동화하여, 유기적인 오토스케일링 시스템을 구현하는 것을 목표로 하고 있습니다.라즈베리파이5와 PC의 활용첫 번째 단계로 라즈베리파이5를 마스터 노...",
    "content": "# 가정용 서버 환경 구축: 라즈베리파이와 PC를 활용한 오토스케일링최근 저는 집에서 가정용 서버 환경을 구축하며, 서버 자동화를 위한 스크립트를 작성했습니다. 이 스크립트는 워커 노드와 메인 노드 설정을 자동화하여, 유기적인 오토스케일링 시스템을 구현하는 것을 목표로 하고 있습니다.라즈베리파이5와 PC의 활용첫 번째 단계로 라즈베리파이5를 마스터 노드로 설정하고, 집에 있는 PC 3대를 워커 노드로 연결했습니다. 각 PC는 Windows 환경이지만, 부팅되면 자동으로 리눅스 가상 환경을 시작하여 Kubernetes의 워커 노드 역할을 합니다.PC 사양각 PC는 다음과 같은 사양을 가지고 있습니다:  Main node PC: 라즈베리파이5 8GB RAM  PC1: 16GB RAM, Ryzen 5600 CPU, 4060TI GPU  PC2: 22GB RAM, Ryzen 2600X CPU, 1060 6GB GPU  PC3: 32GB RAM, Mac M1 Pro이 PC들은 각각 다수의 리눅스 가상 환경을 동시에 구동하도록 설정되어 있으며, 부팅 즉시 가상화된 워커 노드들이 준비됩니다.WOL(웨이크온랜) 기반 오토스케일링오토스케일링의 핵심은 WOL(Wake-on-LAN) 시스템을 활용해 트래픽 부하에 따라 PC를 자동으로 부팅하는 것입니다. 기본적으로 트래픽이 서버 용량의 50%를 초과하면 첫 번째 PC가 자동으로 부팅됩니다. 이후 첫 번째 PC를 포함한 리소스가 다시 50%를 초과하면 두 번째 PC가 부팅됩니다. 이런 식으로 최대 3대의 PC가 서버 리소스에 맞춰 순차적으로 부팅되며, 추가적인 서버 용량을 제공합니다.트래픽 분산 및 전력 절약의 장점이 시스템을 통해 얻을 수 있는 두 가지 주요 장점은 다음과 같습니다:  트래픽 분산 처리: 각 PC가 필요할 때만 부팅되므로, 서버의 리소스를 효율적으로 관리할 수 있습니다. 트래픽이 몰릴 때도 서버의 부하를 최소화하며 안정적인 성능을 유지할 수 있습니다.  전력 소비 절감: 트래픽이 과도하지 않은 경우에는 추가적인 PC 부팅이 필요하지 않아 전력 소비를 절감할 수 있습니다. 필요할 때만 리소스를 추가하고, 불필요할 때는 PC를 꺼두는 방식으로 에너지를 아낄 수 있습니다.이번 프로젝트는 가정용 서버 환경에서 자원 효율성과 전력 소비 절감을 목표로 설계되었습니다. WOL과 가상화 기술을 통해 트래픽이 많을 때만 리소스를 확장하는 유연한 오토스케일링을 구현함으로써, 가정 내 서버 관리의 효율성을 극대화할 수 있습니다.앞으로도 이 시스템을 최적화하여 다양한 상황에서 더욱 효율적으로 서버를 운영할 계획입니다.최종적으로는 1억개의 트래픽을 감당하는 솔루션을 구현하는게 목표입니다"
  },
  
  {
    "title": "쿠버네티스를 가장 쉽게 설정하는 방법",
    "url": "/posts/%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4%EB%A5%BC-%EA%B0%80%EC%9E%A5-%EC%89%BD%EA%B2%8C-%EC%84%A4%EC%A0%95%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95/",
    "categories": "",
    "tags": "",
    "date": "2024-10-13 00:00:00 +0900",
    





    
    "snippet": "이 쿠버네티스(Kubernetes) 설정 스크립트는 사용자가 쿠버네티스를 손쉽게 설치하고 설정할 수 있도록 다양한 작업을 자동화합니다. 주로 Ubuntu 리눅스 환경에서 동작하도록 설계되었으며, 마스터 노드와 워커 노드를 구분하여 설정할 수 있습니다. 이 글에서는 각 스크립트가 어떤 역할을 하는지 간단하게 설명하고, 이 설정을 블로그 글로 작성하는 방...",
    "content": "이 쿠버네티스(Kubernetes) 설정 스크립트는 사용자가 쿠버네티스를 손쉽게 설치하고 설정할 수 있도록 다양한 작업을 자동화합니다. 주로 Ubuntu 리눅스 환경에서 동작하도록 설계되었으며, 마스터 노드와 워커 노드를 구분하여 설정할 수 있습니다. 이 글에서는 각 스크립트가 어떤 역할을 하는지 간단하게 설명하고, 이 설정을 블로그 글로 작성하는 방안을 제안합니다.블로그 글 제목“Ubuntu에서 쿠버네티스(Kubernetes) 클러스터 간편 설치 및 설정 스크립트 가이드”소개이 글에서는 리눅스 환경에서 쿠버네티스 클러스터를 쉽게 설치하고 설정하는 방법을 설명합니다. 이를 위해 필요한 모든 과정을 스크립트화하여, 자동화된 설정을 통해 마스터 노드와 워커 노드를 간편하게 구성할 수 있습니다. 본 가이드는 Ubuntu 기반의 시스템을 기준으로 작성되었습니다.1. 스크립트 개요설정을 자동화하기 위해 만든 스크립트는 총 5개의 주요 단계로 구성됩니다:  kubectlInstaller.sh: 쿠버네티스 클라이언트 도구인 kubectl을 설치합니다.  kubeadmInstaller.sh: 쿠버네티스 클러스터 관리 도구인 kubeadm을 설치합니다.  container.sh: 쿠버네티스 클러스터에서 사용할 컨테이너 런타임 containerd를 설치합니다.  k8sPackage.sh: 쿠버네티스 패키지 및 네트워크 플러그인을 설치합니다.  nodeSetting.sh: 마스터 또는 워커 노드를 설정합니다.이 스크립트를 실행함으로써 복잡한 설치 과정을 간소화할 수 있습니다. 아래에서 각 스크립트가 하는 작업을 좀 더 자세히 설명하겠습니다.2. 스크립트별 상세 설명2.1 kubectlInstaller.sh이 스크립트는 최신 stable 버전의 kubectl을 다운로드하고 설치합니다.  운영체제와 아키텍처를 자동으로 감지하여 맞춤형 설치 파일을 가져옵니다.  kubectl 바이너리의 무결성을 체크섬을 통해 검증하며, 검증 후에는 /usr/local/bin 디렉터리에 설치합니다.2.2 kubeadmInstaller.sh쿠버네티스 설치의 핵심 도구인 kubeadm, kubelet, kubectl을 설치하는 스크립트입니다.  Ubuntu에서 기본적으로 제공되지 않는 Kubernetes 레포지토리를 추가하고 패키지를 설치합니다.  설치 후 kubelet을 활성화하고 자동 시작을 설정합니다.2.3 container.sh이 스크립트는 컨테이너 런타임 containerd를 설치하고, 시스템을 적절히 설정합니다.  컨테이너 런타임으로 containerd를 사용하도록 쿠버네티스를 설정하며, SystemdCgroup을 활성화하여 시스템 자원 관리를 개선합니다.2.4 k8sPackage.sh쿠버네티스 클러스터를 구성할 때 필요한 패키지들을 설치하는 스크립트입니다.  IP 포워딩을 활성화하고, 브리지 네트워크 필터링을 설정합니다.  네트워크 플러그인으로 Calico를 설치하여 클러스터 내부 네트워크 통신을 설정합니다.2.5 nodeSetting.sh이 스크립트는 마스터 노드 또는 워커 노드를 설정하는 과정입니다.  사용자가 입력한 정보를 바탕으로 kubeadm을 사용하여 마스터 노드를 초기화하거나, 워커 노드를 마스터에 조인시킵니다.  마스터 노드에서는 워커 노드를 추가할 수 있는 토큰과 명령어를 생성하여 제공합니다.3. 스크립트 실행 방법모든 스크립트는 다음 명령어를 통해 실행할 수 있습니다:./setup.sh이 스크립트는 운영체제를 자동으로 감지하여 적합한 패키지와 설정을 설치하며, 사용자는 마스터 또는 워커 노드를 선택하여 설정할 수 있습니다. 리눅스에서는 방화벽 설정을 자동으로 적용해주며, Calico 네트워크 플러그인을 설치하여 쿠버네티스의 네트워크 설정을 완료합니다.4. 결론이 스크립트는 복잡한 쿠버네티스 설치 과정을 자동화하여 사용자가 손쉽게 클러스터를 구성할 수 있도록 돕습니다. 마스터 노드와 워커 노드를 구분하여 필요한 방화벽 설정과 노드 간 통신 설정도 간편하게 적용됩니다. 쿠버네티스를 처음 사용하는 사용자나 복잡한 설정이 부담스러운 개발자에게 이 스크립트는 매우 유용할 것입니다.예시 코드블로그 글에서 보여줄 코드 예시는 설정 스크립트와 각 단계별 스크립트의 간단한 부분을 소개할 수 있습니다.예시로, kubectlInstaller.sh의 설치 스크립트는 다음과 같습니다:#!/bin/bash# 운영체제 감지OS=$(uname | tr '[:upper:]' '[:lower:]')# 아키텍처 감지ARCH=$(uname -m)# kubectl 최신 버전 다운로드VERSION=$(curl -L -s https://dl.k8s.io/release/stable.txt)URL=\"https://dl.k8s.io/release/${VERSION}/bin/${OS}/${ARCH}/kubectl\"curl -LO \"$URL\"# 실행 권한 부여 및 설치chmod +x kubectlsudo mv kubectl /usr/local/bin/kubectl이와 같은 예시는 글에서 코드 설명을 쉽게 이해할 수 있도록 도와줄 수 있습니다.마지막으로이 스크립트를 사용하면 쿠버네티스 설정 시간을 크게 줄일 수 있으며, 복잡한 과정을 자동화하여 운영체제에 관계없이 원활한 설치가 가능합니다."
  },
  
  {
    "title": "레디스 키 어노테이션 패턴",
    "url": "/posts/%EB%A0%88%EB%94%94%EC%8A%A4-%ED%82%A4-%EC%96%B4%EB%85%B8%ED%85%8C%EC%9D%B4%EC%85%98-%ED%8C%A8%ED%84%B4/",
    "categories": "",
    "tags": "",
    "date": "2024-10-03 00:00:00 +0900",
    





    
    "snippet": "Redis에서 키 어노테이션의 원칙: 키 간 독립성과 데이터 관리 방법론Redis는 In-Memory 데이터베이스로 빠른 데이터 접근성과 간단한 키-값 저장소의 특성을 가집니다. 하지만, 이러한 단순한 구조에서 데이터를 저장하고 관리하는 데 있어 중요한 원칙 중 하나는 키 간의 독립성입니다. 이를 통해 데이터 간의 참조 무결성을 수동으로 처리하면서도,...",
    "content": "Redis에서 키 어노테이션의 원칙: 키 간 독립성과 데이터 관리 방법론Redis는 In-Memory 데이터베이스로 빠른 데이터 접근성과 간단한 키-값 저장소의 특성을 가집니다. 하지만, 이러한 단순한 구조에서 데이터를 저장하고 관리하는 데 있어 중요한 원칙 중 하나는 키 간의 독립성입니다. 이를 통해 데이터 간의 참조 무결성을 수동으로 처리하면서도, 데이터의 일관성과 효율성을 유지할 수 있습니다. 이 글에서는 Redis에서 키 어노테이션을 사용할 때 키 간 독립성 원칙을 유지하는 방법과 이를 기반으로 한 좋은 패턴을 소개하겠습니다.1. 키 간 독립성의 정의키 간 독립성은 각 키가 서로 직접적인 종속 관계를 가지지 않고, 독립적으로 데이터를 관리하도록 하는 원칙입니다. 이는 데이터 저장과 삭제 시, 한 키의 변화가 다른 키에 직접적인 영향을 미치지 않도록 보장합니다. 이 원칙을 따를 경우 데이터의 일관성 문제를 방지할 수 있으며, 각 데이터를 별도로 관리할 수 있는 유연성을 제공합니다.2. 키 간 독립성을 지키는 데이터 저장 방법론키 간 독립성을 유지하면서도 데이터를 효율적으로 관리하기 위해서는 다음과 같은 방법론을 사용할 수 있습니다.(1) 명시적 키 패턴 사용데이터를 저장할 때, 명시적인 키 패턴을 사용하여 각 데이터를 고유하게 구분할 수 있습니다. 이를 통해 키 간의 충돌을 방지하고, 특정 키의 변화가 다른 키에 영향을 미치지 않도록 할 수 있습니다.      예시: 사용자 정보를 저장하는 경우, 각 사용자별로 고유한 ID를 포함한 키를 사용하여 데이터를 저장합니다.    SET user:1001:name \"John\"SET user:1001:email \"john@example.com\"SET user:1001:age \"25\"              이 패턴에서는 user:1001 키와 관련된 모든 데이터가 독립적으로 관리됩니다. 다른 사용자(user:1002)의 데이터는 서로 독립적이며, 한 사용자의 데이터가 변경되거나 삭제되더라도 다른 사용자에게 영향을 미치지 않습니다.      (2) 네임스페이스 패턴 사용키의 구조를 계층적으로 나누어 데이터를 그룹화하는 방법입니다. 예를 들어, 네임스페이스를 사용하여 데이터의 역할을 분리할 수 있습니다.      예시: 친구 관계를 관리하는 경우    SADD user:1001:friends 1002 1003 1004  # 친구 목록SADD user:1002:friends 1001 1004              user:1001:friends와 user:1002:friends는 각기 독립적으로 관리되며, 친구 관계 데이터를 관리할 때 한쪽의 변경이 다른 쪽에 직접적인 영향을 미치지 않습니다.      (3) TTL(Time-To-Live) 설정TTL을 사용하여 자동 만료되는 데이터를 설정할 수 있습니다. 특히 세션 관리나 일시적인 데이터에 유용하며, 한 데이터가 만료되더라도 다른 데이터에 영향을 미치지 않게 합니다.      예시: 세션 데이터를 저장하고, 1시간 후 자동 만료되도록 설정합니다.    SET session:1234 \"session_data\"EXPIRE session:1234 3600  # 1시간 후 만료              각 세션은 독립적인 TTL을 가지며, 하나의 세션이 만료되더라도 다른 세션에 영향을 미치지 않습니다.      (4) Set 및 Hash 자료형 활용Redis의 Set과 Hash 자료형을 활용하면 데이터 간의 중복을 방지하고, 데이터의 독립성을 유지하면서도 그룹화된 데이터를 관리할 수 있습니다. 특히, 사용자 관계(친구 목록)나 속성 집합을 관리할 때 유용합니다.      예시: 각 사용자의 친구 목록을 Set으로 저장하여 중복된 데이터 없이 관리하고, 각 사용자 간의 독립성을 유지합니다.    SADD user:1001:friends 1002 1003SADD user:1002:friends 1001 1004              Set 자료형은 자동으로 중복된 값을 허용하지 않기 때문에, 같은 친구가 여러 번 추가되는 문제를 방지합니다.      3. 키 간 독립성을 고려한 패턴들(1) Cascade Delete(연쇄 삭제) 방지 패턴연관된 데이터를 함께 삭제할 때, 하나의 키 삭제가 다른 키에 간접적인 영향을 미치지 않도록 하기 위해서는 키를 명확하게 분리하고, 삭제 로직을 별도로 작성해야 합니다.      나쁜 예시: 단순히 하나의 키가 삭제되면 다른 키도 같이 삭제되도록 강제하는 방식은 좋지 않습니다.    DEL user:1001  # 해당 키 삭제가 다른 키에 영향을 미치면 안 됨            좋은 예시: 각 데이터가 독립적으로 관리되므로, 관련된 데이터를 함께 삭제할 때는 명시적으로 삭제해야 합니다.    DEL user:1001:nameDEL user:1001:emailSREM user:1002:friends 1001  # 친구 목록에서 user:1001 제거      (2) 트랜잭션을 통한 원자적 작업 수행여러 작업을 동시에 수행해야 할 때는 트랜잭션을 사용하여 원자적으로 처리할 수 있습니다. 이 과정에서 각 작업은 독립적이며, 모든 작업이 성공하거나 실패할 때만 일괄적으로 처리됩니다.  예시: 사용자를 삭제하고 그 사용자의 친구 목록에서 관련 데이터를 제거하는 트랜잭션    MULTI  DEL user:1001:name  DEL user:1001:email  SREM user:1002:friends 1001  SREM user:1003:friends 1001EXEC      (3) 데이터 복제 및 백업 패턴Redis는 메모리 기반 데이터베이스이므로 데이터 유실에 주의해야 합니다. 이를 방지하기 위해 데이터 백업과 복제를 자주 수행하여 키 간 독립성을 유지할 수 있습니다.4. Redis 키 어노테이션 예시 정리      사용자 정보 관리:    SET user:1001:name \"John\"SET user:1001:email \"john@example.com\"SADD user:1001:friends 1002 1003            세션 관리:    SET session:1234 \"session_data\"EXPIRE session:1234 3600  # 1시간 만료            캐싱된 데이터 관리:    SET cache:product:PRODUCT_ID \"product_data\"EXPIRE cache:product:PRODUCT_ID 1800  # 30분 후 만료            실시간 메시지 관리:    XADD chat:room:100 messages * \"user\" \"john\" \"message\" \"Hello!\"      결론Redis에서 데이터를 저장할 때 키 간 독립성을 원칙으로 하면 데이터 간의 참조 문제를 최소화하고 일관성 있는 데이터 관리가 가능합니다. 키 패턴을 체계적으로 설계하고, Set과 Hash 같은 자료형을 활용하여 중복을 방지하며, TTL을 설정해 자동 만료 기능을 사용하면 효과적으로 데이터를 관리할 수 있습니다.이를 통해 Redis의 성능을 극대화하면서도 데이터 일관성을 유지하는 좋은 패턴을 구축할 수 있습니다."
  },
  
  {
    "title": "레디스 자료형별 유스케이스정리",
    "url": "/posts/%EB%A0%88%EB%94%94%EC%8A%A4-%EC%9E%90%EB%A3%8C%ED%98%95%EB%B3%84-%EC%9C%A0%EC%8A%A4%EC%BC%80%EC%9D%B4%EC%8A%A4%EC%A0%95%EB%A6%AC/",
    "categories": "",
    "tags": "",
    "date": "2024-10-03 00:00:00 +0900",
    





    
    "snippet": "Redis는 다양한 자료형을 제공하며, 이를 통해 캐시, 세션 관리, 실시간 메트릭 수집, 데이터 처리 큐 등 다양한 엔터프라이즈 서비스에서 매우 유용하게 사용됩니다. 각 자료형은 특정 목적에 맞게 설계되었으며, 적절히 사용함으로써 성능 최적화와 데이터 관리의 효율성을 크게 향상시킬 수 있습니다. 아래에서는 각 자료형의 유스케이스를 더 풍부하게 확장하...",
    "content": "Redis는 다양한 자료형을 제공하며, 이를 통해 캐시, 세션 관리, 실시간 메트릭 수집, 데이터 처리 큐 등 다양한 엔터프라이즈 서비스에서 매우 유용하게 사용됩니다. 각 자료형은 특정 목적에 맞게 설계되었으며, 적절히 사용함으로써 성능 최적화와 데이터 관리의 효율성을 크게 향상시킬 수 있습니다. 아래에서는 각 자료형의 유스케이스를 더 풍부하게 확장하여 정리해보겠습니다.1. String (문자열)추가 유스케이스:      캐시:          웹 페이지 캐싱: 자주 조회되는 웹 페이지 또는 API 응답 데이터를 빠르게 조회하기 위해 캐싱.        SET cache:homepage \"html_content\"EXPIRE cache:homepage 3600  # 1시간 동안 캐싱                    이미지 및 이진 데이터 저장: 이미지 파일, PDF와 같은 이진 데이터를 문자열로 저장 가능.        SET image:data \"binary_image_data\"                          카운터 및 실시간 메트릭:          방문자 수 카운트: 특정 웹 페이지나 서비스의 조회 수를 실시간으로 카운트.        INCR page_views:homepage                    실시간 메트릭 수집: API 요청 수, 평균 응답 시간과 같은 실시간 수치를 기록.        INCR api:request_count                          세션 및 인증 토큰 관리:          세션 저장: 각 사용자의 세션 정보를 Redis에 저장하여 빠른 액세스와 만료 설정을 적용.        SET session:token123 \"session_data\"EXPIRE session:token123 1800  # 30분 후 만료                    2. List (리스트)추가 유스케이스:      채팅 메시지 기록 및 실시간 피드 관리:          채팅방 메시지 저장: 채팅 애플리케이션에서 메시지를 시간순으로 기록하고, 이를 빠르게 조회.        LPUSH chat:room:1 \"message\"LRANGE chat:room:1 0 10  # 최신 10개 메시지 조회                          작업 대기열 및 일괄 처리:          작업 스케줄링: 백엔드에서 처리해야 하는 작업을 리스트에 저장하고 순차적으로 처리.        LPUSH task_queue \"task1\"RPOP task_queue  # 작업 처리                          이벤트 기록:          이벤트 로그 저장: 사용자 활동 로그나 시스템 이벤트를 시간순으로 기록.        LPUSH event_log \"user_logged_in\"                    3. Set (집합)추가 유스케이스:      추천 시스템 및 사용자 속성 관리:          유저 그룹 및 공통 관심사 추적: 특정 그룹에 속한 유저들을 추적하거나, 공통 관심사를 찾는 데 사용.        SADD user:1001:categories \"sports\"SADD user:1001:categories \"technology\"                          고유 이벤트 처리:          중복 이벤트 필터링: 고유 이벤트(예: 이메일 전송, 알림 등)가 한 번만 처리되도록 보장.        SADD processed_events \"event123\"                          IP 주소 필터링 및 사용자 활동 추적:          고유 IP 주소 저장: 웹사이트 방문자의 고유 IP 주소를 저장하고 추적.        SADD unique_ips \"192.168.0.1\"                    4. Hash (해시)추가 유스케이스:      사용자 세부 정보 저장:          사용자 프로필 관리: 여러 필드를 가진 사용자 정보를 한 번에 저장하고, 개별 필드를 효율적으로 조회.        HSET user:1001 name \"John\" age 30 email \"john@example.com\"                          구성 설정 관리:          애플리케이션 설정 및 구성 저장: 시스템 설정이나 환경 변수를 해시로 관리.        HSET app:config environment \"production\" version \"1.2.0\"                          제품 정보 관리:          이커머스 플랫폼에서 제품 정보 관리: 제품 정보를 필드별로 저장하고, 개별적으로 수정 가능.        HSET product:123 name \"Laptop\" price 999 stock 50                    5. Sorted Set (정렬된 집합)추가 유스케이스:      우선순위 큐:          긴급 작업 처리: 점수 기반으로 우선순위를 두어 작업을 처리.        ZADD task_queue 10 \"normal_task\"ZADD task_queue 100 \"urgent_task\"ZREVRANGE task_queue 0 -1  # 높은 우선순위 작업부터 조회                          소셜 네트워크 타임라인:          사용자 게시물 타임라인: 사용자별로 최신 게시물을 점수(게시 시간) 기반으로 정렬.        ZADD user:1001:timeline 1620000000 \"post1\"ZADD user:1001:timeline 1620000300 \"post2\"                          리더보드 관리:          게임 리더보드: 게임 내 플레이어 점수를 관리하고 상위 플레이어를 조회.        ZADD leaderboard 1500 \"player1\"ZADD leaderboard 2000 \"player2\"ZREVRANGE leaderboard 0 10 WITHSCORES  # 상위 10명 조회                    6. Bitmap (비트맵)추가 유스케이스:      일별 사용자 로그인 상태 관리:          로그인 기록 추적: 각 사용자의 로그인 여부를 비트 단위로 기록하고, 일별 로그인 상태를 효율적으로 관리.        SETBIT user:1001:logins 0 1  # 첫 번째 날 로그인 기록SETBIT user:1001:logins 1 0  # 두 번째 날 로그인 안 함                          플래그 상태 관리:          플래그 설정: 특정 기능의 활성화 여부를 비트로 관리하여 메모리 효율성을 극대화.        SETBIT feature_flags 0 1  # 첫 번째 플래그 활성화                    7. HyperLogLog추가 유스케이스:      고유 사용자 수 추정:          대규모 트래픽에서 고유 사용자 추적: 웹사이트의 방문자 수를 적은 메모리로 추적.        PFADD unique_visitors \"user1\"PFADD unique_visitors \"user2\"PFCOUNT unique_visitors                          고유 이벤트 추적:          이벤트 처리 수 추정: 이벤트 처리량을 메모리 사용을 줄이며 추정.        PFADD processed_events \"event123\"PFADD processed_events \"event124\"                    8. Stream (스트림)Stream은 Redis 5.0에 도입된 자료형으로, 대용량 데이터 스트리밍과 메시지 브로커 역할을 수행합니다. 스트림은 소비자 그룹을 사용해 여러 소비자가 데이터를 처리할 수 있도록 지원합니다.추가 유스케이스:      실시간 데이터 피드:          실시간 로그 수집: 시스템 로그를 스트림에 기록하고, 소비자 그룹을 통해 여러 서비스가 데이터를 처리.        XADD logs * message \"error occurred\"XREAD COUNT 1 STREAMS logs 0                          이벤트 소싱:          이벤트 처리 시스템: 이벤트 기반 아키텍처에서 각 이벤트를 스트림에 기록하고, 필요 시 이벤트를 재처리.        XADD event_stream * event \"user_created\"                    결론Redis는 다양한 자료형을 통해 효율적인 데이터 관리 전략을 수립할 수 있습니다. 특히 각 자료형을 유스케이스에 맞게 적절히 사용하고, 서로 조합함으로써 성능과 메모리 사용의 최적화를 도모할 수 있습니다. 엔터프라이즈 환경에서는 고속 캐싱, 실시간 데이터 처리, 로그 및 메트릭 관리와 같은 다양한 상황에서 Redis가 널리 활용될 수 있습니다."
  },
  
  {
    "title": "초기설정 스타터팩을 구성하며",
    "url": "/posts/%EC%B4%88%EA%B8%B0%EC%84%A4%EC%A0%95-%EC%8A%A4%ED%83%80%ED%84%B0%ED%8C%A9%EC%9D%84-%EA%B5%AC%EC%84%B1%ED%95%98%EB%A9%B0/",
    "categories": "",
    "tags": "",
    "date": "2024-10-02 00:00:00 +0900",
    





    
    "snippet": "---title: \"MSA 프로젝트를 위한 Docker Compose 스타터팩\"date: \"2024-10-02\"tags: [\"docker\", \"docker-compose\", \"backend\", \"msa\", \"mysql\"]---## MSA 구성의 반복을 피하기 위한 Docker Compose 스타터팩MSA(Microservices Architecture...",
    "content": "---title: \"MSA 프로젝트를 위한 Docker Compose 스타터팩\"date: \"2024-10-02\"tags: [\"docker\", \"docker-compose\", \"backend\", \"msa\", \"mysql\"]---## MSA 구성의 반복을 피하기 위한 Docker Compose 스타터팩MSA(Microservices Architecture)를 구성하거나 새로운 프로젝트를 시작할 때, 매번 동일한 설정과 구성을 반복하는 것이 매우 번거로울 수 있습니다. 특히 도커 환경에서 백엔드, 프론트엔드, 그리고 데이터베이스의 설정을 처음부터 다시 구성하는 일은 시간 소모가 큽니다.그래서 이번 포스팅에서는 이러한 반복적인 작업을 줄이기 위해 제가 준비한 **backend 스타터팩**을 소개하고자 합니다.이 스타터팩은 백엔드, 프론트엔드, MySQL 데이터베이스를 쉽게 설정하고 시작할 수 있도록 구성되어 있습니다.추후에 브랜치로 나뉘어진 상세한 갈래들로 각자 자신의 취향에 맞는 구성을 한번에 Pick 해서 사용할 수 있도록 구성하는것이 목표입니다가령 , 나는 몽고DB를 이용한 NoSQL , backend 를 구성할거야! -이번엔 , Mysql을 사용하지만 ORM을 TypeORM이아닌 다른 ORM을 채택할것이야,이번엔 , Redis 를 도입하여 캐싱전략을 도입할것이야,이번엔 , Redis 도 도입하면서 Kafka도 도입할 예정이야난 다이나모DB와 , Redis 와 Kafka를 이용할거야등등 각각의 전략 및 구성 설정에 맞는 설정들을 각각의 브랜치로 관리하여 가지로 뻗어나가는 초기환경 설정계의 말 그대로의 \"스타터팩\" 을 제공하는것을 목표로합니다.그 구현방법은 스크립트가 될 수도 npm 패키지 매니저에 올릴수도, 갖가지 방법이 있겠으나, 현재로서는 브랜치전략을 이용해 코드를 먼저 구성해보고자 합니다.그 첫번째는 제가 자주사용하는 NestJS 를 바탕으로 구성될 예정이며 각각의 컨테이너로 관리될 수 있는 환경들은 Docker를 이용한 컨테이너로 분리될 수 있도록 구성할 예정입니다.자, 이 기나긴 여정의 첫번째 갈래인 MySQL , TypeORM , NestJS 의 스타터팩의 한줄기를 소개합니다.# 깃 링크```https://github.com/yunsoShin/starter_pack_back.git```### 도커 컴포즈 파일 구조아래는 제가 만든 `docker-compose.yml` 파일입니다. 이 파일을 통해 백엔드, 프론트엔드, MySQL 서비스를 한 번에 구성할 수 있습니다.```yamlservices:  backend:    build:      context: ../backend      dockerfile: ../docker/dockerfile.backend    container_name: backend    ports:      - \"7778:7778\"    environment:      - DB_HOST=${DB_HOST}      - DB_PORT=${DB_PORT}      - DB_USER=${DB_USER}      - DB_PASSWORD=${DB_PASSWORD}      - DB_NAME=${DB_NAME}      - IS_DEV=${IS_DEV}    depends_on:      - mysql    networks:      - mynetwork    restart: on-failure  mysql:    build:      context: ./      dockerfile: ./dockerfile.mysql    container_name: mysql    environment:      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}      - MYSQL_DATABASE=${MYSQL_DATABASE}    ports:      - \"6654:3306\"    volumes:      - db_data:/var/lib/mysql      - ./my.cnf:/etc/mysql/my.cnf      - ./init.sql:/docker-entrypoint-initdb.d/init.sql    networks:      - mynetworkvolumes:  db_data:networks:  mynetwork:    driver: bridge```환경 변수 설정환경 변수 파일을 .env 혹은 .env_example로 구성하여 쉽게 관리할 수 있습니다. 아래는 기본적인 환경 변수 예시입니다:# MySQL 관련 환경 변수DB_HOST=mysqlDB_PORT=3306DB_USER=rootDB_PASSWORD=yo!ur_PWDB_NAME=database_name# 개발 환경 변수IS_DEV=true# MySQL 관련 설정MYSQL_ROOT_PASSWORD=yo!ur_PWMYSQL_DATABASE=database_name주요 설정 설명  백엔드 서비스: 백엔드는 backend라는 서비스명으로 구성되며, 필요한 환경 변수는 .env 파일에서 정의합니다. 만약 데이터베이스 정보가 변경되면 해당 정보만 업데이트해 쉽게 연결할 수 있습니다.      프론트엔드 서비스: 현재는 주석 처리되어 있지만, 필요에 따라 프론트엔드를 추가할 수 있습니다. 기본적으로 Next.js나 React.js와 같은 프레임워크를 사용하는 경우 쉽게 확장 가능합니다. 원래 코드에선 starter_pack으로 구성했었으나 관심사를 분리하고싶다는 생각에 front코드는 starter_pack_front 단으로 분리해놓은 상태입니다.    MySQL 서비스: 데이터베이스로 MySQL을 사용하며, 6654 포트를 통해 외부에서 접근할 수 있습니다. MySQL 설정 파일(my.cnf)과 초기 스크립트(init.sql)도 마운트하여 초기화 과정을 자동화할 수 있습니다.  DB 초기 구성 스크립트에는 전 포트를 허용해주는 설정과 PASSWORD 구성에대한 SQL 스크립트로 구성되었습니다. 해당 설정을 무조건적으로 따르는것이 아닌 각자의 보안적 요소에 맞게 수정하도록 합시다.사용 방법이 컴포즈 파일을 사용하려면 .env_example 파일에서 _example을 지운 후 사용하고자 하는 환경 변수 값을 입력해 주세요. 예를 들어, 데이터베이스의 이름이나 비밀번호가 변경될 경우 -v 옵션을 사용해 볼륨을 초기화한 후 다시 실행하면 됩니다.docker-compose down -vdocker-compose up --build이렇게 하면 모든 설정이 적용된 상태로 컨테이너들이 실행됩니다.마무리이 스타터팩을 사용하면 새로운 프로젝트를 시작할 때나 MSA 구조를 구성할 때 훨씬 더 효율적으로 작업을 진행할 수 있습니다. 앞으로도 새로운 설정과 개선사항을 추가하며 이 스타터팩을 발전시킬 계획입니다.필요한 설정이 있다면 자유롭게 변경하고, 개선된 사항이 있다면 공유해 주시면 감사하겠습니다.  Tip: docker-compose.yml 파일 내에서 불필요한 설정은 주석 처리해두었으니, 사용 시 주석을 해제하거나 필요에 따라 수정해 주세요.태그: docker, msa, docker-compose, backend, mysql이 포스팅은 MSA 환경에서 반복적인 도커 설정을 피하기 위해 만든 스타터팩을 설명하는 데 중점을 두고 있습니다. 원하는 대로 추가 수정하여 사용하실 수 있습니다."
  },
  
  {
    "title": "온프라미스 환경에서 쿠버네티스 클러스트 구성하기:macos에서 multipass를 이용한 vm구성",
    "url": "/posts/%EC%98%A8%ED%94%84%EB%9D%BC%EB%AF%B8%EC%8A%A4-%ED%99%98%EA%B2%BD%EC%97%90%EC%84%9C-%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%8A%B8-%EA%B5%AC%EC%84%B1%ED%95%98%EA%B8%B0-MacOS%EC%97%90%EC%84%9C-Multipass%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-VM%EA%B5%AC%EC%84%B1/",
    "categories": "",
    "tags": "",
    "date": "2024-09-04 00:00:00 +0900",
    





    
    "snippet": "해당 블로그 글에서 Docker 설치 및 테스트 과정을 추가하여 수정해보겠습니다.layout: posttitle: “온프라미스 환경에서 쿠버네티스 클러스터 구성하기: macOS에서 Multipass를 이용한 우분투 VM 설정”date: 2024-09-04categories: kubernetestags: [kubernetes, VM, Docker]온프라...",
    "content": "해당 블로그 글에서 Docker 설치 및 테스트 과정을 추가하여 수정해보겠습니다.layout: posttitle: “온프라미스 환경에서 쿠버네티스 클러스터 구성하기: macOS에서 Multipass를 이용한 우분투 VM 설정”date: 2024-09-04categories: kubernetestags: [kubernetes, VM, Docker]온프라미스 환경에서 쿠버네티스 클러스터 구성하기: macOS에서 Multipass를 이용한 우분투 VM 설정온프라미스 환경에서 쿠버네티스(Kubernetes) 클러스터를 구성하는 것은 클라우드 환경에서의 설정과는 다른 경험을 제공합니다. 특히, macOS 환경에서 Multipass를 활용하여 쿠버네티스 클러스터를 설정하는 과정은 실제 프로덕션 환경과 유사한 환경을 구현하는 데 큰 도움이 됩니다. 이번 글에서는 Multipass를 이용하여 Ubuntu 가상 머신(VM)을 설정하고, Docker를 설치한 후, 쿠버네티스를 설치하는 방법을 소개합니다.1. Multipass 설치먼저, macOS에 Multipass를 설치해야 합니다. Multipass는 경량의 VM을 쉽게 생성하고 관리할 수 있도록 도와주는 도구입니다. 홈브루(Homebrew)를 사용하여 Multipass를 설치할 수 있습니다.brew install --cask multipass위 명령어를 실행하면, macOS에 Multipass가 설치됩니다. 설치가 완료되면 터미널에서 multipass 명령어를 사용할 수 있게 됩니다.2. Ubuntu 가상 머신 생성쿠버네티스를 설치할 환경으로 사용할 Ubuntu VM을 생성합니다. CPU, 메모리, 디스크 용량을 지정하여 VM을 생성할 수 있습니다. 아래 명령어를 사용하여 이름이 ubuntu-k8s인 VM을 생성합니다.multipass launch --name ubuntu-k8s --cpus 2 --memory 4G --disk 20G  --name ubuntu-k8s: 생성할 VM의 이름을 지정합니다.  --cpus 2: 2개의 CPU 코어를 할당합니다.  --memory 4G: 4GB의 메모리를 할당합니다.  --disk 20G: 20GB의 디스크 용량을 할당합니다.명령어를 실행하면 Ubuntu가 설치된 VM이 생성되며, 이 VM은 쿠버네티스를 구성할 기본 환경이 됩니다.3. Ubuntu VM에 접속하기VM이 생성된 후, 아래 명령어를 통해 ubuntu-k8s VM에 접속합니다.multipass shell ubuntu-k8s이제 Ubuntu 환경에 접속한 상태로, 여기서부터는 Docker 설치와 관련된 작업을 진행할 수 있습니다.4. Docker 설치 및 테스트쿠버네티스를 설치하기 전에, 먼저 Docker를 설치하여 환경이 올바르게 구성되었는지 확인해야 합니다. Docker는 쿠버네티스에서 컨테이너를 관리하는 데 필수적인 도구입니다.# 기존 도커 삭제for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done# Add Docker's official GPG key:sudo apt-get updatesudo apt-get install ca-certificates curlsudo install -m 0755 -d /etc/apt/keyringssudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.ascsudo chmod a+r /etc/apt/keyrings/docker.asc# Add the repository to Apt sources:echo \\  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\  $(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\") stable\" | \\  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/nullsudo apt-get update혹은 최신버전의 도커와 우분투를 다운로드하여 실행한다는 가정하에는 아래와 같은 명령어를 이용할 수 있습니다sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin테스트sudo docker run hello-world위 명령어를 실행하면 Docker가 올바르게 설치되었는지 확인할 수 있습니다. hello-world 컨테이너가 정상적으로 실행되면, Docker가 성공적으로 설치된 것입니다.5. 쿠버네티스 설치 및 설정Docker가 정상적으로 설치된 후, 이제 쿠버네티스를 설치할 차례입니다. 먼저 필수 패키지들을 설치하고, 쿠버네티스를 설치하기 위한 설정을 진행합니다.# 쿠버네티스 설치를 위한 필수 패키지 설치sudo apt-get install -y apt-transport-https ca-certificates curl# 쿠버네티스 apt 저장소 추가curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -sudo apt-add-repository \"deb http://apt.kubernetes.io/ kubernetes-xenial main\"# 쿠버네티스 설치sudo apt-get updatesudo apt-get install -y kubelet kubeadm kubectl# kubelet 자동 시작 설정sudo systemctl enable kubeletsudo systemctl start kubelet6. 쿠버네티스 클러스터 초기화이제 클러스터를 초기화합니다. 아래 명령어를 통해 마스터 노드를 초기화합니다.sudo kubeadm init --pod-network-cidr=192.168.0.0/16초기화가 완료되면, 클러스터에 대한 설정을 사용자 환경으로 복사합니다.mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config7. 네트워크 플러그인 설치쿠버네티스에서 Pod들이 통신할 수 있도록 네트워크 플러그인을 설치해야 합니다. 여기서는 Weave Net을 사용합니다.kubectl apply -f https://git.io/weave-kube-1.68. 클러스터 상태 확인설치가 완료된 후, 다음 명령어를 통해 쿠버네티스 클러스터의 상태를 확인할 수 있습니다.kubectl get nodes모든 노드가 Ready 상태로 표시되면, 쿠버네티스 클러스터가 정상적으로 설정된 것입니다.이번 글에서는 macOS에서 Multipass를 이용해 Ubuntu VM을 생성하고, Docker를 설치한 후, 쿠버네티스를 설치하는 과정을 다루었습니다. 이를 통해 온프라미스 환경에서의 쿠버네티스 설정 과정을 체험해볼 수 있습니다. 이 과정을 바탕으로 다양한 쿠버네티스 구성 및 테스트를 진행해볼 수 있을 것입니다."
  },
  
  {
    "title": "배포자동화를 위한 self Hosted Runner구축",
    "url": "/posts/%EB%B0%B0%ED%8F%AC%EC%9E%90%EB%8F%99%ED%99%94%EB%A5%BC-%EC%9C%84%ED%95%9C-self-hosted-runner%EA%B5%AC%EC%B6%95/",
    "categories": "",
    "tags": "",
    "date": "2024-08-27 00:00:00 +0900",
    





    
    "snippet": "GitHub Actions Self-Hosted Runner 구성 및 배포 자동화현대 소프트웨어 개발에서는 자동화된 배포 프로세스가 필수적입니다. 이 블로그 포스트에서는 로컬 호스트 머신에서 SSH 키를 생성하고, 이를 사용하여 도커 컨테이너 내에서 GitHub Actions Self-Hosted Runner를 구성하는 방법을 알아보겠습니다. 최종적으...",
    "content": "GitHub Actions Self-Hosted Runner 구성 및 배포 자동화현대 소프트웨어 개발에서는 자동화된 배포 프로세스가 필수적입니다. 이 블로그 포스트에서는 로컬 호스트 머신에서 SSH 키를 생성하고, 이를 사용하여 도커 컨테이너 내에서 GitHub Actions Self-Hosted Runner를 구성하는 방법을 알아보겠습니다. 최종적으로 이 Runner를 통해 도커 컨테이너에서 호스트 머신으로 SSH 접근을 하여 배포 작업을 자동화하는 방법도 다룰 것입니다.1. SSH 키 생성 및 설정먼저, 도커 컨테이너에서 사용할 SSH 키를 호스트 머신에서 생성해야 합니다. 이 SSH 키는 도커 컨테이너에서 호스트 머신으로의 원격 접근을 허용하는 데 사용됩니다.1.1. SSH 키 생성아래 명령어를 사용하여 호스트 머신에 SSH 키를 생성합니다:ssh-keygen -t rsa -b 4096 -f ~/.ssh/host_rsa -N \"\"chmod 600 ~/.ssh/host_rsa  ~/.ssh/host_rsa: 생성된 개인 키의 경로입니다.  ~/.ssh/host_rsa.pub: 생성된 공개 키의 경로입니다.1.2. 공개 키를 authorized_keys에 추가생성된 공개 키를 authorized_keys에 추가하여 호스트 머신이 SSH 연결을 허용하도록 설정합니다:cat ~/.ssh/host_rsa.pub &gt;&gt; ~/.ssh/authorized_keys이제 호스트 머신에 SSH 연결을 허용하는 설정이 완료되었습니다.2. 도커 컨테이너 구성이제 GitHub Actions Self-Hosted Runner를 실행할 도커 컨테이너를 구성할 차례입니다. 컨테이너는 호스트 머신의 SSH 키를 사용하여 원격 접근을 수행할 수 있습니다.2.1. 도커 설치 (필요한 경우)호스트 머신에 Docker가 설치되어 있지 않은 경우 아래 명령어로 Docker를 설치할 수 있습니다:sudo apt-get updatesudo apt-get install -y docker.io2.2. 도커 이미지 생성도커 이미지를 생성하기 위해 Dockerfile을 작성합니다. 이 Dockerfile은 Self-Hosted Runner를 설정하고, 호스트 머신에 SSH로 접근할 수 있는 환경을 구성합니다:FROM ubuntu:20.04ENV DEBIAN_FRONTEND=noninteractiveRUN apt-get update &amp;&amp; \\    apt-get install -y curl jq git build-essential &amp;&amp; \\    apt-get cleanRUN useradd -m runnerENV RUNNER_VERSION=2.296.0ENV RUNNER_URL=https://github.com/actions/runner/releases/download/v${RUNNER_VERSION}/actions-runner-linux-x64-${RUNNER_VERSION}.tar.gzRUN mkdir /runnerWORKDIR /runnerRUN curl -o actions-runner-linux-x64.tar.gz -L ${RUNNER_URL} &amp;&amp; \\    tar xzf actions-runner-linux-x64.tar.gz &amp;&amp; \\    rm -f actions-runner-linux-x64.tar.gzRUN ./bin/installdependencies.shCOPY entrypoint.sh /runner/RUN chmod +x /runner/entrypoint.shRUN chown -R runner:runner /runnerUSER runnerENTRYPOINT [\"/runner/entrypoint.sh\"]2.3. Entry Point Script 작성도커 컨테이너 내에서 Runner를 실행하기 위한 스크립트를 작성합니다. 이 스크립트는 Runner를 설정하고 GitHub Actions에서 사용할 수 있도록 합니다:#!/bin/bashif [ -z \"$GITHUB_REPOSITORY\" ] || [ -z \"$GITHUB_RUNNER_TOKEN\" ]; then  echo \"GITHUB_REPOSITORY 및 GITHUB_RUNNER_TOKEN 환경 변수가 설정되지 않았습니다.\"  exit 1fi./config.sh --url https://github.com/${GITHUB_REPOSITORY} --token ${GITHUB_RUNNER_TOKEN} --unattended --replace./run.sh2.4. 도커 이미지 빌드 및 컨테이너 실행위에서 작성한 Dockerfile과 entrypoint.sh 스크립트를 사용해 도커 이미지를 빌드하고, 컨테이너를 실행합니다:cd /home/ai-server/github-runnerdocker build -t github-runner .docker run -d --name github-runner \\  -v ~/.ssh/host_rsa:/home/runner/.ssh/id_rsa \\  -v ~/.ssh/host_rsa.pub:/home/runner/.ssh/id_rsa.pub \\  -e GITHUB_REPOSITORY=레포내의 소유자이름/레포이름을 기입합니다 \\  -e GITHUB_RUNNER_TOKEN=레포내의 Settings에 들어가 액션탭에서 runner를 눌러 토큰을 가져옵니다 \\  github-runner컨테이너가 정상적으로 실행되면, SSH 연결이 원활히 이루어지는지 확인합니다:ssh-keyscan -H 192.168.0.xxxx &gt;&gt; /home/runner/.ssh/known_hosts도커 컨테이너 내에서 SSH 설정을 확인해 볼 수 있습니다:docker exec -it github-runner /bin/bashls -l /home/runner/.ssh/3. 배포 스크립트 구성이제 배포를 자동화할 스크립트를 작성할 차례입니다. 이 스크립트는 호스트 머신에서 최신 코드를 가져와 빌드한 후, 애플리케이션을 재시작합니다.3.1. 배포 스크립트 작성배포 작업을 수행하는 스크립트를 아래와 같이 작성합니다:#!/bin/bashexport NVM_DIR=\"$HOME/.nvm\"[ -s \"$NVM_DIR/nvm.sh\" ] &amp;&amp; \\. \"$NVM_DIR/nvm.sh\"nvm use 16.14.2cd 깃활성화된 개발 경로CURRENT_URL=$(git remote get-url origin)if [[ \"$CURRENT_URL\" == https://github.com/* ]]; then  git remote set-url origin SSH로 접근하기 위한 깃 URLfieval \"$(ssh-agent -s)\"ssh-add ~/.ssh/deploy_key#깃에 SSH로접근하기위해 사전 설정해둔 토큰 키git pull origin mainif [ $? -ne 0 ]; then  exit 1finpm installif [ $? -ne 0 ]; then  exit 1finpm run buildif [ $? -ne 0 ]; then  exit 1fipm2 restart ecosystem.config.jsif [ $? -ne 0 ]; then  exit 1fi이 스크립트에 실행 권한을 부여합니다:chmod +x /배포 스크립트 경로/deploy.sh4. GitHub Actions에서 배포 트리거 설정GitHub Actions 워크플로우 파일을 통해 push 이벤트가 발생할 때마다 자동으로 배포 스크립트를 실행하도록 설정합니다.4.1. GitHub Actions Workflow 설정아래와 같은 Workflow 파일을 작성하여 main 브랜치에 푸시될 때 자동으로 배포 작업이 실행되도록 합니다:name: Deploy via SSHon:  push:    branches:      - mainjobs:  deploy:    runs-on: self-hosted    steps:      - name: Checkout code        uses: actions/checkout@v2      - name: SSH and Execute Deploy Script        run: |          ssh -i /home/runner/.ssh/id_rsa -o StrictHostKeyChecking=no $@$ 'bash /Users/sin-yunsu/Documents/GitHub/레포/deploy.sh'        env:          SSH_USER: $          SSH_HOST: $시크릿 키의 경우는 Settings탭에서 레포단위의 환경변술를 설정 할 수 있습니다.5. 요약이 포스트에서는 로컬 호스트 머신에 SSH 키를 생성하고, 도커 컨테이너 내에서 GitHub Actions Self-Hosted Runner를 실행하는 과정을 설명했습니다. 또한, 도커 컨테이너가 호스트 머신에 접근하여 배포 스크립트를 자동으로 실행할 수 있도록 설정하는 방법을 다루었습니다. 이와 같은 설정을 통해 자동화된 배포 환경을 구축할 수 있습니다.이제 여러분의 프로젝트에도 이러한 자동화된 배포 프로세스를 도입하여 생산성을 극대화해 보세요!"
  },
  
  {
    "title": "Msa 도입이 적절한 경우",
    "url": "/posts/MSA-%EB%8F%84%EC%9E%85%EC%9D%B4-%EC%A0%81%EC%A0%88%ED%95%9C-%EA%B2%BD%EC%9A%B0/",
    "categories": "",
    "tags": "",
    "date": "2024-08-27 00:00:00 +0900",
    





    
    "snippet": "마이크로서비스 아키텍처(MSA) 도입 고려사항1. 프로세스 영향력 및 성능 측정마이크로서비스 아키텍처(MSA)를 도입할 때, 각 프로세스의 영향력을 정확히 측정하는 것이 중요합니다. 이를 위해, 예거(Jaeger)와 같은 분산 추적 도구를 활용해 각 서비스의 처리 시간과 영향도를 평가할 수 있습니다. 이러한 도구는 서비스 간의 의존성을 분석하고, 병목...",
    "content": "마이크로서비스 아키텍처(MSA) 도입 고려사항1. 프로세스 영향력 및 성능 측정마이크로서비스 아키텍처(MSA)를 도입할 때, 각 프로세스의 영향력을 정확히 측정하는 것이 중요합니다. 이를 위해, 예거(Jaeger)와 같은 분산 추적 도구를 활용해 각 서비스의 처리 시간과 영향도를 평가할 수 있습니다. 이러한 도구는 서비스 간의 의존성을 분석하고, 병목 현상이나 성능 저하가 발생하는 지점을 파악하는 데 도움을 줍니다.2. 데이터 일관성모놀리식 아키텍처에서는 모든 데이터가 하나의 데이터베이스에 저장되어 관리됩니다. 그러나 MSA로 전환할 경우, 데이터가 여러 데이터베이스에서 관리되며, 이로 인해 데이터 일관성에 문제가 발생할 수 있습니다. 과거에는 데이터베이스 트랜잭션에 의존하여 데이터 일관성을 유지했지만, 분산 시스템에서는 이러한 트랜잭션을 동일하게 적용하기 어렵습니다.대부분의 경우, 분산 트랜잭션을 사용하는 것은 상태 변경을 조정하는 데 매우 큰 문제가 될 수 있습니다. 이 문제를 해결하기 위해서는 SAGA 패턴과 궁극적 일관성(Eventual Consistency)과 같은 개념을 고려해야 합니다. 이러한 개념은 시스템의 데이터 관리 방식에 대한 근본적인 사고 방식을 변화시키며, 기존 시스템을 MSA로 마이그레이션할 때는 특히 어려운 과제가 될 수 있습니다.따라서 운영 환경의 아키텍처 변경에 따른 영향도를 평가하고, 점진적인 접근 방식을 채택하는 것이 매우 중요합니다. 이렇게 하면 변화에 따른 리스크를 최소화할 수 있습니다.3. MSA 도입이 적합하지 않은 경우도메인이 자주 변경되는 스타트업의 경우, MSA 도입은 신중하게 고려해야 합니다. 스타트업은 서비스 경계가 자주 변경되며, 이러한 변경에 따른 조정 비용이 상당할 수 있습니다. 서비스 경계가 안정화되지 않은 상태에서 MSA를 도입하면 오히려 개발과 운영의 복잡성을 증가시킬 수 있습니다.도메인 모델이 안정화된 후에 MSA를 도입하는 것이 바람직합니다. MSA 도입만으로도 자체 배포와 관리에 대한 부담이 증가하게 되며, 예를 들어 5명으로 구성된 팀에서 한 사람이 MSA 관리에 투입된다면, 제품 개발에 투입되는 시간이 줄어들게 됩니다.4. MSA 도입이 적합한 경우반면, 다음과 같은 경우에는 MSA 도입이 효과적일 수 있습니다:  개발자 간의 간섭을 최소화하고 동일한 환경에서 작업을 수행하기 위해: MSA는 조직 경계를 올바르게 설정하고 각 팀이 독립적으로 작업할 수 있도록 도와줍니다.  SaaS 애플리케이션의 경우: 독립적 배포의 필요성이 높은 상황에서 MSA는 유연성을 제공합니다.  시스템 부하에 대한 특성 파악이 가능한 경우: MSA를 통해 시스템 부하에 대한 합리적인 기준선을 설정할 수 있으며, 고효율로 작동하고 잘 통제될 수 있습니다.MSA는 잘 설계된 경우에 조직의 생산성과 시스템의 확장성을 크게 향상시킬 수 있습니다. 그러나 무조건적인 도입보다는, 조직의 특성과 도메인 안정성, 팀의 역량을 고려하여 신중하게 접근하는 것이 중요합니다.이 글은 마이크로서비스 아키텍처(MSA)의 도입을 고려하는 개발자와 팀에게 중요한 통찰을 제공합니다. MSA 도입의 장단점을 명확히 이해하고, 올바른 상황에서 적절하게 도입하는 것이 성공의 열쇠입니다."
  },
  
  {
    "title": "NestJS에서 API 생성 시 테스트 코드 작성 가이드",
    "url": "/posts/NestJS%EC%97%90%EC%84%9C-API-%EC%83%9D%EC%84%B1-%EC%8B%9C-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EC%BD%94%EB%93%9C-%EC%9E%91%EC%84%B1-%EA%B0%80%EC%9D%B4%EB%93%9C/",
    "categories": "NestJS, Testing, TypeScript",
    "tags": "NestJS, 테스트, Mock, 유닛 테스트, 통합 테스트",
    "date": "2024-08-25 10:00:00 +0900",
    





    
    "snippet": "NestJS에서 API 생성 시 테스트 코드 작성 가이드NestJS를 사용해 API를 개발할 때, 테스트 코드 작성은 필수적입니다. 특히, 모듈화된 구조와 의존성 주입(DI) 방식을 사용하는 NestJS에서는 테스트 코드 작성이 비교적 수월하지만, 초기 설정 과정에서 몇 가지 중요한 사항을 고려해야 합니다. 이 글에서는 API 생성 후 테스트 코드를 ...",
    "content": "NestJS에서 API 생성 시 테스트 코드 작성 가이드NestJS를 사용해 API를 개발할 때, 테스트 코드 작성은 필수적입니다. 특히, 모듈화된 구조와 의존성 주입(DI) 방식을 사용하는 NestJS에서는 테스트 코드 작성이 비교적 수월하지만, 초기 설정 과정에서 몇 가지 중요한 사항을 고려해야 합니다. 이 글에서는 API 생성 후 테스트 코드를 작성하기 위한 기본 설정과 Mock 설정 방법, 그리고 유의사항을 다룹니다.배경저는 개인 블로그를 만들어 포스팅된 글들을 관리하고, 방문자들의 반응을 추적하고 싶었습니다. 특히, 각 글이 얼마나 많은 조회수를 기록했는지 알고 싶었습니다.NestJS는 모듈화된 구조와 의존성 주입(DI) 방식을 통해 유지보수성과 확장성을 높여주는 훌륭한 프레임워크입니다. 하지만 개발 과정에서 가장 중요한 부분 중 하나는 테스트 코드 작성이었습니다. 서비스와 컨트롤러가 기대한 대로 동작하는지 확인하고, 추후 수정 및 확장 시 발생할 수 있는 문제를 미리 방지하기 위해서는 철저한 테스트가 필수적이었습니다.이 글에서는 제가 블로그 글의 조회수를 추적하는 API를 개발하며 사용한 테스트 코드 작성법을 소개합니다. API 생성 후 테스트 코드를 작성하기 위한 기본 설정과 Mock 설정 방법, 그리고 유의사항을 다루며, 여러분도 이와 같은 상황에서 쉽게 적용할 수 있도록 안내합니다.1. 초기 API 설정API를 개발할 때 먼저 리소스(Resource)를 생성합니다. NestJS CLI에서 resource 커맨드를 사용하면 컨트롤러(Controller), 서비스(Service), 그리고 관련된 모든 파일들을 자동으로 생성할 수 있습니다.nest g resource posts이 명령어를 통해 posts라는 이름의 리소스가 생성되며, 여기에 컨트롤러와 서비스가 포함됩니다. 이후, PostsController와 PostsService에서 기본적인 API 엔드포인트와 서비스 메소드를 작성할 수 있습니다.생성된 파일들은 프로젝트 구조에서 다음과 같이 나타나게 됩니다:src/└── posts/    ├── dto/    ├── entities/    │   └── post.entity.ts    ├── posts.controller.spec.ts    ├── posts.controller.ts    ├── posts.module.ts    ├── posts.service.spec.ts    └── posts.service.ts이 폴더 구조는 각각의 파일이 어떤 역할을 하는지 명확하게 나눠줍니다. entities 폴더에는 데이터베이스와 연관된 엔티티가, dto 폴더에는 데이터 전송 객체(DTO)가 위치하게 됩니다. 이 구조는 프로젝트의 유지보수성과 가독성을 높여줍니다.2. Post 엔티티 정의우선, 블로그 글에 대한 정보를 담고 있는 Post 엔티티를 정의합니다. 이 엔티티는 데이터베이스에 저장되는 테이블 구조를 정의하며, 블로그 글의 제목, 내용, 조회수, 작성 일자 등을 포함합니다.import {  Entity,  Column,  PrimaryGeneratedColumn,  CreateDateColumn} from \"typeorm\";@Entity(\"post\") // 테이블 이름을 스네이크 케이스로 설정export class Post {  @PrimaryGeneratedColumn({ name: \"id\" }) // 자동 생성된 기본 키 컬럼  id: number;  @Column({ name: \"title\" }) // 컬럼명을 스네이크 케이스로 지정  title: string;  @Column({ name: \"content\" })  content: string;  @Column({ name: \"is_published\", default: true }) // 컬럼명을 스네이크 케이스로 지정  isPublished: boolean;  @Column({ name: \"views\", default: 0 }) // 기본값을 0으로 설정하고 스네이크 케이스 적용  views: number;  @CreateDateColumn({ name: \"created_at\" }) // 자동 생성 시간 컬럼을 스네이크 케이스로 지정  createdAt: Date;}Post 엔티티는 다음과 같은 필드를 가집니다:  id: 자동 생성되는 고유 식별자  title: 블로그 글의 제목  content: 블로그 글의 내용  isPublished: 블로그 글이 발행되었는지 여부를 나타내는 boolean 값 (기본값: true)  views: 조회수 (기본값: 0)  createdAt: 글이 생성된 날짜와 시간을 자동으로 기록이 엔티티를 통해 데이터베이스 테이블이 생성되며, 이후 서비스에서 이 데이터를 관리하게 됩니다.3. 서비스 및 컨트롤러 구현이제 블로그 글의 조회수를 증가시키는 API를 구현합니다. 이 API는 특정 글의 조회수를 1 증가시키고, 업데이트된 글 데이터를 반환합니다.// posts.controller.tsimport { Controller, Patch, Param } from \"@nestjs/common\";import { PostsService } from \"./posts.service\";@Controller(\"posts\")export class PostsController {  constructor(private readonly postsService: PostsService) {}  @Patch(\":id/views\")  incrementViews(@Param(\"id\") id: string) {    return this.postsService.incrementViews(+id);  }}// posts.service.tsimport { Injectable, NotFoundException } from \"@nestjs/common\";import { InjectRepository } from \"@nestjs/typeorm\";import { Repository } from \"typeorm\";import { Post } from \"./entities/post.entity\";@Injectable()export class PostsService {  constructor(    @InjectRepository(Post)    private readonly postsRepository: Repository&lt;Post&gt;  ) {}  async incrementViews(id: number): Promise&lt;Post&gt; {    const post = await this.postsRepository.findOne({ where: { id } });    if (!post) {      throw new NotFoundException(`Post with id ${id} not found`);    }    post.views += 1;    return this.postsRepository.save(post);  }}4. 테스트 코드 작성NestJS에서는 @nestjs/testing 패키지를 사용하여 유닛 테스트와 통합 테스트를 손쉽게 작성할 수 있습니다. 여기서는 PostsService와 PostsController에 대한 유닛 테스트를 작성해보겠습니다.4.1. Mock 설정테스트 코드를 작성할 때 실제 데이터베이스를 사용하지 않도록 Repository를 Mock으로 설정합니다. 이를 통해 테스트의 독립성을 유지하고, 빠르고 안정적인 테스트를 수행할 수 있습니다.// posts.service.spec.tsimport { Test, TestingModule } from \"@nestjs/testing\";import { PostsService } from \"./posts.service\";import { getRepositoryToken } from \"@nestjs/typeorm\";import { Post } from \"./entities/post.entity\";import { Repository } from \"typeorm\";import { NotFoundException } from \"@nestjs/common\";const mockPostRepository = {  findOne: jest.fn(),  save: jest.fn()};describe(\"PostsService\", () =&gt; {  let service: PostsService;  let repository: Repository&lt;Post&gt;;  beforeEach(async () =&gt; {    const module: TestingModule = await Test.createTestingModule({      providers: [        PostsService,        {          provide: getRepositoryToken(Post),          useValue: mockPostRepository        }      ]    }).compile();    service = module.get&lt;PostsService&gt;(PostsService);    repository = module.get&lt;Repository&lt;Post&gt;&gt;(getRepositoryToken(Post));  });  it(\"should increment the views of the post\", async () =&gt; {    const postId = 1;    const post = { id: postId, views: 0 } as Post;    mockPostRepository.findOne.mockResolvedValue(post);    mockPostRepository.save.mockResolvedValue({ ...post, views: 1 });    const updatedPost = await service.incrementViews(postId);    expect(updatedPost.views).toBe(1);    expect(mockPostRepository.findOne).toHaveBeenCalledWith({      where: { id: postId }    });    expect(mockPostRepository.save).toHaveBeenCalledWith({ ...post, views: 1 });  });  it(\"should throw NotFoundException if post is not found\", async () =&gt; {    const postId = 999;    mockPostRepository.findOne.mockResolvedValue(null);    await expect(service.incrementViews(postId)).rejects.toThrow(      NotFoundException    );  });});4.2. 컨트롤러 테스트PostsController에서 PostsService의 메소드가 올바르게 호출되는지 테스트합니다.// posts.controller.spec.tsimport { Test, TestingModule } from \"@nestjs/testing\";import { PostsController } from \"./posts.controller\";import { PostsService } from \"./posts.service\";describe(\"PostsController\", () =&gt; {  let controller: PostsController;  let service: PostsService;  const mockPostsService = {    incrementViews: jest.fn()  };  beforeEach(async () =&gt; {    const module: TestingModule = await Test.createTestingModule({      controllers: [PostsController],      providers: [        {          provide: PostsService,          useValue: mockPostsService        }      ]    }).compile();    controller = module.get&lt;PostsController&gt;(PostsController);    service = module.get&lt;PostsService&gt;(PostsService);  });  it(\"should call incrementViews on the service with the correct id\", async () =&gt; {    const postId = \"1\";    const mockPost = { id: 1, views: 1 };    mockPostsService.incrementViews.mockResolvedValue(mockPost);    const result = await controller.incrementViews(postId);    expect(result).toEqual(mockPost);    expect(service.incrementViews).toHaveBeenCalledWith(1);  });});5. 테스트 실행테스트 코드를 작성한 후, npm test 명령어를 사용하여 테스트를 실행합니다. 모든 테스트가 성공해야 하며, 실패한 테스트가 있을 경우 코드를 다시 검토하고 수정합니다.npm test6. 유의사항  Mock 설정의 중요성: 실제 데이터베이스에 의존하지 않도록 Mock을 잘 설정해야 합니다. 이렇게 하면 테스트가 독립적으로 수행되며, 테스트가 실패해도 데이터베이스가 오염되지 않습니다.  에러 핸들링 테스트: 비정상적인 상황을 시뮬레이션하여 에러 핸들링이 제대로 이루어지는지 확인하는 테스트를 포함하는 것이 좋습니다.  테스트 코드의 유지보수: 코드 변경 시 테스트 코드도 함께 업데이트해야 합니다. 테스트 코드가 실제 코드와 일치하지 않으면 의미가 없습니다.결론NestJS에서 API를 생성할 때, 테스트 코드는 반드시 작성해야 할 중요한 요소입니다. 서비스와 컨트롤러 각각에 대해 유닛 테스트를 작성하고, 데이터베이스와의 상호작용은 Mock을 통해 처리하는 것이 좋은 접근 방식입니다. 이를 통해 안정적이고 유지보수 가능한 코드를 작성할 수 있습니다. NestJS의 유연한 테스트 모듈을 활용하여, 테스트 가능한 코드 구조를 만들고, 코드의 품질을 높여보세요.이제 폴더 구조와 해당 파일의 역할을 명시하여 독자들이 프로젝트 구조를 더 쉽게 이해하고, 테스트 코드를 작성하는 방법을 명확하게 따라할 수 있도록 했습니다."
  },
  
  {
    "title": "Nestjs와 typeorm을 사용한 mysql 데이터베이스 연결 및 설정",
    "url": "/posts/NestJS%EC%99%80-TypeORM%EC%9D%84-%EC%82%AC%EC%9A%A9%ED%95%9C-MySQL-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EC%97%B0%EA%B2%B0-%EB%B0%8F-%EC%84%A4%EC%A0%95/",
    "categories": "",
    "tags": "",
    "date": "2024-08-22 00:00:00 +0900",
    





    
    "snippet": "오늘의 개발 기록: NestJS와 TypeORM을 사용한 MySQL 데이터베이스 연결 및 설정오늘은 NestJS와 TypeORM을 활용하여 MySQL 데이터베이스에 연결하고, 환경 변수에 따라 설정을 다르게 적용하는 작업을 진행했습니다. 이 과정에서 환경에 따른 유연한 설정과 데이터베이스 관리의 중요성을 다시 한번 느낄 수 있었습니다. 이번 포스팅에서...",
    "content": "오늘의 개발 기록: NestJS와 TypeORM을 사용한 MySQL 데이터베이스 연결 및 설정오늘은 NestJS와 TypeORM을 활용하여 MySQL 데이터베이스에 연결하고, 환경 변수에 따라 설정을 다르게 적용하는 작업을 진행했습니다. 이 과정에서 환경에 따른 유연한 설정과 데이터베이스 관리의 중요성을 다시 한번 느낄 수 있었습니다. 이번 포스팅에서는 오늘 진행한 작업의 주요 내용을 정리해보겠습니다.기획 및 구성1.일단은 기존의 DB정보를 환경변수화 시켜서 깃으로부터 배포를 제한하도록해주고싶었습니다2.개발환경에서의 변경사항들을 DB에 실시간으로 동기화 해주는 기능을 추가하고 싶었습니다, 기존 회사코드는 generate를 이용해 수작업으로 적용시키고 있었는데 이를 배포환경에서만 구성해주고개발환경에서는 효율을 위해서 자동화 해주고싶었습니다.3.기존 회사 레거시에서는 entity의 파일들이 /entity 폴더에 나열되어있었습니다 즉 엔티티폴더안에 모두 넣어주고있었고 , 이는 강력한 nestJS의 CLI를 이용한 리소스를 생성했을시, 초기생성되는 구성과 폴더구조가 달라지는일로, 개발효율이 떨어지는 일이 생겼었습니다. 그리하여 이를 없애고자 CLI를 통해 생성한 엔티티를 그대로 적용하는 즉,모듈단위의 entity파일 구성으로 코드를 작성하고자 했습니다.2.DB의 초기 연결이 잘되었는지 로그로 기록하고싶었습니다1. 환경 변수와 설정 관리우선, ConfigModule과 ConfigService를 사용하여 환경 변수를 안전하게 관리하는 구조를 만들었습니다. NestJS의 ConfigModule을 글로벌로 설정하여, 모든 모듈에서 환경 변수를 쉽게 접근할 수 있도록 했습니다. 이를 통해 MySQL 데이터베이스 연결 정보를 안전하게 관리할 수 있었습니다.@Module({  imports: [    ConfigModule.forRoot({      isGlobal: true    }),    TypeOrmModule.forRootAsync({      imports: [ConfigModule],      inject: [ConfigService],      useFactory: (configService: ConfigService) =&gt; ({        type: \"mysql\",        host: configService.get(\"DB_HOST\") as string,        port: parseInt(configService.get(\"DB_PORT\") || \"3306\", 10),        username: configService.get(\"DB_USER\") as string,        password: configService.get(\"DB_PASSWORD\") as string,        database: configService.get(\"DB_NAME\") as string,        synchronize: configService.get(\"IS_DEV\") === \"true\",        autoLoadEntities: configService.get(\"IS_DEV\") === \"true\"      })    }),    PostsModule  ],  controllers: [AppController],  providers: [AppService]})export class AppModule implements OnModuleInit {  private readonly logger = new Logger(AppModule.name);  constructor(private connection: Connection) {}  async onModuleInit() {    try {      if (this.connection.isConnected) {        this.logger.log(\"Database connection established successfully.\");      } else {        this.logger.error(\"Database connection failed.\");      }    } catch (error) {      this.logger.error(        \"Error while checking database connection.\",        error.stack      );    }  }}2. synchronize와 autoLoadEntities 옵션의 차이점NestJS에서 TypeORM을 사용할 때 중요한 설정 중 하나는 synchronize와 autoLoadEntities 옵션입니다. 이 두 옵션의 역할을 명확히 이해하는 것이 데이터베이스 관리에서 매우 중요합니다.      synchronize: 엔티티(Entity)와 데이터베이스 테이블 간의 동기화를 자동으로 처리합니다. 개발 환경에서는 매우 유용하지만, 프로덕션 환경에서는 예상치 못한 데이터 손실을 방지하기 위해 이 옵션을 false로 설정하는 것이 좋습니다.        autoLoadEntities: 애플리케이션에서 정의된 모든 엔티티를 자동으로 로드합니다. 이 옵션은 개발 중에 모든 엔티티를 자동으로 로드할 수 있어 편리하지만, 프로덕션 환경에서는 상황에 따라 조절할 필요가 있습니다.  3. 모듈화된 엔티티 관리이번 작업에서는 각 모듈에서 엔티티를 관리하도록 구조를 설계했습니다. 예를 들어, PostsModule은 자신의 엔티티를 직접 관리합니다. 이를 통해 모듈 간의 의존성을 줄이고, 코드의 유지보수성을 높일 수 있었습니다.import { Module } from \"@nestjs/common\";import { TypeOrmModule } from \"@nestjs/typeorm\";import { PostsService } from \"./posts.service\";import { PostsController } from \"./posts.controller\";import { Post } from \"./entities/post.entity\";@Module({  imports: [TypeOrmModule.forFeature([Post])],  controllers: [PostsController],  providers: [PostsService]})export class PostsModule {}4. 데이터베이스 연결 상태 확인 및 로깅OnModuleInit 인터페이스를 구현하여 데이터베이스 연결 상태를 확인하고, 이를 로깅하는 방식도 추가했습니다. 이 부분은 애플리케이션이 시작될 때 데이터베이스 연결이 성공적으로 이루어졌는지 확인하고, 문제가 있을 경우 적절한 조치를 취할 수 있게 해줍니다.async onModuleInit() {  try {    if (this.connection.isConnected) {      this.logger.log('Database connection established successfully.');    } else {      this.logger.error('Database connection failed.');    }  } catch (error) {    this.logger.error('Error while checking database connection.', error.stack);  }}5. 배운 점 및 개선 사항이번 작업을 통해 환경에 따라 유연하게 설정을 관리하는 것이 얼마나 중요한지 다시 한번 깨달았습니다. 특히, 프로덕션 환경에서는 자동 동기화를 피하고, 마이그레이션을 통한 스키마 관리를 더욱 강화할 필요가 있습니다. 또한, 로깅과 에러 처리를 통해 시스템의 신뢰성을 높이는 것도 중요하다는 점을 다시 한번 확인했습니다.앞으로의 작업에서는 데이터베이스 연결 실패 시 재시도 로직을 추가하거나, 환경 변수의 관리 방식을 더욱 효율적으로 개선해 나갈수도 있을것같습니다.다음계획으로는 연결한 데이터베이스를 바탕으로 작성한 블로그 글을 어떻게 저장하고 사진 및 동영상을 제공할것인지의 기획과 , 페이지별로의 트래픽분석 (하루 방문자수등등)을 고려한 post 테이블의 DBA를 해보고이를 insert하는 API와 컨트롤러를 제작해보고 배포합니다"
  },
  
  {
    "title": "Docker Compose란?",
    "url": "/posts/Docker-compose%EB%9E%80/",
    "categories": "",
    "tags": "",
    "date": "2024-08-09 00:00:00 +0900",
    





    
    "snippet": "Docker Compose: 개요 및 구현 방법Docker Compose는 여러 컨테이너를 정의하고 실행하는 데 사용되는 도구입니다. 특히, 여러 서비스가 상호 작용하는 복잡한 애플리케이션의 경우 유용합니다. Docker Compose를 사용하면 여러 컨테이너로 이루어진 애플리케이션을 쉽게 정의하고 배포할 수 있습니다.이 글에서는 Docker Comp...",
    "content": "Docker Compose: 개요 및 구현 방법Docker Compose는 여러 컨테이너를 정의하고 실행하는 데 사용되는 도구입니다. 특히, 여러 서비스가 상호 작용하는 복잡한 애플리케이션의 경우 유용합니다. Docker Compose를 사용하면 여러 컨테이너로 이루어진 애플리케이션을 쉽게 정의하고 배포할 수 있습니다.이 글에서는 Docker Compose의 기본 개념과 함께 이를 활용하여 애플리케이션을 구축하고 배포하는 방법을 단계별로 설명하겠습니다.1. Docker Compose란?Docker Compose는 docker-compose.yml이라는 파일을 사용하여 애플리케이션의 서비스, 네트워크, 볼륨 등을 정의합니다. docker-compose.yml 파일에 정의된 내용을 바탕으로 docker-compose up 명령어를 통해 모든 컨테이너를 일괄적으로 실행할 수 있습니다.주요 기능  멀티 컨테이너 애플리케이션: 복잡한 애플리케이션을 여러 컨테이너로 나누어 각각의 역할을 분리할 수 있습니다.  환경 설정 관리: 환경 변수, 네트워크 설정 등을 손쉽게 관리할 수 있습니다.  서비스 조정: 여러 서비스 간의 의존성 관리 및 자동 시작/종료가 가능합니다.  개발 환경 구축: 일관된 개발 환경을 유지할 수 있어 협업에 유리합니다.2. Docker Compose 설치설치 방법 (Linux/MacOS):Docker가 이미 설치되어 있다면 Docker Compose도 함께 설치되어 있을 가능성이 높습니다. 그러나 최신 버전을 설치하거나 확인하려면 다음 명령어를 사용할 수 있습니다.# Linux 설치 명령어sudo curl -L \"https://github.com/docker/compose/releases/download/$(curl -s https://api.github.com/repos/docker/compose/releases/latest | grep -oP '(?&lt;=tag_name\": \")[^\"]*')\" -o /usr/local/bin/docker-compose# 실행 권한 부여sudo chmod +x /usr/local/bin/docker-compose# 설치 확인docker-compose --version설치 방법 (Windows):Windows에서는 Docker Desktop을 설치하면 Docker Compose가 자동으로 포함됩니다.3. Docker Compose 구성 파일 작성 (docker-compose.yml)Docker Compose의 핵심은 docker-compose.yml 파일입니다. 이 파일에 모든 서비스, 볼륨, 네트워크 설정을 정의합니다.예제: 간단한 웹 애플리케이션아래는 간단한 웹 애플리케이션을 정의한 docker-compose.yml 파일의 예시입니다. 이 예제에서는 웹 서버(Nginx)와 데이터베이스(MySQL)를 정의합니다.version: \"3\"services:  web:    image: nginx:latest    ports:      - \"8080:80\"    volumes:      - ./html:/usr/share/nginx/html    depends_on:      - db  db:    image: mysql:latest    environment:      MYSQL_ROOT_PASSWORD: example_password      MYSQL_DATABASE: example_db      MYSQL_USER: example_user      MYSQL_PASSWORD: example_user_password    volumes:      - db_data:/var/lib/mysqlvolumes:  db_data:구성 파일 설명:  version: Docker Compose 파일의 버전입니다. 일반적으로 3 또는 그 이상의 버전을 사용합니다.  services: 각 서비스(컨테이너)를 정의하는 블록입니다.          web: Nginx 웹 서버를 실행하는 서비스입니다.                  image: 사용할 Docker 이미지를 지정합니다.          ports: 로컬 포트와 컨테이너 포트를 연결합니다.          volumes: 호스트 시스템의 디렉토리를 컨테이너 내부에 마운트합니다.          depends_on: db 서비스가 먼저 실행된 후 web 서비스가 실행되도록 설정합니다.                    db: MySQL 데이터베이스를 실행하는 서비스입니다.                  environment: MySQL 초기 설정을 위한 환경 변수를 정의합니다.          volumes: 데이터베이스 데이터를 지속적으로 저장할 볼륨을 설정합니다.                      volumes: 서비스 간에 공유되거나 지속적인 데이터를 저장할 볼륨을 정의합니다.4. Docker Compose 실행애플리케이션 시작docker-compose.yml 파일이 준비되었으면 다음 명령어로 애플리케이션을 실행할 수 있습니다.docker-compose up이 명령어는 모든 서비스(컨테이너)를 정의된 순서에 따라 시작합니다. 만약 백그라운드에서 실행하고 싶다면 -d 플래그를 추가합니다:docker-compose up -d애플리케이션 종료실행 중인 모든 서비스를 종료하려면 다음 명령어를 사용합니다.docker-compose down이 명령어는 모든 컨테이너를 중지하고, 생성된 네트워크와 볼륨을 삭제합니다(단, 명시적으로 정의된 볼륨은 삭제되지 않습니다).개별 서비스 실행 및 종료특정 서비스만 실행하거나 종료하려면 서비스 이름을 명령어 뒤에 추가합니다:# 특정 서비스 실행docker-compose up web# 특정 서비스 종료docker-compose stop web로그 확인모든 서비스의 로그를 실시간으로 확인하려면 다음 명령어를 사용합니다:docker-compose logs -f5. 실제 사용 사례다중 컨테이너 애플리케이션 배포실제 환경에서는 프론트엔드, 백엔드, 데이터베이스, 캐시 서버 등을 각각의 서비스로 나누어 Docker Compose를 통해 배포할 수 있습니다.예를 들어, Node.js 백엔드와 React 프론트엔드, Redis 캐시 서버를 사용하는 애플리케이션의 docker-compose.yml 파일은 다음과 같이 구성할 수 있습니다:version: \"3\"services:  frontend:    build: ./frontend    ports:      - \"3000:3000\"  backend:    build: ./backend    ports:      - \"5000:5000\"    depends_on:      - redis    environment:      REDIS_HOST: redis      REDIS_PORT: 6379  redis:    image: \"redis:alpine\"    ports:      - \"6379:6379\"이 설정은 프론트엔드와 백엔드의 개발 환경을 독립적으로 구성하면서, Redis와 같은 서비스를 공유하여 효율적인 작업이 가능합니다.6. Docker Compose의 고급 기능스케일링 (Scaling)Docker Compose를 사용하면 동일한 서비스를 여러 개의 인스턴스로 확장할 수 있습니다. 예를 들어, 웹 서버를 3개의 컨테이너로 확장하려면 다음 명령어를 사용합니다:docker-compose up --scale web=3이 기능은 특히 부하 분산이나 고가용성을 필요로 하는 환경에서 유용합니다.환경 변수 파일 (.env)Docker Compose는 .env 파일을 통해 환경 변수를 설정할 수 있습니다. 예를 들어, 다음과 같은 .env 파일을 작성할 수 있습니다:MYSQL_ROOT_PASSWORD=example_passwordMYSQL_DATABASE=example_db그 후 docker-compose.yml 파일에서 이를 참조할 수 있습니다:environment:  - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}  - MYSQL_DATABASE=${MYSQL_DATABASE}결론Docker Compose는 다중 컨테이너 애플리케이션의 배포 및 관리에 매우 유용한 도구입니다. docker-compose.yml 파일을 통해 애플리케이션의 모든 측면을 정의하고, 단일 명령어로 모든 서비스를 일관되게 실행할 수 있습니다. 이를 통해 개발자는 일관된 환경을 유지하고, 복잡한 애플리케이션을 효율적으로 관리할 수 있습니다.이제 Docker Compose를 사용하여 자신의 프로젝트에 맞는 환경을 구축해보세요. Docker Compose의 강력한 기능을 활용하면 배포, 테스트, 개발 과정이 훨씬 간단해질 것입니다."
  },
  
  {
    "title": "Frigate 설치 및 설정 가이드 (도커 사용)",
    "url": "/posts/%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4-NVR-Frigate-%EA%B5%AC%EC%84%B1%ED%95%98%EA%B8%B0/",
    "categories": "NVR, Home Assistant",
    "tags": "Frigate, Docker, Home Automation, Surveillance",
    "date": "2024-08-07 00:00:00 +0900",
    





    
    "snippet": "Frigate는 실시간 객체 감지 기능을 제공하는 NVR(Network Video Recorder) 오픈소스 소프트웨어입니다. 홈 어시스턴트와도 통합이 가능하여, 스마트 홈 시스템에서 비디오 감시를 효율적으로 관리할 수 있게 해줍니다. Frigate는 딥러닝을 활용하여 영상에서 사람, 차량 등의 객체를 실시간으로 감지하며, 이 모든 처리는 로컬에서 수...",
    "content": "Frigate는 실시간 객체 감지 기능을 제공하는 NVR(Network Video Recorder) 오픈소스 소프트웨어입니다. 홈 어시스턴트와도 통합이 가능하여, 스마트 홈 시스템에서 비디오 감시를 효율적으로 관리할 수 있게 해줍니다. Frigate는 딥러닝을 활용하여 영상에서 사람, 차량 등의 객체를 실시간으로 감지하며, 이 모든 처리는 로컬에서 수행되어 개인 정보 보호에도 유리합니다.Frigate 설치 및 설정 방법 (도커 사용)사전 준비물  Docker가 설치된 시스템  Docker Compose (선택사항, Docker Compose를 사용하는 경우)  한 개 이상의 IP 카메라 또는 네트워크에 연결된 카메라일단 첫번째로 도커를 다운로드 받습니다도커 공식홈페이지 docker --version docker-compose --version다운로드한 도커가 잘 다운받아졌는지 확인해봅니다docker-compose란?1. 깃허브에서 Frigate 소스 가져오기Frigate를 구성하시려면 일단은 깃허브에서 해당 소스를 다운로드받아야합니다.도커 공식홈페이지https://github.com/blakeblackshear/frigate.git2. 디렉토리 설정.├── docker-compose.yml├── config/└── storage/3. Docker Compose 파일 작성Docker Compose를 사용하여 Frigate를 실행하려면 docker-compose.yml 파일을 작성해야 합니다. 다음은 기본적인 Docker Compose 구성의 예시입니다:version: \"3.9\"services:  frigate:    container_name: frigate    restart: unless-stopped    image: ghcr.io/blakeblackshear/frigate:stable    volumes:      - ./config:/config      - ./storage:/media/frigate      - type: tmpfs # Optional: 1GB of memory, reduces SSD/SD Card wear        target: /tmp/cache        tmpfs:          size: 1000000000    ports:      - \"8971:8971\"      - \"8554:8554\" # RTSP feeds4. Frigate 실행Docker Compose 파일과 구성 파일을 준비한 후, Frigate 서비스를 시작하려면 다음 명령어를 사용합니다:docker-compose up -d5. 웹 인터페이스 접근Frigate가 실행되면, 웹 브라우저를 통해 https://&lt;your-server-ip&gt;:8971 혹은 https://localhost:8971주소로 접속할 수 있습니다. 여기에서 실시간 비디오 스트림을 볼 수 있고, 감지된 객체의 이벤트와 기록도 확인할 수 있습니다.접속에 성고했다면 로그인 페이지가 나올텐데 , 해당 페이지의 초기설정값은docker logs frigate 의 명령어로 찾을 수 있습니다로그인에 성공한 이후 좌측하단의 설정 톱니바퀴를 눌러 Configuration editor에서 카메라 설정을 변경할 수 있습니다.자세한 문서는 아래의 글을 확인해 주세요기본적으로 도커내의 환경에서 구동되는 NVR을 만나 볼 수 있을겁니다."
  },
  
  {
    "title": "리액트의 useState훅을 깊이 있게 이해하기",
    "url": "/posts/%EB%A6%AC%EC%95%A1%ED%8A%B8%EC%9D%98-useState%ED%9B%85%EC%9D%84-%EA%B9%8A%EC%9D%B4-%EC%9E%88%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0/",
    "categories": "\\[React,, JavaScript,, Web, Development\\]",
    "tags": "\\[React,useState\\]",
    "date": "2024-06-19 00:00:00 +0900",
    





    
    "snippet": "리액트의 상태관리훅의 기본이 되는  useState훅을 깊이 있게 이해하는것이 이번 포스팅의 목적입니다.useState 기본 예시리액트 컴포넌트에서 useState 훅을 사용하는 기본적인 예시는 다음과 같습니다.import React, { useState } from \"react\";function Counter() {  // count라는 상태 변수와...",
    "content": "리액트의 상태관리훅의 기본이 되는  useState훅을 깊이 있게 이해하는것이 이번 포스팅의 목적입니다.useState 기본 예시리액트 컴포넌트에서 useState 훅을 사용하는 기본적인 예시는 다음과 같습니다.import React, { useState } from \"react\";function Counter() {  // count라는 상태 변수와 이를 갱신할 setCount 함수를 선언합니다.  const [count, setCount] = useState(0);  return (    &lt;div&gt;      &lt;p&gt;You clicked {count} times&lt;/p&gt;      &lt;button onClick={() =&gt; setCount(count + 1)}&gt;Click me&lt;/button&gt;    &lt;/div&gt;  );}export default Counter;이 예시에서 useState 훅을 사용하여 count 상태와 setCount 상태 갱신 함수를 생성했습니다. 버튼을 클릭하면 setCount 함수가 호출되어 count 상태가 갱신됩니다.사용방법에 대한 기본적인 예시는 위와같습니다. 상태를 만들고 해당 상태를 갱신해준다.사용법은 참 쉽지만 그 구현은 어떤식으로 되어있는지 원리도 알고 쓰는것과 모르고 쓰는것은 차이가 큽니다.이제 해당 훅이 어떤식으로 구현되는지 알아보도록 합니다.useState의 구현 원리useState 훅이 어떻게 동작하는지 살펴보겠습니다. useState의 실제 구현 코드를 보면 다음과 같은 형태를 띱니다.function useState(initialState) {  const dispatcher = resolveDispatcher();  return dispatcher.useState(initialState);}useState 함수는 내부적으로 resolveDispatcher 함수를 호출하여 디스패처를 가져오고 있습니다.디스패처(resolveDispatcher)resolveDispatcher 함수는 현재 활성화된 디스패처를 반환합니다. 리액트는 이 디스패처를 통해 현재 컴포넌트의 훅을 관리합니다.function resolveDispatcher() {  const dispatcher = ReactCurrentDispatcher.current;  if (dispatcher === null) {    throw new Error(      \"Invalid hook call. Hooks can only be called inside of the body of a function component.\"    );  }  return dispatcher;}ReactCurrentDispatcherReactCurrentDispatcher는 현재 활성화된 디스패처를 관리하는 객체입니다. 이 디스패처는 리액트가 훅을 호출할 때마다 해당 훅을 관리합니다.const ReactCurrentDispatcher = {  current: null};ReactCurrentDispatcher 객체는 리액트의 훅 시스템의 핵심입니다.훅을 호출할 때마다 현재 디스패처가 사용되어 올바른 훅 함수가 실행됩니다. 다만, resolveDispatcher 함수는 내부적으로 ReactCurrentDispatcher.current를 반환하는데, 이는 훅이 함수형 컴포넌트 내에서만 호출되어야 함을 보장합니다.즉 , 각 컴포넌트가 자신의 상태를 독립적으로 관리할 수 있도록 보장합니다. 디스패처는 각 컴포넌트의 렌더링 컨텍스트(context)에서 활성화되므로, 훅이 호출될 때 적절한 상태와 동작을 참조하게 되는것이죠.아래의 상황처럼 말입니다.function ComponentA() {  const [stateA, setStateA] = useState(0);  // ComponentA가 렌더링되는 동안 React는 ReactCurrentDispatcher.current를 ComponentA의 디스패처로 설정합니다.  // useState 호출 시, 이 디스패처가 사용됩니다.}function ComponentB() {  const [stateB, setStateB] = useState(0);  // ComponentB가 렌더링되는 동안 React는 ReactCurrentDispatcher.current를 ComponentB의 디스패처로 설정합니다.  // useState 호출 시, 이 디스패처가 사용됩니다.}위와같이 컴포넌트가  사용중인 디스패치에 대한 관리와 훅에대한 상태를 관리를 한다는것을 알았다면 , 실제 UI에 해당 훅들을 적용하는 과정을 설명해야합니다.리컨실러(Reconciler)와 훅 관리리액트의 리컨실러는 컴포넌트의 상태와 UI 업데이트를 관리합니다. 훅을 사용할 때마다 리액트는 컴포넌트의 상태를 추적하고, 이를 통해 효율적으로 업데이트를 처리합니다. 훅은 컴포넌트가 렌더링되는 순서대로 호출되어야 하며, 이 순서를 유지하여 일관성을 보장합니다.유즈 스테이트의 상세 구현useState 훅이 리컨실러 내부에서 어떻게 구현되는지는 리액트 코드베이스에서 확인할 수 있습니다. ReactFiberHooks.js 파일에서 훅의 구체적인 로직이 구현되어 있습니다. 예를 들어, useState는 다음과 같이 구현됩니다.//ReactFiberHooks.jsfunction basicStateReducer(state, action) {  return typeof action === \"function\" ? action(state) : action;}function useState(initialState) {  return useReducer(basicStateReducer, initialState);}useState는 내부적으로 useReducer를 사용하여 상태를 관리합니다.이는 리액트가 상태 관리의 일관성을 유지하고, 다양한 형태의 상태 갱신을 지원할 수 있게 합니다.다만, useReducer의 basicStateReducer는 상태가 함수인 경우에 대한 특별한 처리를 포함하는 단순한 리듀서입니다.useState 훅 구현: Reconciler 단계에서의 상세 분석리액트(React)의 훅(Hooks)은 함수형 컴포넌트에서 상태와 생명주기 기능을 사용할 수 있게 해주는 중요한 도구입니다.위에서 우리는 useState 훅의 기본 개념과 리액트 코어에서의 역할을 살펴보았습니다.우리는 유즈 스테이트가 리액트 코어 패키지의 리액트 디스패쳐(ReactCurrentDispatcher) 파일에서 관리된다는 것을 확인했습니다. 이번에는 이 디스패쳐가 어떻게 리컨실러 패키지와 상호작용하는지 살펴보겠습니다.ReactCurrentDispatcher와 Reconciler리액트의 ReactSharedInternals.js 파일에서 ReactCurrentDispatcher의 current 프로퍼티에 할당된 객체를 통해 useState를 사용합니다. 이는 리액트가 현재 활성화된 디스패쳐를 추적하여 올바른 훅을 호출할 수 있게 합니다. ReactFiberHooks.js 파일에서는 리컨실러(Reconciler) 단계에서 이 current 프로퍼티에 값을 할당합니다.// ReactSharedInternals.jsexport const ReactSharedInternals = {  ReactCurrentDispatcher  // 기타 내부 공유 객체들};// ReactFiberHooks.jsimport { ReactCurrentDispatcher } from \"./ReactSharedInternals\";// 마운트 및 업데이트 디스패쳐 설정function renderWithHooks(  current,  workInProgress,  Component,  props,  secondArg,  nextRenderExpirationTime) {  // 현재 디스패쳐를 마운트 디스패쳐로 설정  ReactCurrentDispatcher.current = HooksDispatcherOnMount;  // 훅 호출 및 컴포넌트 렌더링  const children = Component(props, secondArg);  // 완료 후 디스패쳐 초기화  ReactCurrentDispatcher.current = ContextOnlyDispatcher;  return children;}renderWithHooks 함수는 현재 렌더링 중인 컴포넌트와 작업 중인 컴포넌트를 처리합니다. 이 과정에서 훅의 상태를 초기화하고, 컴포넌트를 호출하여 렌더링 결과를 얻습니다.currentlyRenderingFiber와 같은 전역 변수를 사용하여 현재 렌더링 중인 컴포넌트의 상태를 추적합니다.리컨실러 단계의 역할리컨실러는 리액트 엘리먼트를 Fiber로 확장하여 훅의 정보를 포함하게 만듭니다. 이 과정은 리액트의 상태 관리와 UI 업데이트에서 매우 중요합니다.RenderWithHooks 함수renderWithHooks 함수는 리액트 컴포넌트를 호출하고, 훅을 할당하며, 이 과정에서 필요한 모든 로직을 처리합니다. 이 함수는 컴포넌트를 호출하여 결과를 얻고, 이를 가상 DOM(Virtual DOM)에 반영합니다.function renderWithHooks(  current,  workInProgress,  Component,  props,  secondArg,  nextRenderExpirationTime) {  renderExpirationTime = nextRenderExpirationTime;  currentlyRenderingFiber = workInProgress;  workInProgress.memoizedState = null;  workInProgress.updateQueue = null;  workInProgress.expirationTime = NoWork;  ReactCurrentDispatcher.current =    current === null || current.memoizedState === null      ? HooksDispatcherOnMount      : HooksDispatcherOnUpdate;  const children = Component(props, secondArg);  currentlyRenderingFiber = null;  renderExpirationTime = NoWork;  ReactCurrentDispatcher.current = ContextOnlyDispatcher;  return children;}3. useState훅의 구현리액트의 유즈 스테이트 훅은 두 가지 주요 상태에서 작동합니다: 마운트(Mount)와 업데이트(Update).mountState와 updateState 함수는 각각 초기 마운트와 업데이트 시 상태를 처리합니다. 초기 마운트 시 상태를 설정하고, 업데이트 시 펜딩된 액션을 처리하여 새로운 상태를 계산합니다.마운트 상태useState가 처음 호출될 때, 마운트 상태에서는 HooksDispatcherOnMount를 사용합니다. 이 디스패쳐는 mountState 함수를 호출하여 초기 상태를 설정합니다.function mountState(initialState) {  const hook = mountWorkInProgressHook();  if (typeof initialState === \"function\") {    initialState = initialState();  }  hook.memoizedState = hook.baseState = initialState;  const queue = (hook.queue = {    pending: null,    dispatch: null,    lastRenderedReducer: basicStateReducer,    lastRenderedState: initialState  });  const dispatch = (queue.dispatch = dispatchAction.bind(    null,    currentlyRenderingFiber,    queue  ));  return [hook.memoizedState, dispatch];}업데이트 상태컴포넌트가 업데이트될 때는 HooksDispatcherOnUpdate를 사용합니다. 이 디스패쳐는 updateState 함수를 호출하여 변경된 상태를 반영합니다.function updateState(initialState) {  const hook = updateWorkInProgressHook();  const queue = hook.queue;  const pending = queue.pending;  if (pending !== null) {    const first = pending.next;    let newState = hook.memoizedState;    let update = first;    do {      const action = update.action;      newState = queue.lastRenderedReducer(newState, action);      update = update.next;    } while (update !== pending.next);    queue.pending = null;    hook.memoizedState = newState;  }  return [hook.memoizedState, queue.dispatch];}4.RenderWithHooks 함수의 작동 원리current와 workInProgresscurrent는 현재 렌더링 중인 Fiber를 가리키며, workInProgress는 작업 중인 Fiber를 의미합니다. renderWithHooks 함수는 current와 workInProgress를 사용하여 상태를 관리합니다.컴포넌트 호출renderWithHooks 함수는 컴포넌트를 호출하여 children 변수를 설정합니다. 이 변수는 컴포넌트의 결과를 저장합니다.훅 할당훅 정보를 ReactCurrentDispatcher.current에 할당하여, 상황에 맞게 마운트 상태나 업데이트 상태를 처리합니다.상태 초기화컴포넌트가 렌더링을 마칠 때, 전역 변수를 초기화하여 다음 컴포넌트 작업에서 올바른 값을 사용할 수 있도록 합니다.currentlyRenderingFiber = null;workInProgressHook = null;currentHook = null;renderExpirationTime = NoWork;ReactCurrentDispatcher.current = ContextOnlyDispatcher;5. 요약리액트의 useState 훅은 리컨실러 단계에서 복잡한 상호작용을 통해 구현됩니다. renderWithHooks 함수는 훅 정보를 Fiber에 연결하고, 컴포넌트를 호출하여 상태를 관리합니다. 이 과정은 리액트의 상태 관리와 UI 업데이트에 매우 중요한 역할을 합니다."
  },
  
  {
    "title": "NestJS와 Angular: 철학과 설계의 유사성",
    "url": "/posts/NestJS%EC%99%80-Angular-%EC%B2%A0%ED%95%99%EA%B3%BC-%EC%84%A4%EA%B3%84%EC%9D%98-%EC%9C%A0%EC%82%AC%EC%84%B1/",
    "categories": "NestJS, Angular",
    "tags": "web framework, typescript",
    "date": "2024-06-18 00:00:00 +0900",
    





    
    "snippet": "NestJS는 Node.js를 위한 진보된 웹 프레임워크로, Angular의 철학과 디자인 패턴에 깊은 영향을 받아 개발되었습니다. 이는 두 프레임워크가 구조화된 모듈 시스템, 의존성 주입, 데코레이터 사용 등에서 많은 유사성을 가지게 합니다. 아래에서는 NestJS와 Angular의 주요 개념을 비교하면서, 코드 예제를 통해 구체적으로 설명해 보겠습...",
    "content": "NestJS는 Node.js를 위한 진보된 웹 프레임워크로, Angular의 철학과 디자인 패턴에 깊은 영향을 받아 개발되었습니다. 이는 두 프레임워크가 구조화된 모듈 시스템, 의존성 주입, 데코레이터 사용 등에서 많은 유사성을 가지게 합니다. 아래에서는 NestJS와 Angular의 주요 개념을 비교하면서, 코드 예제를 통해 구체적으로 설명해 보겠습니다.목차  모듈 시스템  의존성 주입 (Dependency Injection)  데코레이터 사용  파이프 (Pipes)  가드 (Guards)  인터셉터 (Interceptors)  미들웨어 (Middleware)  라우팅 (Routing)  테스트 (Testing)  커스텀 데코레이터 (Custom Decorators)  라이프사이클 훅 (Lifecycle Hooks)  결론모듈 시스템AngularAngular에서는 모듈이 @NgModule 데코레이터로 정의됩니다. 모듈은 컴포넌트, 서비스, 다른 모듈 등을 그룹화하여 애플리케이션을 구조화합니다.// Angular의 AppModuleimport { NgModule } from \"@angular/core\";import { BrowserModule } from \"@angular/platform-browser\";import { AppComponent } from \"./app.component\";@NgModule({  declarations: [AppComponent],  imports: [BrowserModule],  providers: [],  bootstrap: [AppComponent]})export class AppModule {}NestJSNestJS에서도 모듈이 @Module 데코레이터로 정의되며, 컨트롤러, 서비스, 다른 모듈 등을 포함합니다.// NestJS의 AppModuleimport { Module } from \"@nestjs/common\";import { AppController } from \"./app.controller\";import { AppService } from \"./app.service\";@Module({  imports: [],  controllers: [AppController],  providers: [AppService]})export class AppModule {}의존성 주입 (Dependency Injection)AngularAngular는 의존성 주입을 통해 컴포넌트나 서비스에 필요한 의존성을 주입합니다. @Injectable 데코레이터를 사용하여 서비스를 정의합니다.// Angular의 Serviceimport { Injectable } from \"@angular/core\";@Injectable({  providedIn: \"root\"})export class DataService {  constructor() {}  getData() {    return \"Hello Angular\";  }}// Angular의 Componentimport { Component } from \"@angular/core\";import { DataService } from \"./data.service\";@Component({  selector: \"app-root\",  template: ``})export class AppComponent {  data: string;  constructor(private dataService: DataService) {    this.data = this.dataService.getData();  }}NestJSNestJS는 Angular와 유사하게 @Injectable 데코레이터를 사용하여 서비스를 정의하고, 의존성을 주입합니다.// NestJS의 Serviceimport { Injectable } from \"@nestjs/common\";@Injectable()export class AppService {  getHello(): string {    return \"Hello NestJS\";  }}// NestJS의 Controllerimport { Controller, Get } from \"@nestjs/common\";import { AppService } from \"./app.service\";@Controller()export class AppController {  constructor(private readonly appService: AppService) {}  @Get()  getHello(): string {    return this.appService.getHello();  }}데코레이터 사용AngularAngular는 데코레이터를 사용하여 컴포넌트, 디렉티브, 파이프, 서비스 등을 정의합니다.// Angular의 Component 데코레이터import { Component } from \"@angular/core\";@Component({  selector: \"app-root\",  templateUrl: \"./app.component.html\",  styleUrls: [\"./app.component.css\"]})export class AppComponent {  title = \"app\";}NestJSNestJS는 데코레이터를 사용하여 컨트롤러, 라우트 핸들러, 모듈 등을 정의합니다.// NestJS의 Controller 데코레이터import { Controller, Get } from \"@nestjs/common\";@Controller(\"cats\")export class CatsController {  @Get()  findAll(): string {    return \"This action returns all cats\";  }}파이프 (Pipes)AngularAngular에서 파이프는 데이터를 변환하는 데 사용됩니다. 예를 들어, 날짜 형식을 변환하거나 텍스트를 소문자로 바꾸는 데 사용됩니다.// Angular의 파이프import { Pipe, PipeTransform } from \"@angular/core\";@Pipe({  name: \"capitalize\"})export class CapitalizePipe implements PipeTransform {  transform(value: string): string {    return value.charAt(0).toUpperCase() + value.slice(1);  }}NestJSNestJS에서도 파이프는 유효성 검사와 변환을 위해 사용됩니다. 예를 들어, 요청 데이터를 검증하거나 변환하는 데 사용됩니다.// NestJS의 파이프import {  PipeTransform,  Injectable,  ArgumentMetadata,  BadRequestException} from \"@nestjs/common\";@Injectable()export class ParseIntPipe implements PipeTransform&lt;string, number&gt; {  transform(value: string, metadata: ArgumentMetadata): number {    const val = parseInt(value, 10);    if (isNaN(val)) {      throw new BadRequestException(\"Validation failed\");    }    return val;  }}가드 (Guards)AngularAngular에서는 라우트 가드를 사용하여 특정 경로에 접근하기 전에 사용자의 인증 상태를 확인할 수 있습니다.// Angular의 AuthGuardimport { Injectable } from \"@angular/core\";import { CanActivate, Router } from \"@angular/router\";import { AuthService } from \"./auth.service\";@Injectable({  providedIn: \"root\"})export class AuthGuard implements CanActivate {  constructor(private authService: AuthService, private router: Router) {}  canActivate(): boolean {    if (this.authService.isLoggedIn()) {      return true;    } else {      this.router.navigate([\"login\"]);      return false;    }  }}NestJSNestJS에서도 가드는 요청이 처리되기 전에 특정 조건을 확인하는 데 사용됩니다. 주로 인증 및 권한 부여를 위해 사용됩니다.// NestJS의 AuthGuardimport { Injectable, CanActivate, ExecutionContext } from \"@nestjs/common\";import { Observable } from \"rxjs\";@Injectable()export class AuthGuard implements CanActivate {  canActivate(    context: ExecutionContext  ): boolean | Promise&lt;boolean&gt; | Observable&lt;boolean&gt; {    const request = context.switchToHttp().getRequest();    return validateRequest(request);  }}function validateRequest(request: any): boolean {  // 인증 로직을 여기에 추가  return true;}인터셉터 (Interceptors)AngularAngular에서 HTTP 인터셉터는 모든 HTTP 요청 및 응답을 가로채서 처리할 수 있습니다. 예를 들어, 공통 헤더를 추가하거나 오류를 처리하는 데 사용됩니다.// Angular의 HTTP 인터셉터import { Injectable } from \"@angular/core\";import {  HttpEvent,  HttpInterceptor,  HttpHandler,  HttpRequest} from \"@angular/common/http\";import { Observable } from \"rxjs\";@Injectable()export class AuthInterceptor implements HttpInterceptor {  intercept(    req: HttpRequest&lt;any&gt;,    next: HttpHandler  ): Observable&lt;HttpEvent&lt;any&gt;&gt; {    const authToken = \"my-auth-token\";    const authReq = req.clone({      headers: req.headers.set(\"Authorization\", `Bearer ${authToken}`)    });    return next.handle(authReq);  }}NestJSNestJS에서 인터셉터는 요청 및 응답을 가로채서 처리할 수 있습니다. 예를 들어, 로깅, 캐싱, 응답 데이터 변환 등을 처리할 수 있습니다.// NestJS의 인터셉터import {  Injectable,  NestInterceptor,  ExecutionContext,  CallHandler} from \"@nestjs/common\";import { Observable } from \"rxjs\";import { map } from \"rxjs/operators\";@Injectable()export class TransformInterceptor implements NestInterceptor {  intercept(context: ExecutionContext, next: CallHandler): Observable&lt;any&gt; {    return next.handle().pipe(map((data) =&gt; ({ data })));  }}미들웨어 (Middleware)AngularAngular는 미들웨어 개념이 없지만, 서비스나 다른 기법을 사용하여 비슷한 기능을 구현할 수 있습니다.NestJSNestJS에서는 미들웨어를 사용하여 요청 처리 전에 특정 작업을 수행할 수 있습니다.// NestJS의 미들웨어import { Injectable, NestMiddleware } from \"@nestjs/common\";import { Request, Response, NextFunction } from \"express\";@Injectable()export class LoggerMiddleware implements NestMiddleware {  use(req: Request, res: Response, next: NextFunction) {    console.log(`Request...`);    next();  }}라우팅 (Routing)AngularAngular는 @angular/router 모듈을 통해 클라이언트 사이드 라우팅을 지원합니다. 이를 통해 URL 경로에 따라 컴포넌트를 로드할 수 있습니다.// Angular의 라우팅 설정import { NgModule } from \"@angular/core\";import { RouterModule, Routes } from \"@angular/router\";import { HomeComponent } from \"./home/home.component\";import { AboutComponent } from \"./about/about.component\";const routes: Routes = [  { path: \"\", component: HomeComponent },  { path: \"about\", component: AboutComponent }];@NgModule({  imports: [RouterModule.forRoot(routes)],  exports: [RouterModule]})export class AppRoutingModule {}NestJSNestJS는 @nestjs/common 모듈을 통해 서버 사이드 라우팅을 지원합니다. 컨트롤러를 통해 URL 경로를 정의하고 핸들러를 지정할 수 있습니다.// NestJS의 라우팅 설정import { Controller, Get } from \"@nestjs/common\";@Controller(\"home\")export class HomeController {  @Get()  getHome(): string {    return \"Welcome to Home\";  }}@Controller(\"about\")export class AboutController {  @Get()  getAbout(): string {    return \"About Us\";  }}테스트 (Testing)AngularAngular는 Jasmine과 Karma를 통해 테스트 프레임워크를 제공합니다. 이를 통해 컴포넌트, 서비스 등을 단위 테스트할 수 있습니다.// Angular의 테스트 예제import { TestBed } from \"@angular/core/testing\";import { AppComponent } from \"./app.component\";describe(\"AppComponent\", () =&gt; {  beforeEach(async () =&gt; {    await TestBed.configureTestingModule({      declarations: [AppComponent]    }).compileComponents();  });  it(\"should create the app\", () =&gt; {    const fixture = TestBed.createComponent(AppComponent);    const app = fixture.componentInstance;    expect(app).toBeTruthy();  });});NestJSNestJS는 Jest를 통해 테스트 프레임워크를 제공합니다. 이를 통해 컨트롤러, 서비스 등을 단위 테스트할 수 있습니다.// NestJS의 테스트 예제import { Test, TestingModule } from \"@nestjs/testing\";import { AppController } from \"./app.controller\";import { AppService } from \"./app.service\";describe(\"AppController\", () =&gt; {  let appController: AppController;  beforeEach(async () =&gt; {    const app: TestingModule = await Test.createTestingModule({      controllers: [AppController],      providers: [AppService]    }).compile();    appController = app.get&lt;AppController&gt;(AppController);  });  it('should return \"Hello World!\"', () =&gt; {    expect(appController.getHello()).toBe(\"Hello World!\");  });});커스텀 데코레이터 (Custom Decorators)AngularAngular에서는 커스텀 데코레이터를 사용하여 클래스, 메서드, 속성에 메타데이터를 추가할 수 있습니다.// Angular의 커스텀 데코레이터function Log(target: any, propertyKey: string, descriptor: PropertyDescriptor) {  const originalMethod = descriptor.value;  descriptor.value = function (...args: any[]) {    console.log(      `Method ${propertyKey} called with args: ${JSON.stringify(args)}`    );    return originalMethod.apply(this, args);  };  return descriptor;}class ExampleService {  @Log  exampleMethod(arg1: string, arg2: number) {    return `${arg1} - ${arg2}`;  }}NestJSNestJS에서도 커스텀 데코레이터를 사용하여 라우트 핸들러에 메타데이터를 추가할 수 있습니다.// NestJS의 커스텀 데코레이터import { SetMetadata } from \"@nestjs/common\";export const Roles = (...roles: string[]) =&gt; SetMetadata(\"roles\", roles);import { Controller, Get } from \"@nestjs/common\";import { Roles } from \"./roles.decorator\";@Controller(\"users\")export class UserController {  @Get()  @Roles(\"admin\")  findAll() {    return \"This route is restricted to admin roles\";  }}라이프사이클 훅 (Lifecycle Hooks)AngularAngular는 컴포넌트의 생명주기 동안 특정 시점에 호출되는 여러 라이프사이클 훅을 제공합니다.// Angular의 라이프사이클 훅import { Component, OnInit, OnDestroy } from \"@angular/core\";@Component({  selector: \"app-example\",  template: `&lt;p&gt;Example component&lt;/p&gt;`})export class ExampleComponent implements OnInit, OnDestroy {  ngOnInit() {    console.log(\"Component initialized\");  }  ngOnDestroy() {    console.log(\"Component destroyed\");  }}NestJSNestJS는 모듈, 컨트롤러, 프로바이더 등의 생명주기 동안 특정 시점에 호출되는 여러 라이프사이클 훅을 제공합니다.// NestJS의 라이프사이클 훅import { Injectable, OnModuleInit, OnModuleDestroy } from \"@nestjs/common\";@Injectable()export class ExampleService implements OnModuleInit, OnModuleDestroy {  onModuleInit() {    console.log(\"Module initialized\");  }  onModuleDestroy() {    console.log(\"Module destroyed\");  }}결론NestJS는 Angular의 디자인 패턴을 채택하여, 엔터프라이즈 애플리케이션을 위한 견고한 아키텍처를 제공합니다. 모듈 시스템, 의존성 주입, 데코레이터의 사용 등에서 Angular와 많은 유사성을 보여줍니다. 이를 통해 개발자들은 Angular와 유사한 방식으로 NestJS 애플리케이션을 구조화하고, 쉽게 유지 보수할 수 있습니다.추가 설명환경Angular: 클라이언트 사이드 프레임워크로, 브라우저에서 동작하는 애플리케이션을 만듭니다. 주로 컴포넌트 기반으로 UI를 구축합니다.NestJS: 서버 사이드 프레임워크로, Node.js 환경에서 동작하는 백엔드 애플리케이션을 만듭니다. 주로 컨트롤러, 서비스 기반으로 비즈니스 로직을 구축합니다.의존성 등록Angular: 서비스는 providedIn 속성을 통해 모듈, 컴포넌트, 루트 등 여러 레벨에 등록될 수 있습니다.@Injectable({  providedIn: \"root\"})export class DataService {}NestJS: 서비스는 @Module 데코레이터의 providers 배열에 명시적으로 등록됩니다.@Module({  providers: [AppService]})export class AppModule {}사용 방식Angular: 컴포넌트에서 서비스 주입.constructor(private dataService: DataService) {}NestJS: 컨트롤러나 다른 서비스에서 서비스 주입.constructor(private readonly appService: AppService) {}"
  },
  
  {
    "title": "일렉트론(Electron) 앱의 CI/CD 배포 및 원격 업데이트 기능 추가 방법",
    "url": "/posts/%EC%9D%BC%EB%A0%89%ED%8A%B8%EB%A1%A0-CICD-%EC%9B%90%EA%B2%A9%EB%B2%84%EC%A0%84%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8/",
    "categories": "Electron, CI/CD, Deployment",
    "tags": "Electron, CI/CD, GitHub Actions, electron-builder, electron-updater",
    "date": "2024-06-04 00:00:00 +0900",
    





    
    "snippet": "일렉트론(Electron) 앱의 CI/CD 배포 및 원격 업데이트 기능을 추가하려면 다음과 같은 단계로 진행할 수 있습니다.1. CI/CD 환경 구축CI/CD 도구 선택  GitHub Actions, GitLab CI/CD, Jenkins 등 원하는 도구를 선택합니다.Electron 빌드 및 패키징  electron-builder를 사용하면 다양한 플...",
    "content": "일렉트론(Electron) 앱의 CI/CD 배포 및 원격 업데이트 기능을 추가하려면 다음과 같은 단계로 진행할 수 있습니다.1. CI/CD 환경 구축CI/CD 도구 선택  GitHub Actions, GitLab CI/CD, Jenkins 등 원하는 도구를 선택합니다.Electron 빌드 및 패키징  electron-builder를 사용하면 다양한 플랫폼(Windows, macOS, Linux)용으로 손쉽게 빌드하고 패키징할 수 있습니다.  electron-builder 설정 파일인 package.json에 빌드 설정을 추가합니다.{  \"name\": \"your-app\",  \"version\": \"1.0.0\",  \"main\": \"main.js\",  \"scripts\": {    \"build\": \"electron-builder\"  },  \"build\": {    \"appId\": \"com.yourapp.id\",    \"mac\": {      \"category\": \"public.app-category.utilities\"    },    \"win\": {      \"target\": \"nsis\"    },    \"linux\": {      \"target\": \"AppImage\"    }  },  \"devDependencies\": {    \"electron\": \"^13.0.0\",    \"electron-builder\": \"^22.11.7\"  }}CI/CD 설정  GitHub Actions 예시:name: Build and Releaseon:  push:    branches:      - mainjobs:  build:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v2      - name: Set up Node.js        uses: actions/setup-node@v2        with:          node-version: \"14\"      - run: npm install      - run: npm run build  release:    needs: build    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v2      - name: Set up Node.js        uses: actions/setup-node@v2        with:          node-version: \"14\"      - run: npm install      - run: npm run build      - name: Create Release        uses: softprops/action-gh-release@v1        with:          files: |            dist/*.zip            dist/*.AppImage            dist/*.exe        env:          GITHUB_TOKEN: $2. 원격 업데이트 기능 추가업데이트 서버 설정  electron-updater를 사용하여 업데이트 서버를 설정합니다.  GitHub, S3, 자사 서버 등을 업데이트 소스로 사용할 수 있습니다.앱 설정  Electron 메인 프로세스에서 업데이트를 체크하도록 설정합니다.const { app, BrowserWindow, autoUpdater } = require(\"electron\");const path = require(\"path\");let mainWindow;function createWindow() {  mainWindow = new BrowserWindow({    width: 800,    height: 600,    webPreferences: {      preload: path.join(__dirname, \"preload.js\")    }  });  mainWindow.loadFile(\"index.html\");}app.on(\"ready\", () =&gt; {  createWindow();  autoUpdater.checkForUpdatesAndNotify();  autoUpdater.on(\"update-available\", () =&gt; {    console.log(\"Update available.\");  });  autoUpdater.on(\"update-downloaded\", () =&gt; {    autoUpdater.quitAndInstall();  });});app.on(\"window-all-closed\", () =&gt; {  if (process.platform !== \"darwin\") {    app.quit();  }});app.on(\"activate\", () =&gt; {  if (BrowserWindow.getAllWindows().length === 0) {    createWindow();  }});3. 업데이트 배포  새로운 버전이 배포될 때마다 electron-builder를 통해 패키징 후 업데이트 서버에 업로드합니다.  GitHub를 사용하는 경우, 새 릴리스를 생성하면 업데이트가 자동으로 적용될 수 있습니다.이제 CI/CD 파이프라인을 통해 자동으로 빌드 및 배포가 이루어지고, 사용자들에게 원격 업데이트 기능이 제공될 것입니다."
  },
  
  {
    "title": "Jest로 테스트코드 작성하기: 상세 가이드와 예제 코드",
    "url": "/posts/JEST%EB%A1%9C-%ED%85%8C%EC%8A%A4%ED%8A%B8%EC%BD%94%EB%93%9C-%EC%9E%91%EC%84%B1%ED%95%98%EA%B8%B0-%EC%83%81%EC%84%B8-%EA%B0%80%EC%9D%B4%EB%93%9C%EC%99%80-%EC%98%88%EC%A0%9C-%EC%BD%94%EB%93%9C/",
    "categories": "",
    "tags": "",
    "date": "2024-06-03 00:00:00 +0900",
    





    
    "snippet": "layout: posttitle: “JEST로 테스트코드 작성하기: 상세 가이드와 예제 코드”date: 2024-06-03categories: [JavaScript, Testing]tags: [Jest, TDD]JavaScript 프로젝트에서 테스트를 작성하는 것은 코드의 품질을 유지하고, 예상치 못한 버그를 방지하는 데 중요한 역할을 합니다. Jes...",
    "content": "layout: posttitle: “JEST로 테스트코드 작성하기: 상세 가이드와 예제 코드”date: 2024-06-03categories: [JavaScript, Testing]tags: [Jest, TDD]JavaScript 프로젝트에서 테스트를 작성하는 것은 코드의 품질을 유지하고, 예상치 못한 버그를 방지하는 데 중요한 역할을 합니다. Jest는 Facebook에서 개발한 JavaScript 테스팅 프레임워크로, 설정이 간단하고 다양한 기능을 제공하여 많은 개발자들이 애용하고 있습니다. 이번 블로그 글에서는 Jest를 사용하여 테스트 코드를 작성하는 방법을 자세히 설명하고, 풍부한 예제 코드로 그 과정을 보여드리겠습니다.1. Jest 설치하기먼저, Jest를 프로젝트에 설치해야 합니다. npm을 사용하여 간단히 설치할 수 있습니다:npm install --save-dev jest설치 후, package.json 파일의 scripts 섹션에 Jest를 추가합니다:{  \"scripts\": {    \"test\": \"jest\"  }}이제 npm test 명령어로 Jest 테스트를 실행할 수 있습니다.2. 기본 테스트 작성하기Jest의 기본적인 사용법을 이해하기 위해 간단한 테스트를 작성해보겠습니다. 예제로 사용할 함수는 두 숫자를 더하는 함수입니다:// sum.jsfunction sum(a, b) {  return a + b;}module.exports = sum;이제 이 함수에 대한 테스트 코드를 작성해봅시다:// sum.test.jsconst sum = require(\"./sum\");test(\"adds 1 + 2 to equal 3\", () =&gt; {  expect(sum(1, 2)).toBe(3);});이 테스트는 sum 함수가 1과 2를 더하여 3이 되는지 확인합니다. test 함수는 테스트 케이스를 정의하고, expect 함수는 실제 값이 예상 값과 일치하는지 확인합니다.3. 다양한 매처 사용하기Jest는 다양한 매처(matcher)를 제공하여 다양한 방식으로 값을 검증할 수 있습니다. 몇 가지 예제를 살펴보겠습니다:// matchers.test.jstest(\"two plus two is four\", () =&gt; {  expect(2 + 2).toBe(4);});test(\"object assignment\", () =&gt; {  const data = { one: 1 };  data[\"two\"] = 2;  expect(data).toEqual({ one: 1, two: 2 });});test(\"null\", () =&gt; {  const n = null;  expect(n).toBeNull();  expect(n).toBeDefined();  expect(n).not.toBeUndefined();  expect(n).not.toBeTruthy();  expect(n).toBeFalsy();});test(\"zero\", () =&gt; {  const z = 0;  expect(z).not.toBeNull();  expect(z).toBeDefined();  expect(z).not.toBeUndefined();  expect(z).not.toBeTruthy();  expect(z).toBeFalsy();});4. 비동기 코드 테스트하기비동기 코드를 테스트할 때는 async/await를 사용하거나, done 콜백을 사용할 수 있습니다. 다음은 async/await를 사용하는 예제입니다:// async.jsfunction fetchData() {  return new Promise((resolve) =&gt; {    setTimeout(() =&gt; {      resolve(\"peanut butter\");    }, 1000);  });}module.exports = fetchData;// async.test.jsconst fetchData = require(\"./async\");test(\"the data is peanut butter\", async () =&gt; {  const data = await fetchData();  expect(data).toBe(\"peanut butter\");});5. Mock 함수 사용하기Mock 함수를 사용하면 함수 호출 여부, 호출 횟수, 호출된 인수 등을 확인할 수 있습니다. 예를 들어, 다음과 같은 모듈이 있다고 가정해봅시다:// forEach.jsfunction forEach(items, callback) {  for (let index = 0; index &lt; items.length; index++) {    callback(items[index]);  }}module.exports = forEach;이제 이 모듈을 테스트할 때 mock 함수를 사용해보겠습니다:// forEach.test.jsconst forEach = require(\"./forEach\");test(\"mock callback\", () =&gt; {  const mockCallback = jest.fn((x) =&gt; 42 + x);  forEach([0, 1], mockCallback);  // 콜백 함수가 두 번 호출되었는지 확인  expect(mockCallback.mock.calls.length).toBe(2);  // 첫 번째 호출 시 첫 번째 인수가 0이었는지 확인  expect(mockCallback.mock.calls[0][0]).toBe(0);  // 두 번째 호출 시 첫 번째 인수가 1이었는지 확인  expect(mockCallback.mock.calls[1][0]).toBe(1);  // 첫 번째 호출의 반환 값이 42였는지 확인  expect(mockCallback.mock.results[0].value).toBe(42);});6. 테스트 커버리지 확인하기Jest는 코드 커버리지를 확인할 수 있는 기능도 제공합니다. 다음 명령어를 실행하면 커버리지 보고서를 생성할 수 있습니다:npm test -- --coveragecoverage 폴더에 HTML 형식의 커버리지 보고서가 생성되며, 이를 통해 어느 부분이 테스트되었는지 쉽게 확인할 수 있습니다.현업에서 TDD(Test-Driven Development) 구현하기: Jest를 활용한 사례TDD(Test-Driven Development, 테스트 주도 개발)는 코드 작성 전에 테스트를 먼저 작성하는 방식입니다. TDD를 통해 코드를 작성하면 더 높은 코드 품질과 유지보수성을 확보할 수 있습니다. 이번 포스팅에서는 Jest를 활용하여 현업에서 TDD를 구현하는 방법을 알아보겠습니다.1. TDD의 기본 흐름TDD의 기본적인 흐름은 다음과 같습니다:  테스트 작성 (Red): 실패하는 테스트를 작성합니다.  코드 작성 (Green): 테스트를 통과하기 위한 최소한의 코드를 작성합니다.  리팩토링 (Refactor): 코드의 중복을 제거하고, 더 나은 구조로 리팩토링합니다.이러한 과정을 반복하여 기능을 구현해 나갑니다.2. 예제 프로젝트: Todo 리스트 애플리케이션간단한 Todo 리스트 애플리케이션을 TDD 방식으로 구현해보겠습니다. 기능 요구 사항은 다음과 같습니다:  Todo 항목을 추가할 수 있다.  Todo 항목을 완료 처리할 수 있다.  완료된 Todo 항목을 삭제할 수 있다.2.1 테스트 작성 (Red)먼저, 각 기능에 대한 테스트를 작성합니다.// todo.test.jsconst TodoList = require(\"./todo\");test(\"should add a todo item\", () =&gt; {  const todoList = new TodoList();  todoList.add(\"Learn TDD\");  expect(todoList.getItems()).toEqual([{ text: \"Learn TDD\", done: false }]);});test(\"should mark a todo item as done\", () =&gt; {  const todoList = new TodoList();  todoList.add(\"Learn TDD\");  todoList.markDone(\"Learn TDD\");  expect(todoList.getItems()).toEqual([{ text: \"Learn TDD\", done: true }]);});test(\"should remove a completed todo item\", () =&gt; {  const todoList = new TodoList();  todoList.add(\"Learn TDD\");  todoList.markDone(\"Learn TDD\");  todoList.remove(\"Learn TDD\");  expect(todoList.getItems()).toEqual([]);});2.2 코드 작성 (Green)테스트를 통과하기 위한 최소한의 코드를 작성합니다.// todo.jsclass TodoList {  constructor() {    this.items = [];  }  add(text) {    this.items.push({ text, done: false });  }  getItems() {    return this.items;  }  markDone(text) {    const item = this.items.find((item) =&gt; item.text === text);    if (item) {      item.done = true;    }  }  remove(text) {    this.items = this.items.filter((item) =&gt; item.text !== text || !item.done);  }}module.exports = TodoList;2.3 리팩토링 (Refactor)코드를 개선하여 중복을 제거하고 구조를 개선합니다. 현재 예제에서는 간단한 코드이므로 추가적인 리팩토링이 필요하지 않습니다.3. 비동기 코드 테스트하기 (Jest)비동기 코드를 테스트할 때는 async/await를 사용하거나, done 콜백을 사용할 수 있습니다. 비동기 작업이 완료되기 전에 테스트가 종료되지 않도록 주의해야 합니다. 다음은 비동기 코드 테스트 예제입니다:// asyncTodo.jsclass AsyncTodoList {  constructor() {    this.items = [];  }  async add(text) {    return new Promise((resolve) =&gt; {      setTimeout(() =&gt; {        this.items.push({ text, done: false });        resolve();      }, 1000);    });  }  getItems() {    return this.items;  }}module.exports = AsyncTodoList;// asyncTodo.test.jsconst AsyncTodoList = require(\"./asyncTodo\");test(\"should add a todo item asynchronously\", async () =&gt; {  const todoList = new AsyncTodoList();  await todoList.add(\"Learn TDD\");  expect(todoList.getItems()).toEqual([{ text: \"Learn TDD\", done: false }]);});4. Mock 함수 사용하기 (Jest)Mock 함수는 함수 호출 여부, 호출 횟수, 호출된 인수 등을 확인할 수 있습니다. 외부 API 호출이나 복잡한 비즈니스 로직을 단위 테스트할 때 유용합니다. 다음은 Mock 함수를 사용하는 예제입니다:// externalApi.jsclass ExternalApi {  fetchData(callback) {    setTimeout(() =&gt; {      callback(\"data\");    }, 1000);  }}module.exports = ExternalApi;// externalApi.test.jsconst ExternalApi = require(\"./externalApi\");test(\"should fetch data from external API\", () =&gt; {  const api = new ExternalApi();  const callback = jest.fn();  api.fetchData(callback);  jest.runAllTimers();  expect(callback).toHaveBeenCalledTimes(1);  expect(callback).toHaveBeenCalledWith(\"data\");});"
  },
  
  {
    "title": "리액트의 Reconciliation 과정 설명",
    "url": "/posts/react-%EA%B0%80%EC%83%81%EB%8F%94%EC%9D%98-%EB%8F%99%EC%9E%91%EC%9B%90%EB%A6%AC/",
    "categories": "React, Frontend",
    "tags": "Reconciliation, Virtual DOM, React",
    "date": "2024-06-01 00:00:00 +0900",
    





    
    "snippet": "리액트의 Reconciliation 과정에서는 변경된 부분만 실제 DOM에 반영됩니다. 주어진 코드에서 상태(state)가 변경되면 리액트는 Reconciliation 과정을 통해 변경된 부분만을 찾아서 업데이트합니다. 이를 Raw한 단계로 설명해보겠습니다.코드 예제: ParentComponent와 ChildComponentfunction Parent...",
    "content": "리액트의 Reconciliation 과정에서는 변경된 부분만 실제 DOM에 반영됩니다. 주어진 코드에서 상태(state)가 변경되면 리액트는 Reconciliation 과정을 통해 변경된 부분만을 찾아서 업데이트합니다. 이를 Raw한 단계로 설명해보겠습니다.코드 예제: ParentComponent와 ChildComponentfunction ParentComponent() {  const [data, setData] = useState(\"Initial data\");  const updateData = (newData) =&gt; {    setData(newData);  };  return (    &lt;div&gt;      &lt;ChildComponent data={data} updateData={updateData} /&gt;    &lt;/div&gt;  );}function ChildComponent({ data, updateData }) {  return (    &lt;div&gt;      &lt;p&gt;{data}&lt;/p&gt;      &lt;button onClick={() =&gt; updateData(\"Updated data\")}&gt;Update&lt;/button&gt;    &lt;/div&gt;  );}상태 변경과 Reconciliation 과정초기 상태  ParentComponent가 처음 렌더링될 때, data는 \"Initial data\"입니다.  ChildComponent가 처음 렌더링될 때, data는 \"Initial data\"입니다.이때 Virtual DOM 트리는 다음과 같습니다:// ParentComponent의 Virtual DOMReact.createElement(  \"div\",  null,  React.createElement(ChildComponent, {    data: \"Initial data\",    updateData: updateData  }));// ChildComponent의 Virtual DOMReact.createElement(  \"div\",  null,  React.createElement(\"p\", null, \"Initial data\"),  React.createElement(    \"button\",    { onClick: () =&gt; updateData(\"Updated data\") },    \"Update\"  ));상태 업데이트버튼이 클릭되어 updateData('Updated data')가 호출되면, setData가 \"Updated data\"로 상태를 변경합니다. 이때 ParentComponent와 ChildComponent가 다시 호출되며 새로운 Virtual DOM 트리를 생성합니다:// ParentComponent의 새로운 Virtual DOMReact.createElement(  \"div\",  null,  React.createElement(ChildComponent, {    data: \"Updated data\",    updateData: updateData  }));// ChildComponent의 새로운 Virtual DOMReact.createElement(  \"div\",  null,  React.createElement(\"p\", null, \"Updated data\"),  React.createElement(    \"button\",    { onClick: () =&gt; updateData(\"Updated data\") },    \"Update\"  ));Reconciliation리액트는 새로운 Virtual DOM 트리와 이전 Virtual DOM 트리를 비교하여 변경된 부분을 찾아냅니다. 변경된 부분은 &lt;p&gt; 요소의 텍스트 콘텐츠입니다: 'Initial data' → 'Updated data'.Commit Phase리액트는 변경된 부분만 실제 DOM에 반영합니다. 이 경우 &lt;p&gt; 요소의 텍스트 콘텐츠만 업데이트됩니다:// 실제 DOM 업데이트const pElement = document.querySelector(\"p\");pElement.textContent = \"Updated data\";JSX 변환 예제JSX 코드를 React.createElement 함수 호출로 변환하는 예제를 다시 보겠습니다:const element = &lt;h1&gt;Hello, world!&lt;/h1&gt;;// JSX 변환 후 실제 코드const element = React.createElement(\"h1\", null, \"Hello, world!\");마찬가지로, 주어진 컴포넌트 코드도 React.createElement 함수 호출로 변환될 수 있습니다:function ParentComponent() {  const [data, setData] = useState(\"Initial data\");  const updateData = (newData) =&gt; {    setData(newData);  };  return React.createElement(    \"div\",    null,    React.createElement(ChildComponent, { data: data, updateData: updateData })  );}function ChildComponent({ data, updateData }) {  return React.createElement(    \"div\",    null,    React.createElement(\"p\", null, data),    React.createElement(      \"button\",      { onClick: () =&gt; updateData(\"Updated data\") },      \"Update\"    )  );}이렇게 변환된 코드는 Virtual DOM 트리의 구조를 정확히 보여줍니다. 리액트는 이 구조를 기반으로 Reconciliation 과정을 수행하여, 변경된 부분만 실제 DOM에 반영합니다."
  },
  
  {
    "title": "Next.js와 React Server Components (RSC) 이해하기",
    "url": "/posts/Next.js%EC%99%80-React-Server-Components-(RSC)-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0/",
    "categories": "Next.js, React",
    "tags": "Next.js, ServerComponents",
    "date": "2024-05-21 00:00:00 +0900",
    





    
    "snippet": "개요Next.js는 React 기반의 프레임워크로, 서버 측 렌더링(SSR), 정적 사이트 생성(SSG) 등의 기능을 통해 React 애플리케이션의 성능을 최적화합니다. Next.js는 React Server Components 개념을 도입하여 서버 컴포넌트와 클라이언트 컴포넌트를 구별합니다. 이러한 기술적 발전과 구분 방법을 다음과 같이 설명하고, ...",
    "content": "개요Next.js는 React 기반의 프레임워크로, 서버 측 렌더링(SSR), 정적 사이트 생성(SSG) 등의 기능을 통해 React 애플리케이션의 성능을 최적화합니다. Next.js는 React Server Components 개념을 도입하여 서버 컴포넌트와 클라이언트 컴포넌트를 구별합니다. 이러한 기술적 발전과 구분 방법을 다음과 같이 설명하고, 이를 최적화하여 활용하는 방법을 소개합니다.기술적인 발전 과정Next.js의 서버 컴포넌트와 클라이언트 컴포넌트 구분은 React의 발전과 밀접한 관련이 있습니다. 초기에는 SSR(Server-Side Rendering)과 CSR(Client-Side Rendering)을 사용했으며, 이후 정적 사이트 생성(SSG), Incremental Static Regeneration(ISR) 등을 도입하여 성능을 최적화해 왔습니다.초기 단계: SSR과 CSRNext.js의 초기 버전에서는 SSR(Server-Side Rendering)과 CSR(Client-Side Rendering)을 주로 사용했습니다. SSR은 서버에서 HTML을 생성하여 클라이언트로 전송하고, CSR은 클라이언트에서 모든 렌더링을 담당합니다.정적 사이트 생성(SSG)Next.js는 이후 정적 사이트 생성(SSG) 기능을 도입하여 빌드 시점에 HTML을 생성하여 CDN에 배포할 수 있게 했습니다. 이를 통해 정적 페이지의 성능을 크게 향상시켰습니다.Incremental Static Regeneration(ISR)Next.js는 Incremental Static Regeneration(ISR)을 도입하여 정적 페이지의 일부만 재생성할 수 있게 했습니다. 이를 통해 페이지 업데이트 시 전체 사이트를 다시 빌드하지 않고 필요한 부분만 갱신할 수 있습니다.React Server ComponentsReact는 React Server Components를 도입하여 서버에서 컴포넌트를 렌더링하고, 클라이언트로 필요한 최소한의 JavaScript만 전송하는 방식을 제안했습니다. Next.js는 이를 빠르게 채택하여 서버 컴포넌트와 클라이언트 컴포넌트를 명확히 구분할 수 있게 했습니다. 이 방식은 서버에서 데이터를 가져오고 처리하여 클라이언트로 전달하는 과정을 단순화합니다.NextJS Server ComponentsNext.js는 getServerSideProps, getStaticProps, getStaticPaths 등의 메서드를 제공하여 서버 사이드에서 데이터를 페칭하고 페이지 컴포넌트로 전달할 수 있게 합니다. 이러한 함수는 특정 페이지 컴포넌트와 연동되어 서버에서 데이터를 미리 가져오고 렌더링하는 과정을 단순화합니다.리액트에서의 Server Components를 SSR로 직접구현기본적으로 리액트는 CSR을 지원하는 ‘라이브러리’이기 떄문에서버컴포넌트를 구성하려면 서버의 구성이 필요합니다1. 기본 서버 사이드 렌더링 설정먼저, Express와 React를 사용하여 서버 사이드 렌더링을 설정합니다.package.json 설치{  \"name\": \"ssr-example\",  \"version\": \"1.0.0\",  \"main\": \"server.js\",  \"scripts\": {    \"start\": \"node server.js\"  },  \"dependencies\": {    \"express\": \"^4.17.1\",    \"react\": \"^17.0.2\",    \"react-dom\": \"^17.0.2\",    \"node-fetch\": \"^2.6.1\",    \"@babel/core\": \"^7.12.3\",    \"@babel/preset-env\": \"^7.12.1\",    \"@babel/preset-react\": \"^7.12.1\",    \"babel-register\": \"^6.26.0\"  }}추가로 바벨 종속성 등록 및 호환성체크server.jsimport express from \"express\";import React from \"react\";import { renderToString } from \"react-dom/server\";import App from \"./src/App\";import fetch from \"node-fetch\";const app = express();app.use(express.static(\"public\"));app.get(\"/\", async (req, res) =&gt; {  const response = await fetch(\"https://api.example.com/data\");  const data = await response.text();  const appHTML = renderToString(&lt;App data={data} /&gt;);  res.send(`    &lt;!DOCTYPE html&gt;    &lt;html&gt;      &lt;head&gt;        &lt;title&gt;SSR Example&lt;/title&gt;      &lt;/head&gt;      &lt;body&gt;        &lt;div id=\"root\"&gt;${appHTML}&lt;/div&gt;        &lt;script&gt;window.__INITIAL_DATA__ = ${JSON.stringify(data).replace(          /&lt;/g,          \"\\\\u003c\"        )}&lt;/script&gt;        &lt;script src=\"/client.js\"&gt;&lt;/script&gt;      &lt;/body&gt;    &lt;/html&gt;  `);});app.listen(3000, () =&gt; {  console.log(\"Server is running on http://localhost:3000\");});Express로 Node서버 구성src/App.jsimport React from \"react\";export default function App() {  return &lt;div&gt;Hello from the server!&lt;/div&gt;;}2. 클라이언트 하이드레이션 설정클라이언트에서 서버에서 전송된 HTML을 하이드레이션합니다.public/client.jsimport React from \"react\";import ReactDOM from \"react-dom\";import App from \"../src/App\";ReactDOM.hydrate(&lt;App /&gt;, document.getElementById(\"root\"));3. 데이터 페칭을 포함한 서버 컴포넌트서버에서 데이터를 페칭하여 렌더링하는 컴포넌트를 추가해보겠습니다.src/App.js (데이터 페칭 추가)import React from \"react\";export default function App({ data }) {  return (    &lt;div&gt;      &lt;h1&gt;Data from server:&lt;/h1&gt;      &lt;p&gt;{data}&lt;/p&gt;    &lt;/div&gt;  );}server.js (데이터 페칭 추가)const express = require(\"express\");const React = require(\"react\");const { renderToString } = require(\"react-dom/server\");const App = require(\"./src/App\").default;const fetch = require(\"node-fetch\");const app = express();app.use(express.static(\"public\"));app.get(\"/\", async (req, res) =&gt; {  const response = await fetch(\"https://api.example.com/data\");  const data = await response.text();  const appHTML = renderToString(&lt;App data={data} /&gt;);  res.send(`    &lt;!DOCTYPE html&gt;    &lt;html&gt;      &lt;head&gt;        &lt;title&gt;SSR Example&lt;/title&gt;      &lt;/head&gt;      &lt;body&gt;        &lt;div id=\"root\"&gt;${appHTML}&lt;/div&gt;        &lt;script&gt;window.__INITIAL_DATA__ = ${JSON.stringify(data)}&lt;/script&gt;        &lt;script src=\"/client.js\"&gt;&lt;/script&gt;      &lt;/body&gt;    &lt;/html&gt;  `);});app.listen(3000, () =&gt; {  console.log(\"Server is running on http://localhost:3000\");});public/client.js (하이드레이션 수정)import React from \"react\";import ReactDOM from \"react-dom\";import App from \"../src/App\";const data = window.__INITIAL_DATA__;ReactDOM.hydrate(&lt;App data={data} /&gt;, document.getElementById(\"root\"));4.최적화: 코드 스플리팅 및 React.lazyReact.lazy와 Suspense를 사용하여 코드 스플리팅으로 최적화합니다.src/App.js (코드 스플리팅 추가)import React, { Suspense } from \"react\";const DataComponent = React.lazy(() =&gt; import(\"./DataComponent\"));export default function App({ data }) {  return (    &lt;div&gt;      &lt;h1&gt;Data from server:&lt;/h1&gt;      &lt;Suspense fallback={&lt;div&gt;Loading...&lt;/div&gt;}&gt;        &lt;DataComponent data={data} /&gt;      &lt;/Suspense&gt;    &lt;/div&gt;  );}src/DataComponent.jsimport React from \"react\";export default function DataComponent({ data }) {  return &lt;p&gt;{data}&lt;/p&gt;;}5. 최적화: 서버 사이드 데이터 로딩서버에서 데이터를 미리 로딩하고 클라이언트로 전달하여 네트워크 요청을 최소화합니다.server.js (서버 사이드 데이터 로딩 추가)const express = require(\"express\");const React = require(\"react\");const { renderToString } = require(\"react-dom/server\");const App = require(\"./src/App\").default;const fetch = require(\"node-fetch\");const app = express();app.use(express.static(\"public\"));app.get(\"/\", async (req, res) =&gt; {  const response = await fetch(\"https://api.example.com/data\");  const data = await response.text();  const appHTML = renderToString(&lt;App data={data} /&gt;);  res.send(`    &lt;!DOCTYPE html&gt;    &lt;html&gt;      &lt;head&gt;        &lt;title&gt;SSR Example&lt;/title&gt;      &lt;/head&gt;      &lt;body&gt;        &lt;div id=\"root\"&gt;${appHTML}&lt;/div&gt;        &lt;script&gt;window.__INITIAL_DATA__ = ${JSON.stringify(data)}&lt;/script&gt;        &lt;script src=\"/client.js\"&gt;&lt;/script&gt;      &lt;/body&gt;    &lt;/html&gt;  `);});app.listen(3000, () =&gt; {  console.log(\"Server is running on http://localhost:3000\");});React에서 React Server Components (RSC) 구현 패턴React에서 RSC를 직접 구현하려면 다음과 같은 과정이 필요합니다:  서버 컴포넌트 작성: 서버에서 렌더링할 컴포넌트를 작성합니다.  서버 설정: Express 또는 Koa 같은 Node.js 서버를 설정하여 서버 컴포넌트를 렌더링합니다.  데이터 페칭 및 렌더링: 서버 컴포넌트에서 필요한 데이터를 페칭하고 HTML로 렌더링합니다.  클라이언트 전송: 렌더링된 HTML과 필요한 데이터만 클라이언트로 전송합니다.  클라이언트 하이드레이션: 클라이언트에서 받은 HTML을 하이드레이션하여 상호작용을 추가합니다.NextJS에서의 Server Components 구현 방법Next.js는 페이지 수준에서 데이터 페칭 및 서버 사이드 렌더링을 지원합니다. getServerSideProps 함수를 사용하여 서버 측에서 데이터를 페칭할 수 있습니다.사용 시 주의사항  데이터 페칭: 서버 컴포넌트에서만 데이터 페칭을 수행하고, 클라이언트 컴포넌트에서는 데이터 페칭을 피하는 것이 좋습니다. 이는 서버에서 데이터를 가져오는 것이 더 효율적이기 때문입니다.  상태 관리: 클라이언트 컴포넌트에서는 상태 관리를 사용하여 사용자와의 상호작용을 처리합니다. 서버 컴포넌트에서는 상태 관리를 사용하지 않습니다.  보안: 서버 컴포넌트에서는 클라이언트로 전송되기 전에 모든 데이터가 서버에서 렌더링되므로 보안상 이점이 있습니다.// app/serverComponent.server.jsimport fetchData from 'path/to/fetchData';export default function ServerComponent() {  const data = fetchData();  return (    &lt;div&gt;      &lt;h1&gt;Server Component&lt;/h1&gt;      &lt;p&gt;Data: {data}&lt;/p&gt;    &lt;/div&gt;  );}// app/clientComponent.client.js\"use client\";import { useState } from 'react';export default function ClientComponent() {  const [count, setCount] = useState(0);  return (    &lt;div&gt;      &lt;h1&gt;Client Component&lt;/h1&gt;      &lt;p&gt;Count: {count}&lt;/p&gt;      &lt;button onClick={() =&gt; setCount(count + 1)}&gt;Increment&lt;/button&gt;    &lt;/div&gt;  );}React Server Components (RSC)와 Next.js에서의 구현 차이점  설정과 구성:          React: 서버 설정(예: Express, Koa)을 직접 구성해야 하며, 데이터 페칭과 렌더링을 직접 처리합니다.      Next.js: 파일 시스템 기반 라우팅과 자동 설정을 통해 구성 작업을 최소화하며, 서버 컴포넌트와 클라이언트 컴포넌트를 쉽게 구분하고 사용할 수 있습니다.        데이터 페칭과 렌더링:          React: 데이터 페칭과 렌더링 로직을 직접 작성해야 하며, 서버와 클라이언트 간의 데이터 전송을 직접 관리해야 합니다.      Next.js: getServerSideProps와 getStaticProps 같은 메서드를 사용하여 데이터 페칭과 렌더링을 자동으로 처리하며, 클라이언트로 전송되는 데이터를 최적화합니다.        자동 최적화:          React: 모든 최적화 작업을 직접 수행해야 합니다.      Next.js: 자동 최적화를 통해 서버에서 렌더링된 결과와 클라이언트 측 상호작용을 최적화합니다.            개발 편의성:          React: 초기 설정과 구성이 복잡하며, 모든 작업을 직접 관리해야 합니다.      Next.js: 설정과 구성이 간편하며, 서버 컴포넌트와 클라이언트 컴포넌트를 쉽게 구분하고 사용할 수 있어 개발 편의성이 높습니다.리액트의 복잡한 설정이 필요없어지니 확실히 프레임워크는 프레임워크입니다.다음은 NextJS에서의 활용방법들입니다.        Next.js에서의 활용    1. 컴포넌트 구분 명확히 하기    서버 컴포넌트와 클라이언트 컴포넌트를 명확히 구분하는 것은 중요합니다. 파일 네이밍과 디렉토리 구조를 통해 이를 명확히 하는 것이 좋습니다.    - components/  - ServerComponent.server.js  - ClientComponent.client.js        서버 컴포넌트는 서버에서만 렌더링되므로 보안에 민감한 데이터를 처리할 수 있으며, 클라이언트 컴포넌트는 사용자 인터랙션을 담당합니다.    2. 데이터 페칭과 상태 관리 최적화    서버 컴포넌트에서 데이터 페칭    서버 컴포넌트에서 데이터를 페칭하는 것이 성능 면에서 유리합니다. getServerSideProps 또는 getStaticProps를 사용하여 데이터를 서버에서 미리 로드합니다.    // components/ServerComponent.server.jsimport fetchData from \"path/to/fetchData\";export default function ServerComponent() {  const data = fetchData();  return (    &lt;div&gt;      &lt;h1&gt;Server Component&lt;/h1&gt;      &lt;p&gt;Data: {data}&lt;/p&gt;    &lt;/div&gt;  );}        클라이언트 컴포넌트에서 상태 관리    클라이언트 컴포넌트에서는 상태 관리 라이브러리(예: Redux, Zustand)를 사용하여 사용자 인터랙션을 처리합니다.    // components/ClientComponent.client.js\"use client\";import { useState } from \"react\";export default function ClientComponent() {  const [count, setCount] = useState(0);  return (    &lt;div&gt;      &lt;h1&gt;Client Component&lt;/h1&gt;      &lt;p&gt;Count: {count}&lt;/p&gt;      &lt;button onClick={() =&gt; setCount(count + 1)}&gt;Increment&lt;/button&gt;    &lt;/div&gt;  );}        하이드레이션 문제의 최적화 전후 코드 비교    문제: 하이드레이션 최적화    서버에서 렌더링된 HTML을 클라이언트에서 하이드레이션할 때 발생하는 성능 문제와 일관성 문제를 해결해야 했습니다. 특히, 초기 로드 시 느린 하이드레이션 속도는 사용자 경험을 저하시킬 수 있습니다.    문제 발생 전 코드    ServerComponent.server.js    export default function ServerComponent() {  return (    &lt;div&gt;      &lt;h1&gt;Server Component&lt;/h1&gt;      &lt;p&gt;Data: Static data&lt;/p&gt;    &lt;/div&gt;  );}        ClientComponent.client.js    \"use client\";import { useState, useEffect } from \"react\";export default function ClientComponent() {  const [data, setData] = useState(null);  useEffect(() =&gt; {    fetch(\"/api/data\")      .then((response) =&gt; response.json())      .then((data) =&gt; setData(data));  }, []);  return (    &lt;div&gt;      &lt;h1&gt;Client Component&lt;/h1&gt;      &lt;p&gt;Data: {data}&lt;/p&gt;    &lt;/div&gt;  );}        이 코드는 서버에서 렌더링된 후 클라이언트에서 데이터를 다시 페칭합니다. 이는 불필요한 네트워크 요청을 초래하고, 하이드레이션 속도를 저하시킵니다.    문제 해결 후 코드    ServerComponent.server.js    import fetchData from \"path/to/fetchData\";export default function ServerComponent({ initialData }) {  return (    &lt;div&gt;      &lt;h1&gt;Server Component&lt;/h1&gt;      &lt;p&gt;Data: {initialData}&lt;/p&gt;    &lt;/div&gt;  );}// getServerSideProps.jsexport async function getServerSideProps() {  const data = await fetchData();  return { props: { initialData: data } };}        ClientComponent.client.js    \"use client\";import { useState } from \"react\";export default function ClientComponent({ initialData }) {  const [data] = useState(initialData);  return (    &lt;div&gt;      &lt;h1&gt;Client Component&lt;/h1&gt;      &lt;p&gt;Data: {data}&lt;/p&gt;    &lt;/div&gt;  );}        이 코드는 서버에서 데이터를 미리 페칭하고 클라이언트로 전달합니다. 이렇게 하면 클라이언트에서 추가적인 네트워크 요청 없이 하이드레이션이 이루어져 초기 로드 속도가 개선됩니다. 또한, React의 상태 관리를 사용하여 초기 데이터를 설정하므로 데이터 일관성 문제가 해결됩니다.    3. 코드 스플리팅과 동적 임포트 사용    큰 애플리케이션에서는 성능 최적화를 위해 코드 스플리팅과 동적 임포트를 사용하는 것이 중요합니다. 이를 통해 초기 로드 시간을 줄이고 필요한 부분만 로드할 수 있습니다.    // components/ClientComponent.client.jsimport dynamic from \"next/dynamic\";const HeavyComponent = dynamic(() =&gt; import(\"./HeavyComponent.client\"), {  ssr: false,  loading: () =&gt; &lt;p&gt;Loading...&lt;/p&gt;});export default function ClientComponent() {  return (    &lt;div&gt;      &lt;h1&gt;Client Component&lt;/h1&gt;      &lt;HeavyComponent /&gt;    &lt;/div&gt;  );}        결론    이번 포스팅은 직접 React로 NextJS의 SSR 기능을 모방하고 , 이를 NextJS 에서는 어떻게 활용하는지 포스팅하였습니다다음 포스팅은 Vercel팀이 어떻게 nextJS에 서버컴포넌트를 구현했는지 오픈소스를 까서보는 시간이 될것같습니다.  "
  },
  
  {
    "title": "AWS Docker 컨테이너의 MariaDB 데이터베이스 덤프 파일 생성 및 복사",
    "url": "/posts/AWS-Docker-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88%EC%9D%98-MariaDB-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EB%8D%A4%ED%94%84-%ED%8C%8C%EC%9D%BC-%EC%83%9D%EC%84%B1-%EB%B0%8F-%EB%B3%B5%EC%82%AC/",
    "categories": "AWS, Docker, MariaDB, Backup",
    "tags": "",
    "date": "2024-05-21 00:00:00 +0900",
    





    
    "snippet": "AWS Docker 컨테이너의 MariaDB 데이터베이스 덤프 파일 생성 및 복사개요이 블로그 글에서는 AWS 인스턴스의 Docker 컨테이너에서 MariaDB 데이터베이스 덤프 파일을 생성하고,이를 호스트 로컬 폴더로 복사하는 방법을 단계별로 설명합니다.현재 나의 상황은 AWS 인스턴스로 올라가있는 서버와해당 서버가 이용중인 DB가 도커환경에서 구동...",
    "content": "AWS Docker 컨테이너의 MariaDB 데이터베이스 덤프 파일 생성 및 복사개요이 블로그 글에서는 AWS 인스턴스의 Docker 컨테이너에서 MariaDB 데이터베이스 덤프 파일을 생성하고,이를 호스트 로컬 폴더로 복사하는 방법을 단계별로 설명합니다.현재 나의 상황은 AWS 인스턴스로 올라가있는 서버와해당 서버가 이용중인 DB가 도커환경에서 구동중입니다SSH로 공유된 원격 인스턴스에 접근하여 인스턴스 내부에서 돌아가는 DB환경을 로컬로 재구성하기위해서 필요한 작업을 합니다.1. Docker 컨테이너 내부에서 MariaDB 덤프 파일 생성먼저 Docker 컨테이너 내부에 접속하여 MariaDB 데이터베이스 덤프 파일을 생성합니다.컨테이너 이름을 사용하는 방법:sudo docker exec -it [container_name] /bin/bash컨테이너 ID를 사용하는 방법:sudo docker exec -it [container_id] /bin/bash컨테이너 내부에서 mysqldump 명령어를 실행하여 덤프 파일을 생성합니다:mysqldump  -uroot -p [password] [database] &gt; /tmp/[dumpFileName].sql열 통계 정보 포함 비활성화:MySQL 8.0.21부터 mysqldump는 기본적으로 열 통계 정보를 덤프 파일에 포함시킵니다. 그러나 일부 MariaDB 버전 또는 특정 설정에서는 이 기능이 호환되지 않을 수 있습니다. 따라서 이 옵션을 사용하면 열 통계 정보를 포함하지 않도록 설정할 수 있습니다.만약 mariaDB를 사용하는 환경이고 , 아래와같은 에러가 발생한다면 열통계를 끄는 옵션을 추가하여주세요mysqldump: Couldn't execute 'SELECT COLUMN_NAME,JSON_EXTRACT(HISTOGRAM, '$.\"number-of-buckets-specified\"')FROM information_schema.COLUMN_STATISTICSWHERE SCHEMA_NAME = '[DatabaseName]'AND TABLE_NAME = '[TableName]';':Unknown table 'COLUMN_STATISTICS' in information_schema (1109)이 오류는 MariaDB와 MySQL 버전 차이로 인해 발생하며 mysqldump 명령어가 information_schema 데이터베이스의 COLUMN_STATISTICS 테이블을 찾지 못해서 발생합니다.현재 우리의 DB구성은 mariaDB였기에 버전호환성 문제를 일으키는 것 같습니다.이를 해결하기 위해 –column-statistics=0 옵션을 추가하여 COLUMN_STATISTICS 기능을 비활성화할 수 있습니다.mysqldump --column-statistics=0 -uroot -p [password] [database] &gt; /tmp/[dumpFileName].sql2. 덤프 파일 존재 확인컨테이너 내부에서 덤프 파일이 잘 생성되었는지 확인합니다:ls -al /tmp/예상 출력 예시:root@[container_id]:/# ls -al /tmp/total 12drwxrwxrwt  2 root root 4096 May 21 12:00 .drwxr-xr-x 21 root root 4096 May 21 12:00 ..-rw-r--r--  1 root root 2048 May 21 12:00 [dumpedFileName].sql3.컨테이너에서 호스트로 덤프 파일 복사덤프파일이 생성된 컨테이너의 임시볼륨에 접근하고 SQL파일을 특정경로로 복사해줍니다sudo docker cp [container_id or container_name]:/tmp/[dumpedFileName].sql /home/ubuntu/[copyFileName].sql또는 현재 디렉토리에 복사하려면 다음과 같이 합니다:sudo docker cp 615ff7727e34:/tmp/backup0521.sql .요약이 과정을 통해 AWS 인스턴스의 Docker 컨테이너에서 MariaDB 데이터베이스 덤프 파일을 생성하고이를 호스트 머신으로 복사할 수 있습니다  Docker 컨테이너 내부에 접속  mysqldump 명령어를 사용하여 덤프 파일 생성  ls -al 명령어로 덤프 파일 존재 확인  docker cp 명령어로 덤프 파일을 호스트로 복사"
  },
  
  {
    "title": "Docker 이해하기:arm환경에서 Docker로 python서버 구성하기",
    "url": "/posts/Docker-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-arm%ED%99%98%EA%B2%BD%EC%97%90%EC%84%9C-Docker%EB%A1%9C-python%EC%84%9C%EB%B2%84-%EA%B5%AC%EC%84%B1%ED%95%98%EA%B8%B0/",
    "categories": "docker",
    "tags": "docker",
    "date": "2024-05-15 00:00:00 +0900",
    





    
    "snippet": "Docker 소개Docker는 개발자들이 어디에서나 일관된 환경에서 애플리케이션을 실행할 수 있도록 컨테이너라는 형태로 소프트웨어를 패키징할 수 있는 플랫폼으로, 소프트웨어 개발에 혁명을 일으켰습니다. 이 글에서는 Docker가 등장한 배경, 그리고 컨테이너, 이미지, 볼륨, 빌드 프로세스 같은 주요 개념을 탐구하고, 이러한 개념들이 어떻게 효율적이고...",
    "content": "Docker 소개Docker는 개발자들이 어디에서나 일관된 환경에서 애플리케이션을 실행할 수 있도록 컨테이너라는 형태로 소프트웨어를 패키징할 수 있는 플랫폼으로, 소프트웨어 개발에 혁명을 일으켰습니다. 이 글에서는 Docker가 등장한 배경, 그리고 컨테이너, 이미지, 볼륨, 빌드 프로세스 같은 주요 개념을 탐구하고, 이러한 개념들이 어떻게 효율적이고 예측 가능한 소프트웨어 배포에 기여하는지 살펴보고 , ARM아키텍쳐로 구성된 로컬환경에서버전이 낮은 Python서버를 Docker로 구성하고 서버를 돌려봅니다..Docker의 등장Docker는 2013년에 도입되어, 서로 다른 컴퓨팅 환경에서 소프트웨어를 신뢰성 있게 구성하는 복잡성에 대응하였습니다. 컨테이너 기술을 활용하여 기반 인프라에 관계없이 코드가 동일하게 실행될 수 있도록 함으로써 개발, 테스트 및 배포 워크플로우를 단순화했습니다.주요 Docker 개념 이해컨테이너컨테이너는 코드, 런타임, 라이브러리 및 시스템 설정을 포함하여 애플리케이션 실행에 필요한 모든 것이 포함된 경량의 실행 가능한 패키지입니다. Docker 이미지를 기반으로 운영되며, 각 컨테이너는 서로 완전히 격리되어 있어 같은 호스트에서 실행되어도 서로 영향을 주지 않습니다. 컨테이너는 일시적인 상태를 가지며 실행 중일 때만 상태가 유지됩니다.이미지이미지는 컨테이너 실행에 필요한 파일과 설정이 포함된 불변의 스냅샷입니다. 컨테이너를 생성하는 데 사용되는 템플릿으로 생각할 수 있으며, 하나의 이미지에서 여러 컨테이너를 생성할 수 있습니다. 이미지는 대개 Dockerfile이라는 텍스트 문서를 통해 생성되며, 이 문서에는 컨테이너를 어떻게 구성할지에 대한 지시사항이 포함되어 있습니다.볼륨볼륨은 데이터를 컨테이너와 독립적으로 저장하고 관리할 수 있는 메커니즘입니다. 컨테이너는 일반적으로 불변하며 상태가 없지만, 볼륨을 사용하면 데이터를 영구적으로 저장하거나 여러 컨테이너 간에 공유할 수 있습니다. 볼륨은 호스트 시스템의 특정 부분에 데이터를 저장하며, 컨테이너가 삭제되어도 데이터는 유지됩니다.빌드 프로세스빌드 프로세스는 소스 코드로부터 Docker 이미지를 생성하는 과정입니다. Dockerfile에 정의된 지시사항을 순차적으로 실행하여 이미지의 새로운 계층을 추가하며, 이 계층들이 최종 이미지를 구성합니다. 이렇게 생성된 이미지는 재사용이 가능하며 다른 시스템에 쉽게 배포할 수 있습니다.Docker 이미지 준비이제 기본적인 도커의 개념에 대해 학습했다 믿고 python서버를 docker위에서 구동되는 방법에 대해 소개합니다.Docker를 사용하여 호환성 문제를 해결할 수 있는 Python 3.10 이미지를 준비합니다. Dockerfile을 작성하여 필요한 설정을 구성할 수 있습니다.Python 3.10 이미지를 기반으로 설정FROM python:3.10작업 디렉토리 설정WORKDIR /app의존성 파일 복사COPY requirements.txt .의존성 설치requirements.txt에는 사용중인 라이브러리의 의존성들이 담겨져 있습니다.RUN pip install -r requirements.txt애플리케이션 코드 복사COPY . .서버 실행CMD [\"python\", \"app.py\"]도커 이미지 빌드docker build -t my-python-app .도커 컨테이너실행docker run -p 7077:7077 my-python-app포트번호는 각자 REST API통신을 하기위해 합의된 번호를 사용합니다.도커 컨테이너가 잘 실행되는지 확인하기위해서 REST API를 날려보고 WireShark로 원활한 통신을 하는지 확인해 봅니다서버에서 미리 정의해둔 비지니스 로직을 실행하고 반환하는 값이 정상적입니다.위의 방식으로 7077 포트를 사용하는 파이썬 서버를 도커환경에서 구성하고 API를 실행시켜보았습니다.이로써 어떤 상황에도 서버를 원활하게 구동할 준비가 되었습니다!"
  },
  
  {
    "title": "Electron에서 alert 사용시 input 읽기 전용 문제 해결",
    "url": "/posts/Electron%EC%97%90%EC%84%9C%EC%9D%98-input%EC%9D%B4-%EC%9D%98%EB%8F%84%EC%B9%98%EC%95%8A%EA%B2%8C-readonly%EB%A1%9C-%EA%B0%95%EC%A0%9C%EB%90%98%EB%8A%94-%ED%98%84%EC%83%81/",
    "categories": "Electron, troubleshooting",
    "tags": "",
    "date": "2024-05-13 00:00:00 +0900",
    





    
    "snippet": "개요Electron 애플리케이션에서 alert() 함수를 사용할 때, input 태그가 읽기 전용으로 설정되는 현상이 종종 발생합니다. 이 현상은 Electron의 구조적 특성 때문에 나타나는 문제로, 이해를 돕기 위해 문제의 원인과 해결 방안을 상세히 설명하겠습니다.원인 분석Electron은 Chromium과 Node.js를 기반으로 하는데, 이는 ...",
    "content": "개요Electron 애플리케이션에서 alert() 함수를 사용할 때, input 태그가 읽기 전용으로 설정되는 현상이 종종 발생합니다. 이 현상은 Electron의 구조적 특성 때문에 나타나는 문제로, 이해를 돕기 위해 문제의 원인과 해결 방안을 상세히 설명하겠습니다.원인 분석Electron은 Chromium과 Node.js를 기반으로 하는데, 이는 Electron이 브라우저와 유사한 환경을 제공하지만, 일부 특성이 다르다는 것을 의미합니다. 일반적인 웹 브라우저에서는 alert(), prompt(), confirm() 같은 함수들이 동기적으로 실행되어, 사용자의 입력을 기다리는 동안 전체 렌더링 엔진을 멈춥니다. 그러나 Electron에서는 이러한 함수들이 메인 프로세스의 시스템 대화 상자를 통해 실행되며, 이 과정에서 렌더러 프로세스는 계속해서 비동기적으로 동작합니다.이 때문에, 메인 스레드가 시스템 모달을 실행하면서 렌더러 프로세스의 입력 필드 등이 일시적으로 읽기 전용 상태가 될 수 있습니다. 이는 메인 프로세스와 렌더러 프로세스가 독립적으로 작동하면서 발생하는 동기화 문제로 볼 수 있습니다.해결 방안비동기 대화 상자 사용하기Electron의 dialog 모듈을 사용하여 비동기적으로 메시지 박스를 표시할 수 있습니다. 이 방법은 렌더러 프로세스를 차단하지 않고 사용자의 입력을 받을 수 있습니다.const { dialog } = require(\"electron\");dialog  .showMessageBox({    type: \"info\",    title: \"Information\",    message: \"This is an important message.\"  })  .then((result) =&gt; {    console.log(result.response);  });사용자 정의 모달 구현하기HTML과 CSS를 활용하여 사용자 정의 모달을 만들어 사용하는 것도 좋은 방법입니다. 이는 UI/UX를 완전히 제어할 수 있으며, 기존의 웹 기술을 활용하므로 개발자에게 친숙합니다.&lt;div id=\"myModal\" class=\"modal\"&gt;  &lt;div class=\"modal-content\"&gt;    &lt;span class=\"close\"&gt;&amp;times;&lt;/span&gt;    &lt;p&gt;Some text in the Modal..&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;style&gt;.modal {    display: none;    position: fixed;    z-index: 1;    left: 0;    top: 0;    width: 100%;    height: 100%;    overflow: auto;    background-color: rgb(0,0,0);    background-color: rgba(0,0,0,0.4);}&lt;/style&gt;const modal = document.getElementById(\"myModal\");const span = document.getElementsByClassName(\"close\")[0];span.onclick = function() {    modal.style.display = \"none\";}window.onclick = function(event) {    if (event.target == modal) {        modal.style.display = \"none\";    }}결론Electron에서 alert() 함수의 사용은 입력 필드를 일시적으로 읽기 전용으로 만들 수 있습니다. 이 문제를 해결하기 위해 비동기 대화 상자 사용이나 사용자 정의 모달 구현을 추천합니다. 이 방법들을 통해 사용자 경험을 개선하고 애플리케이션의 효율성을 높일 수 있습니다.커스텀 alert나 modal, dialog 사용함으로써 Electron의 에러를 회피해야합니다. 처음 이 에러를 접하면 어떠한 동작때문인가 싶을텐데해당 이벤트(클릭,handler함수 실행의 사이드이페트)보단 alert그 자체의 문제였어서 당황하였습니다."
  },
  
  {
    "title": "Stencil에서 정적 파일을 이용한 SEO 최적화: RSS, Sitemap, Robots.txt 설정하기",
    "url": "/posts/stencil%EC%97%90%EC%84%9C-%EC%A0%95%EC%A0%81%ED%8C%8C%EC%9D%BC-%EC%B6%94%EA%B0%80%ED%95%B4-SEO%EC%B5%9C%EC%A0%81%ED%99%94%ED%95%98%EA%B8%B0/",
    "categories": "web-development, seo, stencil, vercel, deploy",
    "tags": "",
    "date": "2024-05-12 00:00:00 +0900",
    





    
    "snippet": "개요이 포스트에서는 Stencil 프로젝트에서 SEO를 향상시키기 위해 RSS, sitemap, 및 robots.txt 파일을 정적 파일로 추가하고, 이를 Vercel을 통해 배포하는 과정을 소개하려고 합니다.배경웹 개발에서 검색 엔진 최적화(SEO)는 매우 중요합니다. 효과적인 SEO 설정을 통해 검색 엔진에서 더 높은 순위를 얻고, 이로 인해 웹사...",
    "content": "개요이 포스트에서는 Stencil 프로젝트에서 SEO를 향상시키기 위해 RSS, sitemap, 및 robots.txt 파일을 정적 파일로 추가하고, 이를 Vercel을 통해 배포하는 과정을 소개하려고 합니다.배경웹 개발에서 검색 엔진 최적화(SEO)는 매우 중요합니다. 효과적인 SEO 설정을 통해 검색 엔진에서 더 높은 순위를 얻고, 이로 인해 웹사이트의 트래픽과 가시성이 증가할 수 있습니다.Stencil 프로젝트 설정Stencil은 웹 컴포넌트를 빌드하기 위한 도구이며, 다음과 같이 프로젝트를 설정합니다.  assets 디렉토리에 SEO 관련 파일을 저장합니다.  기본적으로 stencil읭 빌드 경로 www/assets/ 파일들이 해당 위치에 저장됩니다.  SEO폴더안의 정적, 혹은 동적으로 생성된 SEO 파일들을 vercel.json으로 라우팅처리를 해줍니다.파일 구조/www/assets/SEO/└──sitemap.xml└──rss.xml├── rss.xmlVercel에서의 배포Vercel을 사용하여 Stencil 프로젝트를 배포하는 과정은 다음과 같습니다.설정 파일 (vercel.json){  \"rewrites\": [    { \"source\": \"/sitemap.xml\", \"destination\": \"/assets/SEO/sitemap.xml\" },    { \"source\": \"/rss.xml\", \"destination\": \"/assets/SEO/rss.xml\" },    { \"source\": \"/robots.txt\", \"destination\": \"/assets/SEO/robots.txt\" }  ],  \"headers\": [    {      \"source\": \"/rss.xml\",      \"headers\": [        {          \"key\": \"Content-Type\",          \"value\": \"application/xml; charset=utf-8\"        }      ]    },    {      \"source\": \"/sitemap.xml\",      \"headers\": [        {          \"key\": \"Content-Type\",          \"value\": \"application/xml; charset=utf-8\"        }      ]    },    {      \"source\": \"/robots.txt\",      \"headers\": [        {          \"key\": \"Content-Type\",          \"value\": \"text/plain; charset=utf-8\"        },        {          \"key\": \"Cache-Control\",          \"value\": \"public, max-age=86400\"        }      ]    }  ]}라우팅과 파일 타입 설정위의 vercel.json 설정을 통해 각 파일에 적절한 Content-Type 헤더를 설정하고, 캐시 제어를 위한 Cache-Control 헤더를 추가하여 SEO를 최적화할 수 있습니다.마치며이 글에서는 Stencil과 Vercel을 사용하여 RSS, sitemap, 및 robots.txt 파일을 관리하고 SEO를 개선하는 방법을 알아보았습니다.사실은 위의 SEO적용에서의 시행착오가 많았습니다.프로젝트 루트에 해당파일을 위치시켜서 빌드하면 정적자산들이 제대로 빌드되지않는 현상을 겪었고,stencil에서의 정적자산들에 대한 기본위치는 리액트에서의 public처럼 assets에 위치해 있다는 사실을 파악하고vercel에서의 빌드설정파일인 vercel.json에서 최종적으로 자산에 대한 설정을 추가적으로 작업해줘야했습니다결론적으로 deploy되는 폴더인 www/assets/설정 및 저장한 폴더의 정적자산 PATH로 설정을 해줘야합니다..이 설정은 정적자산을 바탕으로 포스팅되었지만 해당 정적자산들을 동적으로 바꿔준다 하더라도 유효합니다."
  },
  
  {
    "title": "일렉트론에서의 서버 오류 핸들링",
    "url": "/posts/%EC%9D%BC%EB%A0%89%ED%8A%B8%EB%A1%A0%EC%97%90%EC%84%9C%EC%9D%98-%EC%84%9C%EB%B2%84-%ED%97%AC%EC%8A%A4%EC%B2%B4%ED%81%AC/",
    "categories": "Electron, Node.js, Socket Server",
    "tags": "Health Check, Server Handling, Socket Server, Electron, troubleshooting",
    "date": "2024-05-10 00:00:00 +0900",
    





    
    "snippet": "개요데이터베이스 백업 로직 중 DB에 센서의 신호값을 저장하거나 , 갖가지 정보 등의 데이터를 소켓 서버에서 참조하는 과정에서 데이터의 무결성을 잃는 현상이 발생했습니다.이로 인해 소켓 서버가 에러를 일으켜 실행되지 않는 오류가 발생했습니다.첫번째는 백업로직중 , 관련된 서버의 동작을 일시정지하는것이 우선되어야겠지만 저는 어느상황에서든지 서버의 이상을...",
    "content": "개요데이터베이스 백업 로직 중 DB에 센서의 신호값을 저장하거나 , 갖가지 정보 등의 데이터를 소켓 서버에서 참조하는 과정에서 데이터의 무결성을 잃는 현상이 발생했습니다.이로 인해 소켓 서버가 에러를 일으켜 실행되지 않는 오류가 발생했습니다.첫번째는 백업로직중 , 관련된 서버의 동작을 일시정지하는것이 우선되어야겠지만 저는 어느상황에서든지 서버의 이상을 감지하고 서버가 자동으로 재실행되는 항상성을 유지하고싶었습니다.따라서 헬스체크의 필요성을 느끼고 일렉트론에서 특정 주기마다 헬스체크를 진행하여 의도치 않은 모든 오류를 핸들링하는 로직을 구현했습니다.추후에 DB백업로직이 실행되면 관련로직의 Socket을 끊고 재연결하고, DB 저장을 일시정지하는 로직을 추가개발해야합니다.헬스체크 로직시스템 환경마다 서버의 실행시간을 예측하기란 어려운 일입니다. 프로그램이 요구하는 시스템의 최소사양에서의 서버실행시간의 평균값인 3초보다 여유를 둔 5초 단위로서비스가 실행되면 헬스체크 메세지를 날리고 , 해당메세지의 respanse Message가 돌아오지못한다면(서버가 원활하지못한다면) 서버를 재실행합니다.재실행은 5초에서 10초 , 20초 , 40초 최대 1분간 기다리며 , 모든 재실행이 실패한다면 dialog로 사용자에게 서버가 원활하지않음을 알립니다.일렉트론 파일에서의 헬스체크 로직// electron 파일에서의 헬스체크 로직let consecutiveFailures = 0;const INITIAL_INTERVAL = 5000;const MAX_INTERVAL = 60000; // 최대 재시작 간격 (60초)let currentInterval = INITIAL_INTERVAL;async function socketHealthCheck() {  if (socketProcess) {    socketProcess.send(\"check-health\");    const isHealthy = await new Promise((resolve) =&gt; {      const timer = setTimeout(() =&gt; {        resolve(false);      }, 5000);      socketProcess.once(\"message\", (message) =&gt; {        if (message === \"socket server health!\") {          clearTimeout(timer);          resolve(true);          console.log(\"socket OK!!\");        }      });    });    if (!isHealthy) {      console.log(\"Socket server is unhealthy, restart\");      await restartSocketServer();      consecutiveFailures += 1;      currentInterval = Math.min(currentInterval * 2, MAX_INTERVAL); // 간격을 두 배로 늘립니다.      mainWindow.reload();      // 연속 실패가 최대 허용 횟수를 초과하면 경고 대화상자를 표시합니다.      if (consecutiveFailures &gt;= MAX_CONSECUTIVE_FAILURES) {        dialog.showMessageBox({          type: \"warning\",          title: \"Socket Server Warning\",          message:            \"소켓 서버가 건강하지 않습니다. 문제가 지속되면 시스템 관리자에게 문의하세요.\",          buttons: [\"확인\"]        });      }    } else {      consecutiveFailures = 0;      currentInterval = INITIAL_INTERVAL; // 서버가 건강하면 간격을 초기화합니다.    }  }}async function restartSocketServer() {  if (socketProcess) {    socketProcess.kill();    socketProcess = null;    await socketStart();    console.log(\"Socket server restarted\");  }}// 일정 간격으로 소켓 서버의 건강을 확인하고, 실패할 경우 간격을 조정합니다.function scheduleHealthCheck() {  setTimeout(() =&gt; {    socketHealthCheck().then(() =&gt; {      scheduleHealthCheck(); // 다음 건강 점검을 스케줄링합니다.    });  }, currentInterval);}scheduleHealthCheck(); // 건강 점검을 시작합니다."
  }
  
]

